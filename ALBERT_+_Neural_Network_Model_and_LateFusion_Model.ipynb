{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ALBERT + Neural Network Model and LateFusion Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNoqmoyVHsmq7xcAfF3zLqa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2f378ee90cf44e49b15dc512d49c0c4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6164c36ee66e46bba5602832b954d924",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_298d6b1369b542e7aac11624cf8ecc21",
              "IPY_MODEL_dc0d02b663824c129f20c6a652c0add3"
            ]
          }
        },
        "6164c36ee66e46bba5602832b954d924": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "298d6b1369b542e7aac11624cf8ecc21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e5f463c86f4d465dbf3a9dc8274c4a8d",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 454,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 454,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_59671e22aa0c41adbbf81591ace44278"
          }
        },
        "dc0d02b663824c129f20c6a652c0add3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_750d0472a4b3428c83405f66bf8c88f0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 454/454 [04:16&lt;00:00,  1.77it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b56fffb4a33b48f2b1d66285a506d803"
          }
        },
        "e5f463c86f4d465dbf3a9dc8274c4a8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "59671e22aa0c41adbbf81591ace44278": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "750d0472a4b3428c83405f66bf8c88f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b56fffb4a33b48f2b1d66285a506d803": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a1d8bf9132e84e6d967c5c4d71151019": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_808714dece2e4a858ec42e352bb94cb0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_df5424d51d5a429eb2fe6556b01ca444",
              "IPY_MODEL_2e3ff748754c4a32a10cfd76804b1a6d"
            ]
          }
        },
        "808714dece2e4a858ec42e352bb94cb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "df5424d51d5a429eb2fe6556b01ca444": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a3e529cd977c45d48f9e13b13848fcb1",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_126db2e27466414eae28024d91eb0095"
          }
        },
        "2e3ff748754c4a32a10cfd76804b1a6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_90e5030a28ef486b865188f8df97c522",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2000/2000 [00:12&lt;00:00, 163.23it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_80e1b05e2c7c49358fda09b77562a941"
          }
        },
        "a3e529cd977c45d48f9e13b13848fcb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "126db2e27466414eae28024d91eb0095": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "90e5030a28ef486b865188f8df97c522": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "80e1b05e2c7c49358fda09b77562a941": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "31d93a451dae48af8159f0301230cfb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_58d19b23585b426a8fe091168a8428fa",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_749ca76b46644a2c873010475c3aae85",
              "IPY_MODEL_bd82c7ae67374214a1b4397a4815671e"
            ]
          }
        },
        "58d19b23585b426a8fe091168a8428fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "749ca76b46644a2c873010475c3aae85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a0e42677e16c4556b81a3ecaf4be2a40",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_87449afc2ae54f919f7c8247bc03ba86"
          }
        },
        "bd82c7ae67374214a1b4397a4815671e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e4240971767e4964a81868c7619f613a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2000/2000 [00:01&lt;00:00, 1085.49it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_715c69632b4042c89c650abd8116f9ca"
          }
        },
        "a0e42677e16c4556b81a3ecaf4be2a40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "87449afc2ae54f919f7c8247bc03ba86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e4240971767e4964a81868c7619f613a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "715c69632b4042c89c650abd8116f9ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5613888808e149a2bda5b939e05e8ae9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_254a12b80c5a4f2ca045faddaf977aee",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d2e9ddd2bf514a96baed89b13494b7e1",
              "IPY_MODEL_06f43b4ae50f49e096019196a099986d"
            ]
          }
        },
        "254a12b80c5a4f2ca045faddaf977aee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d2e9ddd2bf514a96baed89b13494b7e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fc64175f729240518b759dc1778091bc",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a53c01f518884f6789a06a2b1e04580c"
          }
        },
        "06f43b4ae50f49e096019196a099986d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_70d091245bf9456da101e43147ef551c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2000/2000 [00:00&lt;00:00, 4904.39it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_56a7f50900574402bc5fbce45e0548e4"
          }
        },
        "fc64175f729240518b759dc1778091bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a53c01f518884f6789a06a2b1e04580c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "70d091245bf9456da101e43147ef551c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "56a7f50900574402bc5fbce45e0548e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "017859f0149d4bcdbefd0769b527539e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_164f1ada342040819bca1be2abbdf36d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8688b8ed518445869deb1f87d428e74c",
              "IPY_MODEL_179847323fcd4c07a5b7de299a9a6b51"
            ]
          }
        },
        "164f1ada342040819bca1be2abbdf36d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8688b8ed518445869deb1f87d428e74c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_874a774ab4054ab39be1d3d6ae6ae08c",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 454,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 454,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f95543ee365a452bb90c219773c24881"
          }
        },
        "179847323fcd4c07a5b7de299a9a6b51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9b46559abe094c7f89b14dc272b11af4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 454/454 [00:00&lt;00:00, 1984.62it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_35d588fb8df846f1bf40c2efe9b5d93d"
          }
        },
        "874a774ab4054ab39be1d3d6ae6ae08c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f95543ee365a452bb90c219773c24881": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9b46559abe094c7f89b14dc272b11af4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "35d588fb8df846f1bf40c2efe9b5d93d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "595ec784be124bf7b0bb55327e70f2a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_956571f3f3cf4e4fbdf74680f2725939",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5d974e25f86d4f6897ac2ffece987cbd",
              "IPY_MODEL_49b2ddace8884ae29de4e0b4dfe200ea"
            ]
          }
        },
        "956571f3f3cf4e4fbdf74680f2725939": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5d974e25f86d4f6897ac2ffece987cbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_77e2f8319f27425d87cbf7d2ab666577",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ae7c7364c2cd4939bf0696d2bb76e3dc"
          }
        },
        "49b2ddace8884ae29de4e0b4dfe200ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_697f13a0bea54a8ebc071abf20a99ebb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2000/2000 [00:00&lt;00:00, 12305.06it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c0aa38beb7bb43ac9cacf9dbe9a83e8f"
          }
        },
        "77e2f8319f27425d87cbf7d2ab666577": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ae7c7364c2cd4939bf0696d2bb76e3dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "697f13a0bea54a8ebc071abf20a99ebb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c0aa38beb7bb43ac9cacf9dbe9a83e8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ef45ebf43f954dac959f7e8ba9302db1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b3d1efc2b4d54da5b4b7f04199837039",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ec9c6b5c2d9f474fbfa8181f3c2974d0",
              "IPY_MODEL_f7ebb28992d54cbb97b4022bce33fff1"
            ]
          }
        },
        "b3d1efc2b4d54da5b4b7f04199837039": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ec9c6b5c2d9f474fbfa8181f3c2974d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7f15d1c2734247f6979bb01bc8f712fa",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 300,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 300,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_523c00d2634e430cbd060160d06312b5"
          }
        },
        "f7ebb28992d54cbb97b4022bce33fff1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_836e6efcdd634bbc976f0d6cec9e0182",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 300/300 [04:00&lt;00:00,  1.25it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8ea46750e70d41718b556f948c850d21"
          }
        },
        "7f15d1c2734247f6979bb01bc8f712fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "523c00d2634e430cbd060160d06312b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "836e6efcdd634bbc976f0d6cec9e0182": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8ea46750e70d41718b556f948c850d21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/INLANA01/capstone_project_coref_with_transformers/blob/main/ALBERT_%2B_Neural_Network_Model_and_LateFusion_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4RPDiZmp_fd"
      },
      "source": [
        "# Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYtbID0SyORx"
      },
      "source": [
        "import os\n",
        "import gc\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "from tqdm import tqdm\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import log_loss\n",
        "from tqdm import tqdm, trange\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "from sklearn.preprocessing import MinMaxScaler    \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZPCpsucqEd5"
      },
      "source": [
        "# Some of the libraries in extract_features.py use Tensorflow Version 1, hence need to install older version of TenforFlow and disable v2 behaviour"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "skrotr1czUst",
        "outputId": "e0d1e021-a21c-4994-b75c-e103d8fb4304"
      },
      "source": [
        "!pip install tensorflow==1.15\n",
        "!pip install tensorflow-gpu==1.15\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/2b/e3af15221da9ff323521565fa3324b0d7c7c5b1d7a8ca66984c8d59cb0ce/tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 35kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.19.5)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.36.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.2.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.32.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.12.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.12.4)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.8.1)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 56.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.2)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 54.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==1.15) (56.0.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.10.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.4.1)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7540 sha256=2be0ada1b1d131f79ae29ea4fe5848de81e9c99fc0cac6dd6321c6da432335cf\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: gast, keras-applications, tensorflow-estimator, tensorboard, tensorflow\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "  Found existing installation: tensorflow 2.4.1\n",
            "    Uninstalling tensorflow-2.4.1:\n",
            "      Successfully uninstalled tensorflow-2.4.1\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gast",
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==1.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/72/d06017379ad4760dc58781c765376ce4ba5dcf3c08d37032eeefbccf1c51/tensorflow_gpu-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (411.5MB)\n",
            "\u001b[K     |████████████████████████████████| 411.5MB 35kB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.12.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (0.8.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.0.8)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (3.12.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (0.2.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.32.0)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (0.12.0)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.15.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (0.36.2)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (0.2.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.1.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (1.19.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15) (3.3.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.15) (56.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (3.3.4)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (3.10.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (3.4.1)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-1.15.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSLitDSRqkKh"
      },
      "source": [
        "# ALBERT tokenizer needs sentencepiece library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxo3e1sX0rX0",
        "outputId": "f0cc6c48-c3cb-49e5-daee-42805bcfd16a"
      },
      "source": [
        "!pip install sentencepiece"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\r\u001b[K     |▎                               | 10kB 17.7MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 24.5MB/s eta 0:00:01\r\u001b[K     |▉                               | 30kB 29.2MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 18.9MB/s eta 0:00:01\r\u001b[K     |█▍                              | 51kB 16.3MB/s eta 0:00:01\r\u001b[K     |█▋                              | 61kB 15.0MB/s eta 0:00:01\r\u001b[K     |██                              | 71kB 13.4MB/s eta 0:00:01\r\u001b[K     |██▏                             | 81kB 14.0MB/s eta 0:00:01\r\u001b[K     |██▌                             | 92kB 12.4MB/s eta 0:00:01\r\u001b[K     |██▊                             | 102kB 12.5MB/s eta 0:00:01\r\u001b[K     |███                             | 112kB 12.5MB/s eta 0:00:01\r\u001b[K     |███▎                            | 122kB 12.5MB/s eta 0:00:01\r\u001b[K     |███▌                            | 133kB 12.5MB/s eta 0:00:01\r\u001b[K     |███▉                            | 143kB 12.5MB/s eta 0:00:01\r\u001b[K     |████                            | 153kB 12.5MB/s eta 0:00:01\r\u001b[K     |████▍                           | 163kB 12.5MB/s eta 0:00:01\r\u001b[K     |████▋                           | 174kB 12.5MB/s eta 0:00:01\r\u001b[K     |█████                           | 184kB 12.5MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 194kB 12.5MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 204kB 12.5MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 215kB 12.5MB/s eta 0:00:01\r\u001b[K     |██████                          | 225kB 12.5MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 235kB 12.5MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 245kB 12.5MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 256kB 12.5MB/s eta 0:00:01\r\u001b[K     |███████                         | 266kB 12.5MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 276kB 12.5MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 286kB 12.5MB/s eta 0:00:01\r\u001b[K     |████████                        | 296kB 12.5MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 307kB 12.5MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 317kB 12.5MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 327kB 12.5MB/s eta 0:00:01\r\u001b[K     |█████████                       | 337kB 12.5MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 348kB 12.5MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 358kB 12.5MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 368kB 12.5MB/s eta 0:00:01\r\u001b[K     |██████████                      | 378kB 12.5MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 389kB 12.5MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 399kB 12.5MB/s eta 0:00:01\r\u001b[K     |███████████                     | 409kB 12.5MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 419kB 12.5MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 430kB 12.5MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 440kB 12.5MB/s eta 0:00:01\r\u001b[K     |████████████                    | 450kB 12.5MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 460kB 12.5MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 471kB 12.5MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 481kB 12.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 491kB 12.5MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 501kB 12.5MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 512kB 12.5MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 522kB 12.5MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 532kB 12.5MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 542kB 12.5MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 552kB 12.5MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 563kB 12.5MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 573kB 12.5MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 583kB 12.5MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 593kB 12.5MB/s eta 0:00:01\r\u001b[K     |████████████████                | 604kB 12.5MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 614kB 12.5MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 624kB 12.5MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 634kB 12.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 645kB 12.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 655kB 12.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 665kB 12.5MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 675kB 12.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 686kB 12.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 696kB 12.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 706kB 12.5MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 716kB 12.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 727kB 12.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 737kB 12.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 747kB 12.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 757kB 12.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 768kB 12.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 778kB 12.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 788kB 12.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 798kB 12.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 808kB 12.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 819kB 12.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 829kB 12.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 839kB 12.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 849kB 12.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 860kB 12.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 870kB 12.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 880kB 12.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 890kB 12.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 901kB 12.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 911kB 12.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 921kB 12.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 931kB 12.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 942kB 12.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 952kB 12.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 962kB 12.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 972kB 12.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 983kB 12.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 993kB 12.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.0MB 12.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.0MB 12.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.0MB 12.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.0MB 12.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.0MB 12.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1MB 12.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.1MB 12.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.1MB 12.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.1MB 12.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.1MB 12.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.1MB 12.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.1MB 12.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1MB 12.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.1MB 12.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.1MB 12.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2MB 12.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.2MB 12.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.2MB 12.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.2MB 12.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.2MB 12.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.2MB 12.5MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poGLdlIcs_io"
      },
      "source": [
        "!git clone https://github.com/google-research-datasets/gap-coreference.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3R0jusuhvQ_u"
      },
      "source": [
        "## Get the files withour cloning the gitrepo https://stackoverflow.com/questions/4604663/download-single-files-from-github"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTrO4OLasn92"
      },
      "source": [
        "!wget -q https://raw.githubusercontent.com/google-research-datasets/gap-coreference/master/gap-development.tsv\n",
        "!wget -q https://raw.githubusercontent.com/google-research-datasets/gap-coreference/master/gap-validation.tsv\n",
        "!wget -q https://raw.githubusercontent.com/google-research-datasets/gap-coreference/master/gap-test.tsv"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4GaxMajyWc4"
      },
      "source": [
        "!wget -q https://raw.githubusercontent.com/google-research/albert/master/modeling.py \n",
        "# !wget -q https://raw.githubusercontent.com/google-research/albert/master/create_pretraining_data.py \n",
        "!wget -q https://raw.githubusercontent.com/google-research/albert/master/tokenization.py"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DEme_FnZBzW"
      },
      "source": [
        "!wget -q https://raw.githubusercontent.com/google-research/bert/master/extract_features.py "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4H5Ru5xCyrYx"
      },
      "source": [
        "import modeling\n",
        "import tokenization\n",
        "# import extract_features"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhAMNYOyx9oL"
      },
      "source": [
        "# Load the dataset into dataframe using Pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bh0sL1D70plf"
      },
      "source": [
        "val_df = pd.read_table('gap-validation.tsv', index_col='ID').reset_index(drop=True)\n",
        "test_df  = pd.read_table('gap-validation.tsv', index_col='ID').reset_index(drop=True)\n",
        "dev_df  = pd.read_table('gap-development.tsv', index_col='ID').reset_index(drop=True)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wztO03x4yPWc"
      },
      "source": [
        "# Download ALBERT model, to extract features and get embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDphKg7dw7K6"
      },
      "source": [
        "!wget -q https://storage.googleapis.com/albert_models/albert_base_v2.tar.gz"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIqw4YQs3zsv"
      },
      "source": [
        "# Extract Zip file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VO3-UKG3yxtS"
      },
      "source": [
        "import tarfile\n",
        "my_tar = tarfile.open('./albert_base_v2.tar.gz')\n",
        "my_tar.extractall('.') # specify which folder to extract to\n",
        "my_tar.close()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgZYo72SWKnW"
      },
      "source": [
        "# Process the data to extract features and get word embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rp7NUYux1ZVe"
      },
      "source": [
        "def count_char(text, offset):   \n",
        "    # count = 0\n",
        "    # for pos in range(offset):\n",
        "    #     if text[pos] != \" \": count +=1\n",
        "    # return count\n",
        "    return sum([1 if text[pos] != \" \" else 0 for pos in range(offset)])\n",
        "\n",
        "def candidate_length(candidate):\n",
        "    # count = 0\n",
        "    # for i in range(len(candidate)):\n",
        "    #     if candidate[i] !=  \" \": count += 1\n",
        "    # return count\n",
        "    return sum([1 if candidate[i] !=  \" \" else 0 for i in range(len(candidate))])\n",
        "\n",
        "def count_token_length_special(token):\n",
        "    count = 0\n",
        "    special_token = [\"#\", \" \"]\n",
        "    # for i in range(len(token)):\n",
        "    #     if token[i] not in special_token: count+=1\n",
        "    # return count\n",
        "    return sum([1 if token[i] not in special_token else 0 for i in range(len(token))])\n",
        "\n",
        "def embed_by_bert(df, path_to_bert='albert_base', embed_size=768, batch_size=8,\n",
        "                 layers='-1', max_seq_length=256):\n",
        "    \n",
        "    text = df['Text']\n",
        "    text.to_csv('input.txt', index=False, header=False)\n",
        "    albert_extract()\n",
        "\n",
        "    bert_output = pd.read_json(\"output.jsonl\", lines=True)\n",
        "    print(bert_output.head())\n",
        "    \n",
        "    os.system(\"rm input.txt\")\n",
        "    os.system(\"rm output.jsonl\")\n",
        "    \n",
        "    index = df.index\n",
        "    columns = [\"emb_A\", \"emb_B\", \"emb_P\", \"label\"]\n",
        "    emb = pd.DataFrame(index = index, columns = columns)\n",
        "    emb.index.name = \"ID\"\n",
        "    \n",
        "    for i in tqdm(range(len(text))):\n",
        "        \n",
        "        features = bert_output.loc[i, \"features\"]\n",
        "        P_char_start = count_char(df.loc[i, 'Text'], df.loc[i, 'Pronoun-offset'])\n",
        "        A_char_start = count_char(df.loc[i, 'Text'], df.loc[i, 'A-offset'])\n",
        "        B_char_start = count_char(df.loc[i, 'Text'], df.loc[i, 'B-offset'])\n",
        "        A_length = candidate_length(df.loc[i, 'A'])\n",
        "        B_length = candidate_length(df.loc[i, 'B'])\n",
        "        \n",
        "        emb_A, emb_B, emb_P = np.zeros(embed_size), np.zeros(embed_size), np.zeros(embed_size)\n",
        "        char_count, cnt_A, cnt_B = 0, 0, 0\n",
        "        \n",
        "        for j in range(2, len(features)):\n",
        "            token = features[j][\"token\"]\n",
        "            token_length = count_token_length_special(token)\n",
        "            if char_count == P_char_start:\n",
        "                emb_P += np.asarray(features[j][\"layers\"][0]['values']) \n",
        "            if char_count in range(A_char_start, A_char_start + A_length):\n",
        "                emb_A += np.asarray(features[j][\"layers\"][0]['values'])\n",
        "                cnt_A += 1\n",
        "            if char_count in range(B_char_start, B_char_start + B_length):\n",
        "                emb_B += np.asarray(features[j][\"layers\"][0]['values'])\n",
        "                cnt_B += 1                \n",
        "            char_count += token_length\n",
        "        \n",
        "        if cnt_A > 0:\n",
        "            emb_A /= cnt_A\n",
        "        if cnt_B > 0:\n",
        "            emb_B /= cnt_B\n",
        "        \n",
        "        label = \"Neither\"\n",
        "        if (df.loc[i,\"A-coref\"] == True):\n",
        "            label = \"A\"\n",
        "        if (df.loc[i,\"B-coref\"] == True):\n",
        "            label = \"B\"\n",
        "\n",
        "        emb.iloc[i] = [emb_A, emb_B, emb_P, label]\n",
        "        \n",
        "    return emb    "
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKTntlI3o3ha",
        "outputId": "7b758783-d87d-4fd5-f26b-3022fd568ebe"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 11.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 49.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 50.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0oocFay8rlB"
      },
      "source": [
        "# extract_features.py  from BERT re written for ALBERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9IXwQ_pg6RO"
      },
      "source": [
        "from transformers import AlbertTokenizer, AlbertModel, AlbertConfig\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import codecs\n",
        "import collections\n",
        "import json\n",
        "import re\n",
        "\n",
        "import modeling\n",
        "import tokenization\n",
        "import tensorflow as tf\n",
        "\n",
        "# flags = tf.flags\n",
        "\n",
        "# FLAGS = flags.FLAGS\n",
        "\n",
        "# flags.DEFINE_string(\"input_file\", 'input.txt', \"\")\n",
        "\n",
        "# flags.DEFINE_string(\"output_file\", 'output.jsonl', \"\")\n",
        "\n",
        "# flags.DEFINE_string(\"layers\", \"-1\", \"\")\n",
        "\n",
        "# flags.DEFINE_string(\n",
        "#     \"bert_config_file\", 'albert_base/albert_config.json',\n",
        "#     \"The config json file corresponding to the pre-trained BERT model. \"\n",
        "#     \"This specifies the model architecture.\")\n",
        "\n",
        "# flags.DEFINE_integer(\n",
        "#     \"max_seq_length\", 128,\n",
        "#     \"The maximum total input sequence length after WordPiece tokenization. \"\n",
        "#     \"Sequences longer than this will be truncated, and sequences shorter \"\n",
        "#     \"than this will be padded.\")\n",
        "\n",
        "# flags.DEFINE_string(\n",
        "#     \"init_checkpoint\", 'albert_base/model.ckpt',\n",
        "#     \"Initial checkpoint (usually from a pre-trained BERT model).\")\n",
        "\n",
        "# flags.DEFINE_string(\"vocab_file\", 'albert_base/30k-clean.vocab',\n",
        "#                     \"The vocabulary file that the BERT model was trained on.\")\n",
        "\n",
        "# flags.DEFINE_bool(\n",
        "#     \"do_lower_case\", True,\n",
        "#     \"Whether to lower case the input text. Should be True for uncased \"\n",
        "#     \"models and False for cased models.\")\n",
        "\n",
        "# flags.DEFINE_integer(\"batch_size\", 32, \"Batch size for predictions.\")\n",
        "\n",
        "# flags.DEFINE_bool(\"use_tpu\", False, \"Whether to use TPU or GPU/CPU.\")\n",
        "\n",
        "# flags.DEFINE_string(\"master\", None,\n",
        "#                     \"If using a TPU, the address of the master.\")\n",
        "\n",
        "# flags.DEFINE_integer(\n",
        "#     \"num_tpu_cores\", 8,\n",
        "#     \"Only used if `use_tpu` is True. Total number of TPU cores to use.\")\n",
        "\n",
        "# flags.DEFINE_bool(\n",
        "#     \"use_one_hot_embeddings\", False,\n",
        "#     \"If True, tf.one_hot will be used for embedding lookups, otherwise \"\n",
        "#     \"tf.nn.embedding_lookup will be used. On TPUs, this should be True \"\n",
        "#     \"since it is much faster.\")"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uzcamYygwEW"
      },
      "source": [
        "\n",
        "class InputExample(object):\n",
        "\n",
        "  def __init__(self, unique_id, text_a, text_b):\n",
        "    self.unique_id = unique_id\n",
        "    self.text_a = text_a\n",
        "    self.text_b = text_b\n",
        "\n",
        "\n",
        "class InputFeatures(object):\n",
        "  \"\"\"A single set of features of data.\"\"\"\n",
        "\n",
        "  def __init__(self, unique_id, tokens, input_ids, input_mask, input_type_ids):\n",
        "    self.unique_id = unique_id\n",
        "    self.tokens = tokens\n",
        "    self.input_ids = input_ids\n",
        "    self.input_mask = input_mask\n",
        "    self.input_type_ids = input_type_ids\n",
        "\n",
        "\n",
        "def input_fn_builder(features, seq_length):\n",
        "  \"\"\"Creates an `input_fn` closure to be passed to TPUEstimator.\"\"\"\n",
        "\n",
        "  all_unique_ids = []\n",
        "  all_input_ids = []\n",
        "  all_input_mask = []\n",
        "  all_input_type_ids = []\n",
        "\n",
        "  for feature in features:\n",
        "    all_unique_ids.append(feature.unique_id)\n",
        "    all_input_ids.append(feature.input_ids)\n",
        "    all_input_mask.append(feature.input_mask)\n",
        "    all_input_type_ids.append(feature.input_type_ids)\n",
        "\n",
        "  def input_fn(params):\n",
        "    \"\"\"The actual input function.\"\"\"\n",
        "    batch_size = params[\"batch_size\"]\n",
        "\n",
        "    num_examples = len(features)\n",
        "\n",
        "    # This is for demo purposes and does NOT scale to large data sets. We do\n",
        "    # not use Dataset.from_generator() because that uses tf.py_func which is\n",
        "    # not TPU compatible. The right way to load data is with TFRecordReader.\n",
        "    d = tf.data.Dataset.from_tensor_slices({\n",
        "        \"unique_ids\":\n",
        "            tf.constant(all_unique_ids, shape=[num_examples], dtype=tf.int32),\n",
        "        \"input_ids\":\n",
        "            tf.constant(\n",
        "                all_input_ids, shape=[num_examples, seq_length],\n",
        "                dtype=tf.int32),\n",
        "        \"input_mask\":\n",
        "            tf.constant(\n",
        "                all_input_mask,\n",
        "                shape=[num_examples, seq_length],\n",
        "                dtype=tf.int32),\n",
        "        \"input_type_ids\":\n",
        "            tf.constant(\n",
        "                all_input_type_ids,\n",
        "                shape=[num_examples, seq_length],\n",
        "                dtype=tf.int32),\n",
        "    })\n",
        "\n",
        "    d = d.batch(batch_size=batch_size, drop_remainder=False)\n",
        "    return d\n",
        "\n",
        "  return input_fn\n",
        "\n",
        "\n",
        "def model_fn_builder(bert_config, init_checkpoint, layer_indexes, use_tpu,\n",
        "                     use_one_hot_embeddings):\n",
        "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
        "\n",
        "  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
        "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
        "\n",
        "    unique_ids = features[\"unique_ids\"]\n",
        "    input_ids = features[\"input_ids\"]\n",
        "    input_mask = features[\"input_mask\"]\n",
        "    input_type_ids = features[\"input_type_ids\"]\n",
        "\n",
        "    model = modeling.AlbertModel(\n",
        "        config=bert_config,\n",
        "        is_training=False,\n",
        "        input_ids=input_ids,\n",
        "        input_mask=input_mask,\n",
        "        token_type_ids=input_type_ids,\n",
        "        use_one_hot_embeddings=use_one_hot_embeddings)\n",
        "\n",
        "    if mode != tf.estimator.ModeKeys.PREDICT:\n",
        "      raise ValueError(\"Only PREDICT modes are supported: %s\" % (mode))\n",
        "\n",
        "    tvars = tf.trainable_variables()\n",
        "    scaffold_fn = None\n",
        "    (assignment_map,\n",
        "     initialized_variable_names) = modeling.get_assignment_map_from_checkpoint(\n",
        "         tvars, init_checkpoint)\n",
        "    if use_tpu:\n",
        "\n",
        "      def tpu_scaffold():\n",
        "        tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
        "        return tf.train.Scaffold()\n",
        "\n",
        "      scaffold_fn = tpu_scaffold\n",
        "    else:\n",
        "      tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
        "\n",
        "    tf.logging.info(\"**** Trainable Variables ****\")\n",
        "    for var in tvars:\n",
        "      init_string = \"\"\n",
        "      if var.name in initialized_variable_names:\n",
        "        init_string = \", *INIT_FROM_CKPT*\"\n",
        "      tf.logging.info(\"  name = %s, shape = %s%s\", var.name, var.shape,\n",
        "                      init_string)\n",
        "\n",
        "    all_layers = model.get_all_encoder_layers()\n",
        "\n",
        "    predictions = {\n",
        "        \"unique_id\": unique_ids,\n",
        "    }\n",
        "\n",
        "    for (i, layer_index) in enumerate(layer_indexes):\n",
        "      predictions[\"layer_output_%d\" % i] = all_layers[layer_index]\n",
        "\n",
        "    output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n",
        "        mode=mode, predictions=predictions, scaffold_fn=scaffold_fn)\n",
        "    return output_spec\n",
        "\n",
        "  return model_fn\n",
        "\n",
        "\n",
        "def convert_examples_to_features(examples, seq_length, tokenizer):\n",
        "  \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\n",
        "\n",
        "  features = []\n",
        "  for (ex_index, example) in enumerate(examples):\n",
        "    tokens_a = tokenizer.tokenize(example.text_a)\n",
        "\n",
        "    tokens_b = None\n",
        "    if example.text_b:\n",
        "      tokens_b = tokenizer.tokenize(example.text_b)\n",
        "\n",
        "    if tokens_b:\n",
        "      # Modifies `tokens_a` and `tokens_b` in place so that the total\n",
        "      # length is less than the specified length.\n",
        "      # Account for [CLS], [SEP], [SEP] with \"- 3\"\n",
        "      _truncate_seq_pair(tokens_a, tokens_b, seq_length - 3)\n",
        "    else:\n",
        "      # Account for [CLS] and [SEP] with \"- 2\"\n",
        "      if len(tokens_a) > seq_length - 2:\n",
        "        tokens_a = tokens_a[0:(seq_length - 2)]\n",
        "\n",
        "    # The convention in BERT is:\n",
        "    # (a) For sequence pairs:\n",
        "    #  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n",
        "    #  type_ids: 0     0  0    0    0     0       0 0     1  1  1  1   1 1\n",
        "    # (b) For single sequences:\n",
        "    #  tokens:   [CLS] the dog is hairy . [SEP]\n",
        "    #  type_ids: 0     0   0   0  0     0 0\n",
        "    #\n",
        "    # Where \"type_ids\" are used to indicate whether this is the first\n",
        "    # sequence or the second sequence. The embedding vectors for `type=0` and\n",
        "    # `type=1` were learned during pre-training and are added to the wordpiece\n",
        "    # embedding vector (and position vector). This is not *strictly* necessary\n",
        "    # since the [SEP] token unambiguously separates the sequences, but it makes\n",
        "    # it easier for the model to learn the concept of sequences.\n",
        "    #\n",
        "    # For classification tasks, the first vector (corresponding to [CLS]) is\n",
        "    # used as as the \"sentence vector\". Note that this only makes sense because\n",
        "    # the entire model is fine-tuned.\n",
        "    tokens = []\n",
        "    input_type_ids = []\n",
        "    tokens.append(\"[CLS]\")\n",
        "    input_type_ids.append(0)\n",
        "    for token in tokens_a:\n",
        "      tokens.append(token)\n",
        "      input_type_ids.append(0)\n",
        "    tokens.append(\"[SEP]\")\n",
        "    input_type_ids.append(0)\n",
        "\n",
        "    if tokens_b:\n",
        "      for token in tokens_b:\n",
        "        tokens.append(token)\n",
        "        input_type_ids.append(1)\n",
        "      tokens.append(\"[SEP]\")\n",
        "      input_type_ids.append(1)\n",
        "    \n",
        "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "    # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
        "    # tokens are attended to.\n",
        "    input_mask = [1] * len(input_ids)\n",
        "\n",
        "    # Zero-pad up to the sequence length.\n",
        "    while len(input_ids) < seq_length:\n",
        "      input_ids.append(0)\n",
        "      input_mask.append(0)\n",
        "      input_type_ids.append(0)\n",
        "\n",
        "    assert len(input_ids) == seq_length\n",
        "    assert len(input_mask) == seq_length\n",
        "    assert len(input_type_ids) == seq_length\n",
        "\n",
        "    if ex_index < 5:\n",
        "      tf.logging.info(\"*** Example ***\")\n",
        "      tf.logging.info(\"unique_id: %s\" % (example.unique_id))\n",
        "      tf.logging.info(\"tokens: %s\" % \" \".join(\n",
        "          [tokenization.printable_text(x) for x in tokens]))\n",
        "      tf.logging.info(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\n",
        "      tf.logging.info(\"input_mask: %s\" % \" \".join([str(x) for x in input_mask]))\n",
        "      tf.logging.info(\n",
        "          \"input_type_ids: %s\" % \" \".join([str(x) for x in input_type_ids]))\n",
        "\n",
        "    features.append(\n",
        "        InputFeatures(\n",
        "            unique_id=example.unique_id,\n",
        "            tokens=tokens,\n",
        "            input_ids=input_ids,\n",
        "            input_mask=input_mask,\n",
        "            input_type_ids=input_type_ids))\n",
        "  return features\n",
        "\n",
        "\n",
        "def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n",
        "  \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
        "\n",
        "  # This is a simple heuristic which will always truncate the longer sequence\n",
        "  # one token at a time. This makes more sense than truncating an equal percent\n",
        "  # of tokens from each, since if one sequence is very short then each token\n",
        "  # that's truncated likely contains more information than a longer sequence.\n",
        "  while True:\n",
        "    total_length = len(tokens_a) + len(tokens_b)\n",
        "    if total_length <= max_length:\n",
        "      break\n",
        "    if len(tokens_a) > len(tokens_b):\n",
        "      tokens_a.pop()\n",
        "    else:\n",
        "      tokens_b.pop()\n",
        "\n",
        "\n",
        "def read_examples(input_file):\n",
        "  \"\"\"Read a list of `InputExample`s from an input file.\"\"\"\n",
        "  examples = []\n",
        "  unique_id = 0\n",
        "  with tf.gfile.GFile(input_file, \"r\") as reader:\n",
        "    while True:\n",
        "      line = tokenization.convert_to_unicode(reader.readline())\n",
        "      if not line:\n",
        "        break\n",
        "      line = line.strip()\n",
        "      text_a = None\n",
        "      text_b = None\n",
        "      m = re.match(r\"^(.*) \\|\\|\\| (.*)$\", line)\n",
        "      if m is None:\n",
        "        text_a = line\n",
        "      else:\n",
        "        text_a = m.group(1)\n",
        "        text_b = m.group(2)\n",
        "      examples.append(\n",
        "          InputExample(unique_id=unique_id, text_a=text_a, text_b=text_b))\n",
        "      unique_id += 1\n",
        "  return examples\n",
        "\n"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvtlKhBOiD8a"
      },
      "source": [
        "def albert_extract():\n",
        "    tf.logging.set_verbosity(tf.logging.INFO)\n",
        "\n",
        "    #   layer_indexes = [int(x) for x in FLAGS.layers.split(\",\")]\n",
        "    layer_indexes = [-1]\n",
        "\n",
        "    #   bert_config = modeling.AlbertConfig.from_json_file('albert_base/albert_config.json')\n",
        "\n",
        "    model_path = \"albert-base-v2\"\n",
        "    do_lower_case = True\n",
        "    bert_config = AlbertConfig.from_pretrained(model_path,hidden_act =\"gelu\")\n",
        "    tokenizer = AlbertTokenizer.from_pretrained(model_path, do_lower_case=do_lower_case)\n",
        "    #   tokenizer = tokenization.FullTokenizer(\n",
        "    #       vocab_file='albert_base/30k-clean.vocab', do_lower_case=True)\n",
        "\n",
        "    is_per_host = tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2\n",
        "    run_config = tf.contrib.tpu.RunConfig(\n",
        "        master=None,\n",
        "        tpu_config=tf.contrib.tpu.TPUConfig(\n",
        "            num_shards=8,\n",
        "            per_host_input_for_training=is_per_host))\n",
        "\n",
        "    examples = read_examples('input.txt')\n",
        "\n",
        "    features = convert_examples_to_features(\n",
        "        examples=examples, seq_length=512, tokenizer=tokenizer)\n",
        "\n",
        "    unique_id_to_feature = {}\n",
        "    for feature in features:\n",
        "        unique_id_to_feature[feature.unique_id] = feature\n",
        "\n",
        "    model_fn = model_fn_builder(\n",
        "        bert_config=bert_config,\n",
        "        init_checkpoint='albert_base/model.ckpt-best',\n",
        "        layer_indexes=layer_indexes,\n",
        "        use_tpu=False,\n",
        "        use_one_hot_embeddings=False)\n",
        "\n",
        "    # If TPU is not available, this will fall back to normal Estimator on CPU\n",
        "    # or GPU.\n",
        "    estimator = tf.contrib.tpu.TPUEstimator(\n",
        "        use_tpu=False,\n",
        "        model_fn=model_fn,\n",
        "        config=run_config,\n",
        "        predict_batch_size=32)\n",
        "\n",
        "    input_fn = input_fn_builder(\n",
        "        features=features, seq_length=512)\n",
        "\n",
        "    with codecs.getwriter(\"utf-8\")(tf.gfile.Open('output.jsonl',\n",
        "                                                \"w\")) as writer:\n",
        "        for result in estimator.predict(input_fn, yield_single_examples=True):\n",
        "            unique_id = int(result[\"unique_id\"])\n",
        "            feature = unique_id_to_feature[unique_id]\n",
        "            output_json = collections.OrderedDict()\n",
        "            output_json[\"linex_index\"] = unique_id\n",
        "            all_features = []\n",
        "            for (i, token) in enumerate(feature.tokens):\n",
        "                all_layers = []\n",
        "                for (j, layer_index) in enumerate(layer_indexes):\n",
        "                    layer_output = result[\"layer_output_%d\" % j]\n",
        "                    layers = collections.OrderedDict()\n",
        "                    layers[\"index\"] = layer_index\n",
        "                    layers[\"values\"] = [\n",
        "                        round(float(x), 6) for x in layer_output[i:(i + 1)].flat\n",
        "                    ]\n",
        "                    all_layers.append(layers)\n",
        "                    features = collections.OrderedDict()\n",
        "                    features[\"token\"] = token\n",
        "                    features[\"layers\"] = all_layers\n",
        "                    all_features.append(features)\n",
        "            output_json[\"features\"] = all_features\n",
        "            writer.write(json.dumps(output_json) + \"\\n\")"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6ixiEgjo78g"
      },
      "source": [
        "from transformers import AlbertTokenizer, AlbertModel, AlbertConfig"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDlnMW5D9GuD"
      },
      "source": [
        "# Multi-class Neural Network \n",
        "## Detailed explaination of how to train a multiclass neural network model using PyTorch: https://towardsdatascience.com/pytorch-tabular-multiclass-classification-9f8211a123ab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgOEKfsmITev"
      },
      "source": [
        "class MulticlassClassification(nn.Module):\n",
        "    def __init__(self, num_feature, num_class):\n",
        "        super(MulticlassClassification, self).__init__()\n",
        "        \n",
        "        self.layer_1 = nn.Linear(num_feature, 512)\n",
        "        self.layer_2 = nn.Linear(512, 128)\n",
        "        self.layer_3 = nn.Linear(128, 64)\n",
        "        self.layer_out = nn.Linear(64, num_class) \n",
        "        \n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "        self.batchnorm1 = nn.BatchNorm1d(512)\n",
        "        self.batchnorm2 = nn.BatchNorm1d(128)\n",
        "        self.batchnorm3 = nn.BatchNorm1d(64)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.layer_1(x)\n",
        "        x = self.batchnorm1(x)\n",
        "        x = self.relu(x)\n",
        "        \n",
        "        x = self.layer_2(x)\n",
        "        x = self.batchnorm2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        \n",
        "        x = self.layer_3(x)\n",
        "        x = self.batchnorm3(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        \n",
        "        x = self.layer_out(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJIRT4jXIUTo"
      },
      "source": [
        "def featurize(embedding_df):\n",
        "    \n",
        "    pronoun_embs, a_embs, b_embs, labels = [], [], [], []\n",
        "    \n",
        "    for i in tqdm(range(len(embedding_df))):\n",
        "        \n",
        "        pronoun_embs.append(embedding_df.loc[i, \"emb_P\"])\n",
        "        a_embs.append(embedding_df.loc[i, \"emb_A\"])\n",
        "        b_embs.append(embedding_df.loc[i, \"emb_B\"])\n",
        "\n",
        "        label_map = {'A': 0, 'B': 1, 'Neither': 2}\n",
        "        labels.append(label_map[embedding_df.loc[i, \"label\"]])\n",
        "\n",
        "    \n",
        "    a_embs = np.asarray(a_embs).astype('float')\n",
        "    b_embs = np.asarray(b_embs).astype('float') \n",
        "    pronoun_embs = np.asarray(pronoun_embs).astype('float')\n",
        "    \n",
        "    return np.concatenate([a_embs, b_embs, pronoun_embs], axis=1), np.asarray(labels)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTSAK4zYIbU_"
      },
      "source": [
        "class ClassifierDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, X_data, y_data):\n",
        "        self.X_data = X_data\n",
        "        self.y_data = y_data\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        return self.X_data[index], self.y_data[index]\n",
        "        \n",
        "    def __len__ (self):\n",
        "        return len(self.X_data)\n"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7et4oLiWIdTS"
      },
      "source": [
        "def get_class_distribution(obj):\n",
        "    count_dict = {\n",
        "        \"A\": 0,\n",
        "        \"B\": 0,\n",
        "        \"N\": 0,\n",
        "    }\n",
        "    \n",
        "    for i in obj:\n",
        "        if i == 0: \n",
        "            count_dict['A'] += 1\n",
        "        elif i == 1: \n",
        "            count_dict['B'] += 1\n",
        "        elif i == 2: \n",
        "            count_dict['N'] += 1\n",
        "            \n",
        "    return count_dict"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOl5qEhaIfH_"
      },
      "source": [
        "def multi_acc(y_pred, y_test):\n",
        "    y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n",
        "    _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)    \n",
        "    \n",
        "    correct_pred = (y_pred_tags == y_test).float()\n",
        "    acc = correct_pred.sum() / len(correct_pred)\n",
        "    \n",
        "    acc = torch.round(acc * 100)\n",
        "    \n",
        "    return acc"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzhDvm56-_HZ"
      },
      "source": [
        "# Training the model based on the embeddings from ALBERT."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "2f378ee90cf44e49b15dc512d49c0c4b",
            "6164c36ee66e46bba5602832b954d924",
            "298d6b1369b542e7aac11624cf8ecc21",
            "dc0d02b663824c129f20c6a652c0add3",
            "e5f463c86f4d465dbf3a9dc8274c4a8d",
            "59671e22aa0c41adbbf81591ace44278",
            "750d0472a4b3428c83405f66bf8c88f0",
            "b56fffb4a33b48f2b1d66285a506d803",
            "a1d8bf9132e84e6d967c5c4d71151019",
            "808714dece2e4a858ec42e352bb94cb0",
            "df5424d51d5a429eb2fe6556b01ca444",
            "2e3ff748754c4a32a10cfd76804b1a6d",
            "a3e529cd977c45d48f9e13b13848fcb1",
            "126db2e27466414eae28024d91eb0095",
            "90e5030a28ef486b865188f8df97c522",
            "80e1b05e2c7c49358fda09b77562a941",
            "31d93a451dae48af8159f0301230cfb4",
            "58d19b23585b426a8fe091168a8428fa",
            "749ca76b46644a2c873010475c3aae85",
            "bd82c7ae67374214a1b4397a4815671e",
            "a0e42677e16c4556b81a3ecaf4be2a40",
            "87449afc2ae54f919f7c8247bc03ba86",
            "e4240971767e4964a81868c7619f613a",
            "715c69632b4042c89c650abd8116f9ca",
            "5613888808e149a2bda5b939e05e8ae9",
            "254a12b80c5a4f2ca045faddaf977aee",
            "d2e9ddd2bf514a96baed89b13494b7e1",
            "06f43b4ae50f49e096019196a099986d",
            "fc64175f729240518b759dc1778091bc",
            "a53c01f518884f6789a06a2b1e04580c",
            "70d091245bf9456da101e43147ef551c",
            "56a7f50900574402bc5fbce45e0548e4",
            "017859f0149d4bcdbefd0769b527539e",
            "164f1ada342040819bca1be2abbdf36d",
            "8688b8ed518445869deb1f87d428e74c",
            "179847323fcd4c07a5b7de299a9a6b51",
            "874a774ab4054ab39be1d3d6ae6ae08c",
            "f95543ee365a452bb90c219773c24881",
            "9b46559abe094c7f89b14dc272b11af4",
            "35d588fb8df846f1bf40c2efe9b5d93d",
            "595ec784be124bf7b0bb55327e70f2a3",
            "956571f3f3cf4e4fbdf74680f2725939",
            "5d974e25f86d4f6897ac2ffece987cbd",
            "49b2ddace8884ae29de4e0b4dfe200ea",
            "77e2f8319f27425d87cbf7d2ab666577",
            "ae7c7364c2cd4939bf0696d2bb76e3dc",
            "697f13a0bea54a8ebc071abf20a99ebb",
            "c0aa38beb7bb43ac9cacf9dbe9a83e8f",
            "ef45ebf43f954dac959f7e8ba9302db1",
            "b3d1efc2b4d54da5b4b7f04199837039",
            "ec9c6b5c2d9f474fbfa8181f3c2974d0",
            "f7ebb28992d54cbb97b4022bce33fff1",
            "7f15d1c2734247f6979bb01bc8f712fa",
            "523c00d2634e430cbd060160d06312b5",
            "836e6efcdd634bbc976f0d6cec9e0182",
            "8ea46750e70d41718b556f948c850d21"
          ]
        },
        "id": "3E6J1h05Ig0R",
        "outputId": "2e2ed3e0-4007-4207-863e-b1c38722b2d3"
      },
      "source": [
        "import time\n",
        "start = time.time()\n",
        "\n",
        "val_df = pd.read_table('gap-validation.tsv', index_col='ID').reset_index(drop=True)\n",
        "test_df  = pd.read_table('gap-test.tsv', index_col='ID').reset_index(drop=True)\n",
        "dev_df  = pd.read_table('gap-development.tsv', index_col='ID').reset_index(drop=True)\n",
        "\n",
        "val_bert_emb = embed_by_bert(val_df)\n",
        "dev_bert_emb = embed_by_bert(dev_df)\n",
        "test_bert_emb = embed_by_bert(test_df)\n",
        "\n",
        "X_train, y_train = featurize(dev_bert_emb)\n",
        "X_val , y_val = featurize(val_bert_emb)\n",
        "X_test, y_test = featurize(test_bert_emb)\n",
        "\n",
        "train_dataset = ClassifierDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train).long())\n",
        "val_dataset = ClassifierDataset(torch.from_numpy(X_val).float(), torch.from_numpy(y_val).long())\n",
        "test_dataset = ClassifierDataset(torch.from_numpy(X_test).float(), torch.from_numpy(y_test).long())\n",
        "\n",
        "target_list = []\n",
        "for _, t in train_dataset:\n",
        "    target_list.append(t)\n",
        "    \n",
        "target_list = torch.tensor(target_list)\n",
        "target_list = target_list[torch.randperm(len(target_list))]\n",
        "\n",
        "class_count = [i for i in get_class_distribution(y_train).values()]\n",
        "class_weights = 1./torch.tensor(class_count, dtype=torch.float) \n",
        "# print(class_weights)\n",
        "\n",
        "class_weights_all = class_weights[target_list]\n",
        "\n",
        "weighted_sampler = WeightedRandomSampler(\n",
        "    weights=class_weights_all,\n",
        "    num_samples=len(class_weights_all),\n",
        "    replacement=True\n",
        ")\n",
        "\n",
        "EPOCHS = 300\n",
        "BATCH_SIZE = 16\n",
        "LEARNING_RATE = 0.0007\n",
        "NUM_FEATURES = 2304\n",
        "NUM_CLASSES = 3\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, sampler=weighted_sampler)\n",
        "val_loader = DataLoader(dataset=val_dataset, batch_size=1)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=1)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# print(device)\n",
        "\n",
        "model = MulticlassClassification(num_feature = NUM_FEATURES, num_class=NUM_CLASSES)\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "# print(model)\n",
        "\n",
        "accuracy_stats = {\n",
        "    'train': [],\n",
        "    \"val\": []\n",
        "}\n",
        "loss_stats = {\n",
        "    'train': [],\n",
        "    \"val\": []\n",
        "}\n",
        "\n",
        "# albert_train_preds = []\n",
        "\n",
        "print(\"Begin training.\")\n",
        "for e in tqdm(range(1, EPOCHS+1)):\n",
        "    \n",
        "    # TRAINING\n",
        "    train_epoch_loss = 0\n",
        "    train_epoch_acc = 0\n",
        "    model.train()\n",
        "    for X_train_batch, y_train_batch in train_loader:\n",
        "        X_train_batch, y_train_batch = X_train_batch.to(device), y_train_batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        y_train_pred = model(X_train_batch)\n",
        "\n",
        "        probs = nn.Softmax(dim=1)(y_train_pred)\n",
        "        # preds = torch.max(probs, 1)[1]\n",
        "        # albert_train_preds.append([float(probs[0][0]), float(probs[0][1]), float(probs[0][2])])\n",
        "        \n",
        "        train_loss = criterion(y_train_pred, y_train_batch)\n",
        "        train_acc = multi_acc(y_train_pred, y_train_batch)\n",
        "        \n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        train_epoch_loss += train_loss.item()\n",
        "        train_epoch_acc += train_acc.item()\n",
        "        \n",
        "        \n",
        "    # VALIDATION    \n",
        "    with torch.no_grad():\n",
        "        \n",
        "        val_epoch_loss = 0\n",
        "        val_epoch_acc = 0\n",
        "        \n",
        "        model.eval()\n",
        "        for X_val_batch, y_val_batch in val_loader:\n",
        "            X_val_batch, y_val_batch = X_val_batch.to(device), y_val_batch.to(device)\n",
        "            \n",
        "            y_val_pred = model(X_val_batch)\n",
        "                        \n",
        "            val_loss = criterion(y_val_pred, y_val_batch)\n",
        "            val_acc = multi_acc(y_val_pred, y_val_batch)\n",
        "            \n",
        "            val_epoch_loss += val_loss.item()\n",
        "            val_epoch_acc += val_acc.item()\n",
        "    loss_stats['train'].append(train_epoch_loss/len(train_loader))\n",
        "    loss_stats['val'].append(val_epoch_loss/len(val_loader))\n",
        "    accuracy_stats['train'].append(train_epoch_acc/len(train_loader))\n",
        "    accuracy_stats['val'].append(val_epoch_acc/len(val_loader))\n",
        "                              \n",
        "    \n",
        "    print(f'Epoch {e+0:03}: | Train Loss: {train_epoch_loss/len(train_loader):.5f}') \n",
        "    print(f'Val Loss: {val_epoch_loss/len(val_loader):.5f}')\n",
        "    print(f'Train Acc: {train_epoch_acc/len(train_loader):.3f}')\n",
        "    print(f'Val Acc: {val_epoch_acc/len(val_loader):.3f}')\n",
        "\n",
        "end = time.time()\n",
        "print(end - start)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 0\n",
            "INFO:tensorflow:tokens: [CLS] ▁ \" he ▁admitted ▁making ▁four ▁trips ▁to ▁china ▁and ▁playing ▁golf ▁there . ▁he ▁also ▁admitted ▁that ▁z te ▁officials , ▁whom ▁he ▁says ▁are ▁his ▁golf ▁buddies , ▁hosted ▁and ▁paid ▁for ▁the ▁trips . ▁jose ▁de ▁ vene cia ▁iii , ▁son ▁of ▁house ▁speaker ▁jose ▁de ▁ vene cia ▁jr , ▁alleged ▁that ▁a bal os ▁offered ▁him ▁us $ 10 ▁million ▁to ▁withdraw ▁his ▁proposal ▁on ▁the ▁ n bn ▁project . \" [SEP]\n",
            "INFO:tensorflow:input_ids: 2 13 7 438 3297 544 222 9573 20 998 17 791 4034 80 9 24 67 3297 30 2052 591 3055 15 1368 24 898 50 33 4034 26530 15 2812 17 2192 26 14 9573 9 2712 121 13 10263 4321 1867 15 433 16 191 4687 2712 121 13 10263 4321 2000 15 5965 30 21 3817 759 1434 61 182 4403 1036 507 20 10664 33 5149 27 14 13 103 11954 669 9 7 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1\n",
            "INFO:tensorflow:tokens: [CLS] ▁ \" ka th le en ▁not t ▁was ▁born ▁in ▁camb er well , ▁london . ▁her ▁father , ▁philip , ▁was ▁a ▁lithograph ic ▁printer , ▁and ▁her ▁mother , ▁ellen , ▁ran ▁a ▁boarding ▁house ▁in ▁bri x ton ; ▁kathleen ▁was ▁their ▁third ▁daughter . ▁she ▁was ▁educated ▁at ▁mary ▁da t chel or ▁girls ' ▁school ▁ ( now ▁closed ) , ▁london , ▁before ▁attending ▁king ' s ▁college , ▁london . \" [SEP]\n",
            "INFO:tensorflow:input_ids: 2 13 7 657 96 413 219 52 38 23 386 19 15681 106 854 15 479 9 36 321 15 3214 15 23 21 25644 596 12925 15 17 36 449 15 8767 15 717 21 9400 191 19 5584 396 444 73 17008 23 66 422 783 9 39 23 3977 35 1044 1331 38 8856 248 1258 22 116 13 5 1387 827 6 15 479 15 115 6237 437 22 18 314 15 479 9 7 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 2\n",
            "INFO:tensorflow:tokens: [CLS] ▁ \" when ▁she ▁returns ▁to ▁her ▁hotel ▁room , ▁a ▁liberia n ▁man ▁ ( ton y ▁todd ) ▁forces ▁her ▁to ▁smug gle ▁$20 ▁million ▁worth ▁of ▁conflict ▁diamonds ▁to ▁new ▁york , ▁or ▁else ▁fellow ▁fight ▁attendant ▁and ▁friend ▁angela ▁will ▁die . ▁she ▁is ▁caught ▁before ▁she ▁can ▁board ▁the ▁flight , ▁and ▁the ▁team ▁now ▁have ▁nine ▁hours ▁until ▁the ▁plane ▁lands , ▁and ▁save ▁angela . ▁after ▁the ▁confiscated ▁diamonds ▁are ▁stolen ▁by ▁the ▁brother ▁of ▁kale o ▁ ( ja son ▁scott ▁lee ) , ▁whom ▁danny ▁put ▁away ▁for ▁murdering ▁his ▁partner ▁last ▁year , ▁five - 0 ▁and ▁chief ▁fry er ▁team ▁up ▁and ▁enlist ▁the ▁help ▁of ▁august ▁march ▁ ( ed ▁as ner ) , ▁who ▁served ▁a ▁30 - year ▁sentence ▁for ▁smuggling ▁diamonds . \" [SEP]\n",
            "INFO:tensorflow:input_ids: 2 13 7 3185 39 4815 20 36 1454 337 15 21 18646 103 169 13 5 444 93 6176 6 879 36 20 14827 4875 18375 507 2715 16 2930 13010 20 78 305 15 54 962 1657 1074 13980 17 860 11384 129 1327 9 39 25 1383 115 39 92 686 14 1690 15 17 14 173 130 57 1391 974 163 14 3627 3912 15 17 2079 11384 9 75 14 19947 13010 50 6746 34 14 655 16 21818 111 13 5 1004 528 1824 1358 6 15 1368 5303 442 229 26 23537 33 2417 236 159 15 355 8 387 17 903 9887 106 173 71 17 18036 14 448 16 316 285 13 5 69 28 1031 6 15 72 423 21 712 8 731 5123 26 23343 13010 9 7 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 3\n",
            "INFO:tensorflow:tokens: [CLS] ▁ \" on ▁19 ▁march ▁2007 , ▁during ▁a ▁campaign ▁appearance ▁for ▁the ▁new ▁south ▁wales ▁state ▁election , ▁the ▁then ▁opposition ▁leader ▁peter ▁deb nam ▁was ▁confronted ▁by ▁re uca s sel ▁wearing ▁nothing ▁but ▁speed os ▁and ▁a ▁baseball ▁cap , ▁making ▁fun ▁of ▁deb nam ' s ▁campaign ▁appearances ▁in ▁the ▁swim wear . ▁when ▁tv ▁cameras ▁remained ▁focused ▁on ▁re uca s sel ▁rather ▁than ▁mr ▁deb nam , ▁he ▁said , ▁ \" sorry , ▁i ' m ▁not ▁peter ▁deb nam , ▁he ' s ▁over ▁there . \" [SEP]\n",
            "INFO:tensorflow:input_ids: 2 13 7 218 732 285 624 15 112 21 1150 1468 26 14 78 180 1791 146 776 15 14 94 2901 1156 936 12406 6865 23 14568 34 302 11938 18 3434 2466 626 47 1362 759 17 21 1845 2605 15 544 2414 16 12406 6865 22 18 1150 2248 19 14 9221 13691 9 76 983 8688 935 2604 27 302 11938 18 3434 864 119 820 12406 6865 15 24 87 15 13 7 8959 15 31 22 79 52 936 12406 6865 15 24 22 18 84 80 9 7 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 4\n",
            "INFO:tensorflow:tokens: [CLS] ▁ \" by ▁this ▁time , ▁karen ▁ bli xen ▁had ▁separated ▁from ▁her ▁husband , ▁and ▁after ▁their ▁divorce ▁in ▁1925 , ▁finch ▁hat ton ▁moved ▁into ▁her ▁house ▁and ▁began ▁leading ▁safari s ▁for ▁wealthy ▁sports men . ▁among ▁his ▁clients ▁were ▁marshall ▁field ▁jr ▁and ▁edward , ▁prince ▁of ▁wales . ▁according ▁to ▁the ▁author ▁mary ▁love ll , ▁in ▁1930 ▁finch ▁hat ton ▁began ▁a ▁love ▁affair ▁with ▁ber yl ▁mark ham , ▁who ▁was ▁working ▁as ▁a ▁race - horse ▁trainer ▁in ▁nairobi ▁and ▁the ▁surrounding ▁area . ▁later , ▁she ▁would ▁become ▁known ▁as ▁a ▁pioneer ▁fly er ▁herself ▁ ( mark ham ▁attributed ▁her ▁interest ▁in ▁flying ▁to ▁her ▁association ▁with ▁tom ▁campbell ▁black ) . \" [SEP]\n",
            "INFO:tensorflow:input_ids: 2 13 7 779 48 85 15 7512 13 12834 14940 41 4196 37 36 1253 15 17 75 66 7366 19 5031 15 15545 2970 444 385 77 36 191 17 260 1005 25055 18 26 6574 1059 755 9 497 33 7421 46 4526 575 2000 17 1640 15 1296 16 1791 9 496 20 14 1314 1044 339 211 15 19 2215 15545 2970 444 260 21 339 5675 29 5914 3079 943 1225 15 72 23 638 28 21 764 8 14077 9088 19 23651 17 14 2470 217 9 138 15 39 83 533 167 28 21 6217 2855 106 958 13 5 4527 1225 6270 36 1163 19 2317 20 36 607 29 2067 4775 319 6 9 7 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f4d7bdbdcb0>) includes params argument, but params are not passed to Estimator.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp_e9m3zw4\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp_e9m3zw4', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f4df00e8850>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=2, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': None}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n",
            "INFO:tensorflow:Could not find trained model in model_dir: /tmp/tmp_e9m3zw4, running initialization to predict.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Running infer on CPU\n",
            "INFO:tensorflow:name bert/embeddings/word_embeddings match to bert/embeddings/word_embeddings\n",
            "INFO:tensorflow:name bert/embeddings/token_type_embeddings match to bert/embeddings/token_type_embeddings\n",
            "INFO:tensorflow:name bert/embeddings/position_embeddings match to bert/embeddings/position_embeddings\n",
            "INFO:tensorflow:name bert/embeddings/LayerNorm/beta match to bert/embeddings/LayerNorm/beta\n",
            "INFO:tensorflow:name bert/embeddings/LayerNorm/gamma match to bert/embeddings/LayerNorm/gamma\n",
            "INFO:tensorflow:name bert/encoder/embedding_hidden_mapping_in/kernel match to bert/encoder/embedding_hidden_mapping_in/kernel\n",
            "INFO:tensorflow:name bert/encoder/embedding_hidden_mapping_in/bias match to bert/encoder/embedding_hidden_mapping_in/bias\n",
            "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/kernel match to bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/kernel\n",
            "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/bias match to bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/bias\n",
            "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/kernel match to bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/kernel\n",
            "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/bias match to bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/bias\n",
            "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/kernel match to bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/kernel\n",
            "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/bias match to bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/bias\n",
            "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/kernel match to bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/kernel\n",
            "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/bias match to bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/bias\n",
            "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/LayerNorm/beta match to bert/encoder/transformer/group_0/inner_group_0/LayerNorm/beta\n",
            "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/LayerNorm/gamma match to bert/encoder/transformer/group_0/inner_group_0/LayerNorm/gamma\n",
            "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/kernel match to bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/kernel\n",
            "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/bias match to bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/bias\n",
            "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/kernel match to bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/kernel\n",
            "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/bias match to bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/bias\n",
            "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/beta match to bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/beta\n",
            "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/gamma match to bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/gamma\n",
            "INFO:tensorflow:name bert/pooler/dense/kernel match to bert/pooler/dense/kernel\n",
            "INFO:tensorflow:name bert/pooler/dense/bias match to bert/pooler/dense/bias\n",
            "INFO:tensorflow:**** Trainable Variables ****\n",
            "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (30000, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/embedding_hidden_mapping_in/kernel:0, shape = (128, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/embedding_hidden_mapping_in/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "   linex_index                                           features\n",
            "0            0  [{'token': '[CLS]', 'layers': [{'index': -1, '...\n",
            "1            1  [{'token': '[CLS]', 'layers': [{'index': -1, '...\n",
            "2            2  [{'token': '[CLS]', 'layers': [{'index': -1, '...\n",
            "3            3  [{'token': '[CLS]', 'layers': [{'index': -1, '...\n",
            "4            4  [{'token': '[CLS]', 'layers': [{'index': -1, '...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2f378ee90cf44e49b15dc512d49c0c4b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=454.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/internals/blocks.py:849: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  arr_value = np.array(value)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 0\n",
            "INFO:tensorflow:tokens: [CLS] ▁ \" zo e ▁tel ford ▁ - - ▁played ▁the ▁police ▁officer ▁girlfriend ▁of ▁simon , ▁maggie . ▁dumped ▁by ▁simon ▁in ▁the ▁final ▁episode ▁of ▁series ▁1 , ▁after ▁he ▁slept ▁with ▁jenny , ▁and ▁is ▁not ▁seen ▁again . ▁phoebe ▁thomas ▁played ▁cheryl ▁cassidy , ▁pauline ' s ▁friend ▁and ▁also ▁a ▁year ▁11 ▁pupil ▁in ▁simon ' s ▁class . ▁dumped ▁her ▁boyfriend ▁following ▁simon ' s ▁advice ▁after ▁he ▁wouldn ' t ▁have ▁sex ▁with ▁her ▁but ▁later ▁realised ▁this ▁was ▁due ▁to ▁him ▁catching ▁crab s ▁off ▁her ▁friend ▁pauline . \" [SEP]\n",
            "INFO:tensorflow:input_ids: 2 13 7 2500 62 6757 1426 13 8 8 257 14 698 1069 5606 16 2214 15 8379 9 15754 34 2214 19 14 426 942 16 231 137 15 75 24 7132 29 8369 15 17 25 52 541 188 9 20336 831 257 22087 15603 15 18076 22 18 860 17 67 21 159 547 11990 19 2214 22 18 718 9 15754 36 6198 249 2214 22 18 4978 75 24 1265 22 38 57 1589 29 36 47 138 12514 48 23 397 20 61 9436 11895 18 168 36 860 18076 9 7 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1\n",
            "INFO:tensorflow:tokens: [CLS] ▁ \" he ▁grew ▁up ▁in ▁evans ton , ▁illinois ▁the ▁second ▁oldest ▁of ▁five ▁children ▁including ▁his ▁brothers , ▁fred ▁and ▁gordon ▁and ▁sisters , ▁marge ▁ ( pe ppy ) ▁and ▁marilyn . ▁his ▁high ▁school ▁days ▁were ▁spent ▁at ▁new ▁tri er ▁high ▁school ▁in ▁win net ka , ▁illinois . ▁mackenzie ▁studied ▁with ▁bernard ▁leach ▁from ▁1949 ▁to ▁1952 . ▁his ▁simple , ▁wheel - throw n ▁functional ▁pottery ▁is ▁heavily ▁influenced ▁by ▁the ▁oriental ▁aesthetic ▁of ▁sho ji ▁hamad a ▁and ▁kanji ro ▁ kawa i . \" [SEP]\n",
            "INFO:tensorflow:input_ids: 2 13 7 438 1642 71 19 5161 444 15 2695 14 153 2976 16 355 391 215 33 1670 15 4250 17 3791 17 3945 15 22724 13 5 1664 17129 6 17 16592 9 33 183 116 509 46 1111 35 78 2286 106 183 116 19 628 2328 657 15 2695 9 12130 1449 29 5537 21641 37 3720 20 3439 9 33 1935 15 3556 8 21440 103 7652 12403 25 2991 3927 34 14 11339 9450 16 5799 1616 26468 58 17 28575 661 13 6965 49 9 7 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 2\n",
            "INFO:tensorflow:tokens: [CLS] ▁ \" he ▁had ▁been ▁reelected ▁to ▁congress , ▁but ▁resigned ▁in ▁1990 ▁to ▁accept ▁a ▁post ▁as ▁ambassador ▁to ▁brazil . ▁de ▁la ▁so ta ▁again ▁ran ▁for ▁governor ▁of ▁c * rd oba ▁in ▁1991 . ▁defeated ▁by ▁governor ▁angelo z ▁by ▁over ▁ 15% , ▁this ▁latter ▁setback ▁was ▁significant ▁because ▁it ▁cost ▁de ▁la ▁so ta ▁much ▁of ▁his ▁support ▁within ▁the ▁just icia list ▁party ▁ ( which ▁was ▁flush ▁with ▁victory ▁in ▁the ▁1991 ▁mid - term s ) , ▁leading ▁to ▁president ▁carlos ▁men em ▁ ' s ▁endorsement ▁of ▁a ▁separate ▁party ▁list ▁in ▁c * rd oba ▁for ▁the ▁1993 ▁mid - term ▁elections , ▁and ▁to ▁de ▁la ▁so ta ' s ▁failure ▁to ▁regain ▁a ▁seat ▁in ▁congress . \" [SEP]\n",
            "INFO:tensorflow:input_ids: 2 13 7 438 41 74 23080 20 1656 15 47 3861 19 961 20 3440 21 678 28 4399 20 2867 9 121 333 86 536 188 717 26 1268 16 272 2483 897 10595 19 1586 9 1420 34 1268 14840 380 34 84 13 15264 15 48 1932 23149 23 1505 185 32 1516 121 333 86 536 212 16 33 555 363 14 114 15269 5739 346 13 5 2140 23 15017 29 1575 19 14 1586 907 8 3964 18 6 15 1005 20 406 4791 304 1503 13 22 18 19849 16 21 1725 346 968 19 272 2483 897 10595 26 14 1609 907 8 3964 2311 15 17 20 121 333 86 536 22 18 2990 20 10464 21 988 19 1656 9 7 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 3\n",
            "INFO:tensorflow:tokens: [CLS] ▁ \" the ▁current ▁members ▁of ▁crime ▁have ▁also ▁performed ▁in ▁san ▁francisco ▁under ▁the ▁band ▁name ▁ \" re mote ▁viewers \" . ▁strike ▁has ▁published ▁two ▁works ▁of ▁fiction ▁in ▁recent ▁years : ▁ports ▁of ▁hell , ▁which ▁is ▁listed ▁in ▁the ▁rock ▁and ▁roll ▁hall ▁of ▁fame ▁library , ▁and ▁a ▁loud ▁humming ▁sound ▁came ▁from ▁above . ▁rank ▁has ▁produced ▁numerous ▁films ▁ ( under ▁his ▁real ▁name , ▁henry ▁rosenthal ) ▁including ▁the ▁hit ▁the ▁devil ▁and ▁daniel ▁johnston . \" [SEP]\n",
            "INFO:tensorflow:input_ids: 2 13 7 124 866 443 16 2237 57 67 986 19 523 2086 131 14 323 204 13 7 99 20209 6311 7 9 3333 63 467 81 693 16 3209 19 1764 122 45 9551 16 1094 15 56 25 1510 19 14 629 17 3001 554 16 2720 1248 15 17 21 3414 23331 646 281 37 784 9 2839 63 671 1548 1491 13 5 4579 33 683 204 15 1010 28881 6 215 14 770 14 5462 17 1975 11627 9 7 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 4\n",
            "INFO:tensorflow:tokens: [CLS] ▁ \" her ▁santa ▁fe ▁opera ▁debut ▁in ▁2005 ▁was ▁as ▁nu ria ▁in ▁the ▁revised ▁edition ▁of ▁gol ij ov ' s ▁a in ada mar . ▁she ▁sang ▁on ▁the ▁subsequent ▁deutsche ▁gram mo phon ▁recording ▁of ▁the ▁opera . ▁for ▁his ▁opera ▁doctor ▁atomic , ▁adams ▁re wrote ▁the ▁role ▁of ▁kitty ▁op pen heimer , ▁originally ▁a ▁me zzo - soprano ▁role , ▁for ▁soprano ▁voice , ▁and ▁rivera ▁sang ▁the ▁re written ▁part ▁of ▁kitty ▁op pen heimer ▁at ▁lyric ▁opera ▁of ▁chicago , ▁de ▁ned erland se ▁opera , ▁and ▁the ▁metropolitan ▁opera . , ▁all ▁in ▁2007 . ▁she ▁has ▁since ▁sung ▁several ▁parts ▁and ▁roles ▁in ▁john ▁adams ' ▁works , ▁including ▁the ▁soprano ▁part ▁in ▁el ▁ni * o , ▁and ▁the ▁role ▁of ▁kum u dha ▁in ▁a ▁flowering ▁tree ▁in ▁the ▁peter ▁sell ars ▁production ▁at ▁the ▁new ▁crowned ▁hope ▁festival ▁in ▁vienna . \" [SEP]\n",
            "INFO:tensorflow:input_ids: 2 13 7 1694 2490 3686 1877 893 19 812 23 28 3152 2548 19 14 7886 1322 16 13442 9999 2026 22 18 21 108 4405 1615 9 39 3811 27 14 3147 11176 7594 1293 9045 1576 16 14 1877 9 26 33 1877 1687 9692 15 4773 302 12331 14 597 16 16758 3088 3014 18654 15 912 21 55 12154 8 26728 597 15 26 12958 430 15 17 16668 3811 14 302 6390 141 16 16758 3088 3014 18654 35 14224 1877 16 1360 15 121 12266 19276 870 1877 15 17 14 3466 1877 9 15 65 19 624 9 39 63 179 6332 238 1341 17 2954 19 239 4773 22 693 15 215 14 12958 141 19 931 1781 2483 111 15 17 14 597 16 14460 291 7977 19 21 11550 1541 19 14 936 3344 5446 637 35 14 78 11419 1376 874 19 4945 9 7 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f4f51dddef0>) includes params argument, but params are not passed to Estimator.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpq7uaig9r\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpq7uaig9r', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f4e86120390>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=2, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': None}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n",
            "INFO:tensorflow:Could not find trained model in model_dir: /tmp/tmpq7uaig9r, running initialization to predict.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Running infer on CPU\n",
            "INFO:tensorflow:name bert/embeddings/word_embeddings match to bert/embeddings/word_embeddings\n",
            "INFO:tensorflow:name bert/embeddings/token_type_embeddings match to bert/embeddings/token_type_embeddings\n",
            "INFO:tensorflow:name bert/embeddings/position_embeddings match to bert/embeddings/position_embeddings\n",
            "INFO:tensorflow:name bert/embeddings/LayerNorm/beta match to bert/embeddings/LayerNorm/beta\n",
            "INFO:tensorflow:name bert/embeddings/LayerNorm/gamma match to bert/embeddings/LayerNorm/gamma\n",
            "INFO:tensorflow:name bert/encoder/embedding_hidden_mapping_in/kernel match to bert/encoder/embedding_hidden_mapping_in/kernel\n",
            "INFO:tensorflow:name bert/encoder/embedding_hidden_mapping_in/bias match to bert/encoder/embedding_hidden_mapping_in/bias\n",
            "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/kernel match to bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/kernel\n",
            "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/bias match to bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/bias\n",
            "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/kernel match to bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/kernel\n",
            "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/bias match to bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/bias\n",
            "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/kernel match to bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/kernel\n",
            "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/bias match to bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/bias\n",
            "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/kernel match to bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/kernel\n",
            "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/bias match to bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/bias\n",
            "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/LayerNorm/beta match to bert/encoder/transformer/group_0/inner_group_0/LayerNorm/beta\n",
            "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/LayerNorm/gamma match to bert/encoder/transformer/group_0/inner_group_0/LayerNorm/gamma\n",
            "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/kernel match to bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/kernel\n",
            "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/bias match to bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/bias\n",
            "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/kernel match to bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/kernel\n",
            "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/bias match to bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/bias\n",
            "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/beta match to bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/beta\n",
            "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/gamma match to bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/gamma\n",
            "INFO:tensorflow:name bert/pooler/dense/kernel match to bert/pooler/dense/kernel\n",
            "INFO:tensorflow:name bert/pooler/dense/bias match to bert/pooler/dense/bias\n",
            "INFO:tensorflow:**** Trainable Variables ****\n",
            "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (30000, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/embedding_hidden_mapping_in/kernel:0, shape = (128, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/embedding_hidden_mapping_in/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "   linex_index                                           features\n",
            "0            0  [{'token': '[CLS]', 'layers': [{'index': -1, '...\n",
            "1            1  [{'token': '[CLS]', 'layers': [{'index': -1, '...\n",
            "2            2  [{'token': '[CLS]', 'layers': [{'index': -1, '...\n",
            "3            3  [{'token': '[CLS]', 'layers': [{'index': -1, '...\n",
            "4            4  [{'token': '[CLS]', 'layers': [{'index': -1, '...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a1d8bf9132e84e6d967c5c4d71151019",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=2000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/internals/blocks.py:849: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  arr_value = np.array(value)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 0\n",
            "INFO:tensorflow:tokens: [CLS] ▁ \" upon ▁their ▁acceptance ▁into ▁the ▁kon tin ent al ▁hockey ▁league , ▁ deh ner ▁left ▁finland ▁to ▁sign ▁a ▁contract ▁in ▁germany ▁with ▁eh c ▁m * n chen ▁of ▁the ▁del ▁on ▁june ▁18 , ▁2014 . ▁after ▁capturing ▁the ▁german ▁championship ▁with ▁the ▁m * n chen ▁team ▁in ▁2016 , ▁he ▁left ▁the ▁club ▁and ▁was ▁picked ▁up ▁by ▁fellow ▁del ▁side ▁eh c ▁wolf sburg ▁in ▁july ▁2016 . ▁former ▁nhl er ▁gary ▁su ter ▁and ▁olympic - med al ist ▁bob ▁su ter ▁are ▁ deh ner ' s ▁uncle s . ▁his ▁cousin ▁is ▁minnesota ▁wild ' s ▁alternate ▁captain ▁ryan ▁su ter . \" [SEP]\n",
            "INFO:tensorflow:input_ids: 2 13 7 20243 66 10156 77 14 5191 2864 2291 192 2184 278 15 13 22850 1031 225 5613 20 1676 21 1305 19 914 29 16177 150 307 2483 103 5549 16 14 1506 27 295 474 15 623 9 75 12859 14 548 599 29 14 307 2483 103 5549 173 19 690 15 24 225 14 288 17 23 2114 71 34 1657 1506 270 16177 150 2597 6333 19 313 690 9 336 6542 106 4443 2538 815 17 2713 8 4688 192 702 1909 2538 815 50 13 22850 1031 22 18 2788 18 9 33 4191 25 3650 1808 22 18 4912 1062 2959 2538 815 9 7 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1\n",
            "INFO:tensorflow:tokens: [CLS] ▁ \" between ▁the ▁years ▁1979 - 1981 , ▁river ▁won ▁four ▁local ▁titles , ▁and ▁became ▁one ▁of ▁the ▁most ▁expensive ▁teams ▁in ▁the ▁world , ▁with ▁a ▁first ▁team ▁ ( al on so - ▁lu que ) ▁playing ▁in ▁league ▁games ▁and ▁an ▁equally ▁prestigious ▁second ▁team ▁ ( car r asco - ▁ram * n ▁ d * az ) ▁used ▁mostly ▁in ▁copa ▁libertadores ▁matches . ▁during ▁the ▁1981 ▁ \" n acion al \" ▁tournament ▁ ( which ▁river ▁would ▁eventually ▁win ) , ▁alonso ▁often ▁clashed ▁with ▁then ▁coach ▁alfredo ▁di ▁st * fa no ▁ ( who ▁seldom ▁selected ▁him ▁for ▁the ▁first ▁team ▁and ▁instead ▁put ▁younger ▁players ▁such ▁as ▁carlos ▁daniel ▁tap ia ▁and ▁jose ▁maria ▁viet a ▁in ▁his ▁position ) . \" [SEP]\n",
            "INFO:tensorflow:input_ids: 2 13 7 14427 14 122 2188 8 7023 15 341 230 222 375 3037 15 17 178 53 16 14 127 5381 952 19 14 126 15 29 21 64 173 13 5 192 218 656 8 1612 2005 6 791 19 278 466 17 40 7634 8550 153 173 13 5 1367 139 16568 8 2843 2483 103 13 43 2483 4925 6 147 1555 19 10236 28103 1717 9 112 14 2229 13 7 103 13911 192 7 1085 13 5 2140 341 83 878 628 6 15 19672 478 25374 29 94 977 23136 926 354 2483 1473 251 13 5 1924 18001 1704 61 26 14 64 173 17 700 442 2226 1007 145 28 4791 1975 5526 549 17 2712 1926 20344 58 19 33 649 6 9 7 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 2\n",
            "INFO:tensorflow:tokens: [CLS] ▁ \" though ▁his ▁emigration ▁from ▁the ▁country ▁has ▁affected ▁his ▁leadership ▁status , ▁kam el ▁is ▁still ▁a ▁respected ▁elder ▁of ▁the ▁clan . ▁after ▁the ▁fall ▁of ▁hus s ien ' s ▁regime , ▁many ▁considered ▁dr . ▁ali ▁al adh adh ▁a ▁candidate ▁to ▁lead ▁the ▁clan . ▁a ▁contributor ▁to ▁iraq ' s ▁liberation , ▁ali ▁al adh adh ▁and ▁a ▁long ▁time ▁oppose ▁to ▁saddam ' s ▁regime . ▁he ▁was ▁ambushed ▁with ▁his ▁pregnant ▁wife ▁on ▁his ▁way ▁to ▁the ▁hospital ▁in ▁2006 ▁by ▁iraqi ▁insurgents . \" [SEP]\n",
            "INFO:tensorflow:input_ids: 2 13 7 9371 33 22454 37 14 475 63 4114 33 2399 1782 15 6235 532 25 174 21 10861 5227 16 14 4258 9 75 14 1080 16 7734 18 6288 22 18 5136 15 151 724 744 9 2767 493 16502 16502 21 2316 20 672 14 4258 9 21 12922 20 4903 22 18 7581 15 2767 493 16502 16502 17 21 175 85 13659 20 26683 22 18 5136 9 24 23 24753 29 33 5951 663 27 33 161 20 14 980 19 592 34 8567 23063 9 7 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 3\n",
            "INFO:tensorflow:tokens: [CLS] ▁ \" at ▁the ▁trial , ▁pis ci otta ▁said : ▁ \" those ▁who ▁have ▁made ▁promises ▁to ▁us ▁are ▁called ▁bernardo ▁matt ar ella , ▁prince ▁all iata , ▁the ▁monarch ist ▁mp ▁marches ano ▁and ▁also ▁sign or ▁ s cel ba , ▁minister ▁for ▁home ▁affairs ▁ . . . ▁it ▁was ▁marches ano , ▁prince ▁all iata ▁and ▁bernardo ▁matt ar ella ▁who ▁ordered ▁the ▁massacre ▁of ▁port ella ▁di ▁ gine stra . ▁before ▁the ▁massacre ▁they ▁met ▁giulia no . . . \" ▁however ▁the ▁mps ▁matt ar ella , ▁all iata ▁and ▁marches ano ▁were ▁declared ▁innocent ▁by ▁the ▁court ▁of ▁appeal ▁of ▁palermo , ▁at ▁a ▁trial ▁which ▁dealt ▁with ▁their ▁alleged ▁role ▁in ▁the ▁event . ▁during ▁his ▁trial ▁pis ci otta ▁could ▁not ▁account ▁for ▁giulia no ' s ▁documents ▁in ▁which ▁he ▁named ▁the ▁high - ranking ▁government ▁officials ▁and ▁ma fi osi ▁involved ▁with ▁giulia no ' s ▁band . \" [SEP]\n",
            "INFO:tensorflow:input_ids: 2 13 7 721 14 2178 15 15197 1892 15099 87 45 13 7 13577 72 57 117 12247 20 182 50 227 23640 2315 512 2120 15 1296 65 7436 15 14 8151 702 4628 21302 3571 17 67 1676 248 13 18 11040 969 15 789 26 213 2118 13 9 9 9 32 23 21302 3571 15 1296 65 7436 17 23640 2315 512 2120 72 1905 14 7605 16 1295 2120 926 13 22131 5253 9 115 14 7605 59 798 21960 251 9 9 9 7 207 14 15103 2315 512 2120 15 65 7436 17 21302 3571 46 2482 5490 34 14 495 16 4262 16 22093 15 35 21 2178 56 9706 29 66 5965 597 19 14 807 9 112 33 2178 15197 1892 15099 110 52 2176 26 21960 251 22 18 4374 19 56 24 377 14 183 8 14675 283 3055 17 1216 1707 9753 1013 29 21960 251 22 18 323 9 7 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 4\n",
            "INFO:tensorflow:tokens: [CLS] ▁ \" it ▁is ▁about ▁a ▁pair ▁of ▁united ▁states ▁navy ▁shore ▁patrol ler s ▁ ( s ps ) ▁ ( tom ▁beren ger ▁and ▁william ▁mcnamara ) ▁who ▁must ▁escort ▁a ▁beautiful ▁prisoner ▁ ( er ika ▁el enia k ) , ▁and ▁the ▁troubles ▁they ▁encounter . ▁eddie ▁deva ne ▁ ( william ▁mcnamara ) ▁is ▁a ▁young ▁sailor ▁who ▁has ▁carried ▁out ▁a ▁number ▁of ▁inventory - related ▁scam s ▁along ▁with ▁his ▁partner - in - crim e ▁howard ▁ ( cris pin ▁glover ) ▁and ▁made ▁a ▁lot ▁of ▁money ▁during ▁his ▁service . ▁a ▁day ▁before ▁his ▁discharge , ▁eddie ▁is ▁assigned ▁to ▁escort ▁a ▁prisoner ▁from ▁the ▁marine ▁base ▁at ▁camp ▁le je une ▁along ▁with ▁the ▁authoritarian , ▁no - nonsense ▁chief ▁petty ▁officer ▁rock ▁ reilly ▁ ( tom ▁beren ger ) . \" [SEP]\n",
            "INFO:tensorflow:input_ids: 2 13 7 242 25 88 21 2146 16 181 202 1393 3944 5273 1252 18 13 5 18 1919 6 13 5 6015 23222 1674 17 605 28633 6 72 491 7345 21 1632 6566 13 5 106 4166 931 15064 197 6 15 17 14 16615 59 7007 9 4646 16078 556 13 5 15034 28633 6 25 21 461 13051 72 63 1521 70 21 234 16 13875 8 6203 20789 18 303 29 33 2417 8 108 8 15797 62 3444 13 5 11455 3489 21457 6 17 117 21 865 16 875 112 33 365 9 21 208 115 33 11389 15 4646 25 2467 20 7345 21 6566 37 14 2061 1000 35 1232 1009 1969 6763 303 29 14 26819 15 90 8 16684 903 12839 1069 629 13 15382 13 5 6015 23222 1674 6 9 7 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f4f51e0db00>) includes params argument, but params are not passed to Estimator.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpeiy3lxcp\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpeiy3lxcp', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f4e8f260210>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=2, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': None}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n",
            "INFO:tensorflow:Could not find trained model in model_dir: /tmp/tmpeiy3lxcp, running initialization to predict.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Running infer on CPU\n",
            "INFO:tensorflow:name bert/embeddings/word_embeddings match to bert/embeddings/word_embeddings\n",
            "INFO:tensorflow:name bert/embeddings/token_type_embeddings match to bert/embeddings/token_type_embeddings\n",
            "INFO:tensorflow:name bert/embeddings/position_embeddings match to bert/embeddings/position_embeddings\n",
            "INFO:tensorflow:name bert/embeddings/LayerNorm/beta match to bert/embeddings/LayerNorm/beta\n",
            "INFO:tensorflow:name bert/embeddings/LayerNorm/gamma match to bert/embeddings/LayerNorm/gamma\n",
            "INFO:tensorflow:name bert/encoder/embedding_hidden_mapping_in/kernel match to bert/encoder/embedding_hidden_mapping_in/kernel\n",
            "INFO:tensorflow:name bert/encoder/embedding_hidden_mapping_in/bias match to bert/encoder/embedding_hidden_mapping_in/bias\n",
            "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/kernel match to bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/kernel\n",
            "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/bias match to bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/bias\n",
            "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/kernel match to bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/kernel\n",
            "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/bias match to bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/bias\n",
            "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/kernel match to bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/kernel\n",
            "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/bias match to bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/bias\n",
            "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/kernel match to bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/kernel\n",
            "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/bias match to bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/bias\n",
            "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/LayerNorm/beta match to bert/encoder/transformer/group_0/inner_group_0/LayerNorm/beta\n",
            "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/LayerNorm/gamma match to bert/encoder/transformer/group_0/inner_group_0/LayerNorm/gamma\n",
            "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/kernel match to bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/kernel\n",
            "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/bias match to bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/bias\n",
            "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/kernel match to bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/kernel\n",
            "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/bias match to bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/bias\n",
            "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/beta match to bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/beta\n",
            "INFO:tensorflow:name bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/gamma match to bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/gamma\n",
            "INFO:tensorflow:name bert/pooler/dense/kernel match to bert/pooler/dense/kernel\n",
            "INFO:tensorflow:name bert/pooler/dense/bias match to bert/pooler/dense/bias\n",
            "INFO:tensorflow:**** Trainable Variables ****\n",
            "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (30000, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 128), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (128,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/embedding_hidden_mapping_in/kernel:0, shape = (128, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/embedding_hidden_mapping_in/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "   linex_index                                           features\n",
            "0            0  [{'token': '[CLS]', 'layers': [{'index': -1, '...\n",
            "1            1  [{'token': '[CLS]', 'layers': [{'index': -1, '...\n",
            "2            2  [{'token': '[CLS]', 'layers': [{'index': -1, '...\n",
            "3            3  [{'token': '[CLS]', 'layers': [{'index': -1, '...\n",
            "4            4  [{'token': '[CLS]', 'layers': [{'index': -1, '...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "31d93a451dae48af8159f0301230cfb4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=2000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/internals/blocks.py:849: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  arr_value = np.array(value)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5613888808e149a2bda5b939e05e8ae9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=2000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "017859f0149d4bcdbefd0769b527539e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=454.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "595ec784be124bf7b0bb55327e70f2a3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=2000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Begin training.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ef45ebf43f954dac959f7e8ba9302db1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=300.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 001: | Train Loss: 1.01068\n",
            "Val Loss: 1.13986\n",
            "Train Acc: 50.816\n",
            "Val Acc: 37.885\n",
            "Epoch 002: | Train Loss: 0.73724\n",
            "Val Loss: 1.13685\n",
            "Train Acc: 68.576\n",
            "Val Acc: 41.630\n",
            "Epoch 003: | Train Loss: 0.66022\n",
            "Val Loss: 1.10881\n",
            "Train Acc: 71.768\n",
            "Val Acc: 47.797\n",
            "Epoch 004: | Train Loss: 0.54083\n",
            "Val Loss: 1.28731\n",
            "Train Acc: 78.728\n",
            "Val Acc: 42.511\n",
            "Epoch 005: | Train Loss: 0.48243\n",
            "Val Loss: 1.25074\n",
            "Train Acc: 81.816\n",
            "Val Acc: 45.815\n",
            "Epoch 006: | Train Loss: 0.35657\n",
            "Val Loss: 1.50399\n",
            "Train Acc: 86.232\n",
            "Val Acc: 43.392\n",
            "Epoch 007: | Train Loss: 0.31185\n",
            "Val Loss: 1.46139\n",
            "Train Acc: 88.384\n",
            "Val Acc: 41.410\n",
            "Epoch 008: | Train Loss: 0.27957\n",
            "Val Loss: 1.50612\n",
            "Train Acc: 89.632\n",
            "Val Acc: 45.154\n",
            "Epoch 009: | Train Loss: 0.27235\n",
            "Val Loss: 1.58395\n",
            "Train Acc: 89.408\n",
            "Val Acc: 48.238\n",
            "Epoch 010: | Train Loss: 0.22746\n",
            "Val Loss: 1.62464\n",
            "Train Acc: 91.472\n",
            "Val Acc: 46.256\n",
            "Epoch 011: | Train Loss: 0.18200\n",
            "Val Loss: 1.70142\n",
            "Train Acc: 93.584\n",
            "Val Acc: 48.678\n",
            "Epoch 012: | Train Loss: 0.17573\n",
            "Val Loss: 1.80624\n",
            "Train Acc: 92.696\n",
            "Val Acc: 47.137\n",
            "Epoch 013: | Train Loss: 0.17345\n",
            "Val Loss: 1.76504\n",
            "Train Acc: 93.584\n",
            "Val Acc: 48.678\n",
            "Epoch 014: | Train Loss: 0.16756\n",
            "Val Loss: 1.80010\n",
            "Train Acc: 94.208\n",
            "Val Acc: 49.119\n",
            "Epoch 015: | Train Loss: 0.17682\n",
            "Val Loss: 1.88791\n",
            "Train Acc: 93.776\n",
            "Val Acc: 47.797\n",
            "Epoch 016: | Train Loss: 0.15341\n",
            "Val Loss: 1.74984\n",
            "Train Acc: 93.856\n",
            "Val Acc: 46.035\n",
            "Epoch 017: | Train Loss: 0.15717\n",
            "Val Loss: 1.81840\n",
            "Train Acc: 93.984\n",
            "Val Acc: 51.101\n",
            "Epoch 018: | Train Loss: 0.14878\n",
            "Val Loss: 2.09736\n",
            "Train Acc: 94.080\n",
            "Val Acc: 49.339\n",
            "Epoch 019: | Train Loss: 0.09928\n",
            "Val Loss: 2.12828\n",
            "Train Acc: 96.616\n",
            "Val Acc: 48.678\n",
            "Epoch 020: | Train Loss: 0.13014\n",
            "Val Loss: 1.98361\n",
            "Train Acc: 95.504\n",
            "Val Acc: 47.797\n",
            "Epoch 021: | Train Loss: 0.12658\n",
            "Val Loss: 1.99170\n",
            "Train Acc: 95.384\n",
            "Val Acc: 47.137\n",
            "Epoch 022: | Train Loss: 0.09844\n",
            "Val Loss: 2.15629\n",
            "Train Acc: 96.872\n",
            "Val Acc: 47.357\n",
            "Epoch 023: | Train Loss: 0.13947\n",
            "Val Loss: 2.24455\n",
            "Train Acc: 95.480\n",
            "Val Acc: 51.322\n",
            "Epoch 024: | Train Loss: 0.09258\n",
            "Val Loss: 2.11656\n",
            "Train Acc: 96.960\n",
            "Val Acc: 47.137\n",
            "Epoch 025: | Train Loss: 0.12476\n",
            "Val Loss: 2.20931\n",
            "Train Acc: 94.976\n",
            "Val Acc: 47.797\n",
            "Epoch 026: | Train Loss: 0.08179\n",
            "Val Loss: 2.19439\n",
            "Train Acc: 96.568\n",
            "Val Acc: 51.982\n",
            "Epoch 027: | Train Loss: 0.07696\n",
            "Val Loss: 2.35661\n",
            "Train Acc: 96.968\n",
            "Val Acc: 49.559\n",
            "Epoch 028: | Train Loss: 0.09667\n",
            "Val Loss: 2.40789\n",
            "Train Acc: 97.096\n",
            "Val Acc: 50.881\n",
            "Epoch 029: | Train Loss: 0.12106\n",
            "Val Loss: 2.32044\n",
            "Train Acc: 95.376\n",
            "Val Acc: 48.678\n",
            "Epoch 030: | Train Loss: 0.12761\n",
            "Val Loss: 2.12412\n",
            "Train Acc: 95.224\n",
            "Val Acc: 46.256\n",
            "Epoch 031: | Train Loss: 0.10750\n",
            "Val Loss: 2.28820\n",
            "Train Acc: 96.056\n",
            "Val Acc: 50.441\n",
            "Epoch 032: | Train Loss: 0.08742\n",
            "Val Loss: 2.32507\n",
            "Train Acc: 96.704\n",
            "Val Acc: 48.238\n",
            "Epoch 033: | Train Loss: 0.06854\n",
            "Val Loss: 2.40839\n",
            "Train Acc: 97.152\n",
            "Val Acc: 48.899\n",
            "Epoch 034: | Train Loss: 0.07290\n",
            "Val Loss: 2.52949\n",
            "Train Acc: 97.680\n",
            "Val Acc: 48.899\n",
            "Epoch 035: | Train Loss: 0.09423\n",
            "Val Loss: 2.43351\n",
            "Train Acc: 96.944\n",
            "Val Acc: 47.797\n",
            "Epoch 036: | Train Loss: 0.09891\n",
            "Val Loss: 2.38792\n",
            "Train Acc: 96.160\n",
            "Val Acc: 46.916\n",
            "Epoch 037: | Train Loss: 0.07493\n",
            "Val Loss: 2.39178\n",
            "Train Acc: 97.088\n",
            "Val Acc: 52.643\n",
            "Epoch 038: | Train Loss: 0.06243\n",
            "Val Loss: 2.50947\n",
            "Train Acc: 97.680\n",
            "Val Acc: 50.000\n",
            "Epoch 039: | Train Loss: 0.06042\n",
            "Val Loss: 2.60658\n",
            "Train Acc: 97.976\n",
            "Val Acc: 50.220\n",
            "Epoch 040: | Train Loss: 0.07114\n",
            "Val Loss: 2.60090\n",
            "Train Acc: 97.200\n",
            "Val Acc: 49.780\n",
            "Epoch 041: | Train Loss: 0.08425\n",
            "Val Loss: 2.62330\n",
            "Train Acc: 97.200\n",
            "Val Acc: 47.577\n",
            "Epoch 042: | Train Loss: 0.05359\n",
            "Val Loss: 2.61465\n",
            "Train Acc: 98.104\n",
            "Val Acc: 49.339\n",
            "Epoch 043: | Train Loss: 0.06282\n",
            "Val Loss: 2.70610\n",
            "Train Acc: 97.872\n",
            "Val Acc: 50.661\n",
            "Epoch 044: | Train Loss: 0.09326\n",
            "Val Loss: 2.62384\n",
            "Train Acc: 96.536\n",
            "Val Acc: 47.357\n",
            "Epoch 045: | Train Loss: 0.09675\n",
            "Val Loss: 2.54467\n",
            "Train Acc: 96.488\n",
            "Val Acc: 47.577\n",
            "Epoch 046: | Train Loss: 0.07652\n",
            "Val Loss: 2.66360\n",
            "Train Acc: 97.432\n",
            "Val Acc: 50.220\n",
            "Epoch 047: | Train Loss: 0.04827\n",
            "Val Loss: 2.66605\n",
            "Train Acc: 98.256\n",
            "Val Acc: 47.797\n",
            "Epoch 048: | Train Loss: 0.05790\n",
            "Val Loss: 2.76680\n",
            "Train Acc: 97.624\n",
            "Val Acc: 48.238\n",
            "Epoch 049: | Train Loss: 0.05219\n",
            "Val Loss: 2.80147\n",
            "Train Acc: 98.016\n",
            "Val Acc: 48.678\n",
            "Epoch 050: | Train Loss: 0.08174\n",
            "Val Loss: 2.80818\n",
            "Train Acc: 97.376\n",
            "Val Acc: 47.797\n",
            "Epoch 051: | Train Loss: 0.05729\n",
            "Val Loss: 2.82188\n",
            "Train Acc: 98.112\n",
            "Val Acc: 47.577\n",
            "Epoch 052: | Train Loss: 0.07860\n",
            "Val Loss: 2.61011\n",
            "Train Acc: 97.472\n",
            "Val Acc: 48.899\n",
            "Epoch 053: | Train Loss: 0.05567\n",
            "Val Loss: 2.78294\n",
            "Train Acc: 97.984\n",
            "Val Acc: 50.441\n",
            "Epoch 054: | Train Loss: 0.04271\n",
            "Val Loss: 2.68647\n",
            "Train Acc: 98.840\n",
            "Val Acc: 48.678\n",
            "Epoch 055: | Train Loss: 0.06066\n",
            "Val Loss: 2.87620\n",
            "Train Acc: 97.568\n",
            "Val Acc: 48.458\n",
            "Epoch 056: | Train Loss: 0.04858\n",
            "Val Loss: 2.92080\n",
            "Train Acc: 98.544\n",
            "Val Acc: 48.458\n",
            "Epoch 057: | Train Loss: 0.05586\n",
            "Val Loss: 2.68769\n",
            "Train Acc: 98.160\n",
            "Val Acc: 49.339\n",
            "Epoch 058: | Train Loss: 0.05610\n",
            "Val Loss: 2.98565\n",
            "Train Acc: 97.872\n",
            "Val Acc: 48.899\n",
            "Epoch 059: | Train Loss: 0.04677\n",
            "Val Loss: 2.79577\n",
            "Train Acc: 98.456\n",
            "Val Acc: 48.899\n",
            "Epoch 060: | Train Loss: 0.06167\n",
            "Val Loss: 2.81632\n",
            "Train Acc: 97.824\n",
            "Val Acc: 48.018\n",
            "Epoch 061: | Train Loss: 0.06653\n",
            "Val Loss: 2.80316\n",
            "Train Acc: 98.208\n",
            "Val Acc: 45.815\n",
            "Epoch 062: | Train Loss: 0.05154\n",
            "Val Loss: 2.84460\n",
            "Train Acc: 98.264\n",
            "Val Acc: 50.220\n",
            "Epoch 063: | Train Loss: 0.05746\n",
            "Val Loss: 2.92937\n",
            "Train Acc: 97.816\n",
            "Val Acc: 50.000\n",
            "Epoch 064: | Train Loss: 0.03835\n",
            "Val Loss: 2.79727\n",
            "Train Acc: 98.464\n",
            "Val Acc: 50.220\n",
            "Epoch 065: | Train Loss: 0.05198\n",
            "Val Loss: 2.80818\n",
            "Train Acc: 98.272\n",
            "Val Acc: 51.322\n",
            "Epoch 066: | Train Loss: 0.05323\n",
            "Val Loss: 2.91934\n",
            "Train Acc: 98.072\n",
            "Val Acc: 50.661\n",
            "Epoch 067: | Train Loss: 0.04139\n",
            "Val Loss: 2.87701\n",
            "Train Acc: 98.352\n",
            "Val Acc: 48.458\n",
            "Epoch 068: | Train Loss: 0.05434\n",
            "Val Loss: 3.07932\n",
            "Train Acc: 97.920\n",
            "Val Acc: 51.101\n",
            "Epoch 069: | Train Loss: 0.04077\n",
            "Val Loss: 2.98219\n",
            "Train Acc: 98.408\n",
            "Val Acc: 49.119\n",
            "Epoch 070: | Train Loss: 0.02834\n",
            "Val Loss: 3.12412\n",
            "Train Acc: 99.040\n",
            "Val Acc: 50.661\n",
            "Epoch 071: | Train Loss: 0.06450\n",
            "Val Loss: 3.05926\n",
            "Train Acc: 97.648\n",
            "Val Acc: 49.339\n",
            "Epoch 072: | Train Loss: 0.04811\n",
            "Val Loss: 2.91228\n",
            "Train Acc: 97.816\n",
            "Val Acc: 48.018\n",
            "Epoch 073: | Train Loss: 0.03209\n",
            "Val Loss: 3.10947\n",
            "Train Acc: 98.840\n",
            "Val Acc: 47.137\n",
            "Epoch 074: | Train Loss: 0.03742\n",
            "Val Loss: 2.97919\n",
            "Train Acc: 98.888\n",
            "Val Acc: 49.559\n",
            "Epoch 075: | Train Loss: 0.05125\n",
            "Val Loss: 2.97657\n",
            "Train Acc: 98.072\n",
            "Val Acc: 48.678\n",
            "Epoch 076: | Train Loss: 0.02785\n",
            "Val Loss: 3.09877\n",
            "Train Acc: 98.944\n",
            "Val Acc: 50.220\n",
            "Epoch 077: | Train Loss: 0.05573\n",
            "Val Loss: 3.23518\n",
            "Train Acc: 98.256\n",
            "Val Acc: 46.916\n",
            "Epoch 078: | Train Loss: 0.03950\n",
            "Val Loss: 3.02963\n",
            "Train Acc: 98.600\n",
            "Val Acc: 47.357\n",
            "Epoch 079: | Train Loss: 0.02313\n",
            "Val Loss: 3.16454\n",
            "Train Acc: 99.032\n",
            "Val Acc: 47.137\n",
            "Epoch 080: | Train Loss: 0.03610\n",
            "Val Loss: 3.20380\n",
            "Train Acc: 98.320\n",
            "Val Acc: 48.018\n",
            "Epoch 081: | Train Loss: 0.03783\n",
            "Val Loss: 3.24071\n",
            "Train Acc: 98.512\n",
            "Val Acc: 48.238\n",
            "Epoch 082: | Train Loss: 0.03095\n",
            "Val Loss: 3.20475\n",
            "Train Acc: 98.992\n",
            "Val Acc: 48.899\n",
            "Epoch 083: | Train Loss: 0.04865\n",
            "Val Loss: 3.21741\n",
            "Train Acc: 98.064\n",
            "Val Acc: 48.678\n",
            "Epoch 084: | Train Loss: 0.04851\n",
            "Val Loss: 3.30127\n",
            "Train Acc: 98.456\n",
            "Val Acc: 49.119\n",
            "Epoch 085: | Train Loss: 0.05620\n",
            "Val Loss: 3.44220\n",
            "Train Acc: 98.016\n",
            "Val Acc: 51.762\n",
            "Epoch 086: | Train Loss: 0.05762\n",
            "Val Loss: 3.14899\n",
            "Train Acc: 97.872\n",
            "Val Acc: 50.441\n",
            "Epoch 087: | Train Loss: 0.04481\n",
            "Val Loss: 3.23475\n",
            "Train Acc: 98.024\n",
            "Val Acc: 48.238\n",
            "Epoch 088: | Train Loss: 0.03448\n",
            "Val Loss: 3.37706\n",
            "Train Acc: 98.344\n",
            "Val Acc: 49.119\n",
            "Epoch 089: | Train Loss: 0.02922\n",
            "Val Loss: 3.48464\n",
            "Train Acc: 98.744\n",
            "Val Acc: 50.441\n",
            "Epoch 090: | Train Loss: 0.03547\n",
            "Val Loss: 3.39330\n",
            "Train Acc: 99.088\n",
            "Val Acc: 51.542\n",
            "Epoch 091: | Train Loss: 0.02454\n",
            "Val Loss: 3.33387\n",
            "Train Acc: 98.648\n",
            "Val Acc: 53.084\n",
            "Epoch 092: | Train Loss: 0.04327\n",
            "Val Loss: 3.25211\n",
            "Train Acc: 98.456\n",
            "Val Acc: 52.643\n",
            "Epoch 093: | Train Loss: 0.06609\n",
            "Val Loss: 3.25862\n",
            "Train Acc: 97.872\n",
            "Val Acc: 51.322\n",
            "Epoch 094: | Train Loss: 0.03057\n",
            "Val Loss: 3.20575\n",
            "Train Acc: 98.792\n",
            "Val Acc: 50.220\n",
            "Epoch 095: | Train Loss: 0.02837\n",
            "Val Loss: 3.20064\n",
            "Train Acc: 98.992\n",
            "Val Acc: 49.119\n",
            "Epoch 096: | Train Loss: 0.02617\n",
            "Val Loss: 3.18978\n",
            "Train Acc: 98.992\n",
            "Val Acc: 51.762\n",
            "Epoch 097: | Train Loss: 0.03673\n",
            "Val Loss: 3.34464\n",
            "Train Acc: 98.448\n",
            "Val Acc: 52.643\n",
            "Epoch 098: | Train Loss: 0.03796\n",
            "Val Loss: 3.66339\n",
            "Train Acc: 98.752\n",
            "Val Acc: 51.101\n",
            "Epoch 099: | Train Loss: 0.03695\n",
            "Val Loss: 3.31939\n",
            "Train Acc: 98.752\n",
            "Val Acc: 50.881\n",
            "Epoch 100: | Train Loss: 0.04539\n",
            "Val Loss: 3.41043\n",
            "Train Acc: 98.448\n",
            "Val Acc: 51.762\n",
            "Epoch 101: | Train Loss: 0.05055\n",
            "Val Loss: 3.23879\n",
            "Train Acc: 97.704\n",
            "Val Acc: 48.458\n",
            "Epoch 102: | Train Loss: 0.05701\n",
            "Val Loss: 3.35497\n",
            "Train Acc: 98.160\n",
            "Val Acc: 48.899\n",
            "Epoch 103: | Train Loss: 0.05211\n",
            "Val Loss: 3.29018\n",
            "Train Acc: 98.608\n",
            "Val Acc: 48.899\n",
            "Epoch 104: | Train Loss: 0.04434\n",
            "Val Loss: 3.27514\n",
            "Train Acc: 98.648\n",
            "Val Acc: 48.458\n",
            "Epoch 105: | Train Loss: 0.03116\n",
            "Val Loss: 3.32895\n",
            "Train Acc: 98.544\n",
            "Val Acc: 49.119\n",
            "Epoch 106: | Train Loss: 0.05141\n",
            "Val Loss: 3.14379\n",
            "Train Acc: 98.448\n",
            "Val Acc: 50.220\n",
            "Epoch 107: | Train Loss: 0.02128\n",
            "Val Loss: 3.44187\n",
            "Train Acc: 99.184\n",
            "Val Acc: 49.339\n",
            "Epoch 108: | Train Loss: 0.03288\n",
            "Val Loss: 3.35100\n",
            "Train Acc: 98.744\n",
            "Val Acc: 47.797\n",
            "Epoch 109: | Train Loss: 0.02475\n",
            "Val Loss: 3.44283\n",
            "Train Acc: 99.040\n",
            "Val Acc: 50.000\n",
            "Epoch 110: | Train Loss: 0.02387\n",
            "Val Loss: 3.50195\n",
            "Train Acc: 99.136\n",
            "Val Acc: 50.661\n",
            "Epoch 111: | Train Loss: 0.02590\n",
            "Val Loss: 3.47448\n",
            "Train Acc: 99.040\n",
            "Val Acc: 50.000\n",
            "Epoch 112: | Train Loss: 0.02712\n",
            "Val Loss: 3.63966\n",
            "Train Acc: 99.232\n",
            "Val Acc: 49.119\n",
            "Epoch 113: | Train Loss: 0.02887\n",
            "Val Loss: 3.74565\n",
            "Train Acc: 99.080\n",
            "Val Acc: 47.797\n",
            "Epoch 114: | Train Loss: 0.05668\n",
            "Val Loss: 3.54038\n",
            "Train Acc: 98.400\n",
            "Val Acc: 47.797\n",
            "Epoch 115: | Train Loss: 0.03638\n",
            "Val Loss: 3.31497\n",
            "Train Acc: 98.504\n",
            "Val Acc: 49.780\n",
            "Epoch 116: | Train Loss: 0.02028\n",
            "Val Loss: 3.58971\n",
            "Train Acc: 98.840\n",
            "Val Acc: 49.780\n",
            "Epoch 117: | Train Loss: 0.02275\n",
            "Val Loss: 3.54460\n",
            "Train Acc: 98.976\n",
            "Val Acc: 49.339\n",
            "Epoch 118: | Train Loss: 0.03946\n",
            "Val Loss: 3.45809\n",
            "Train Acc: 98.600\n",
            "Val Acc: 48.899\n",
            "Epoch 119: | Train Loss: 0.02543\n",
            "Val Loss: 3.62514\n",
            "Train Acc: 98.936\n",
            "Val Acc: 51.762\n",
            "Epoch 120: | Train Loss: 0.02069\n",
            "Val Loss: 3.30782\n",
            "Train Acc: 99.080\n",
            "Val Acc: 51.762\n",
            "Epoch 121: | Train Loss: 0.03015\n",
            "Val Loss: 3.39315\n",
            "Train Acc: 98.848\n",
            "Val Acc: 53.304\n",
            "Epoch 122: | Train Loss: 0.01365\n",
            "Val Loss: 3.41961\n",
            "Train Acc: 99.664\n",
            "Val Acc: 51.982\n",
            "Epoch 123: | Train Loss: 0.02642\n",
            "Val Loss: 3.41937\n",
            "Train Acc: 98.992\n",
            "Val Acc: 48.458\n",
            "Epoch 124: | Train Loss: 0.01782\n",
            "Val Loss: 3.63160\n",
            "Train Acc: 99.232\n",
            "Val Acc: 50.441\n",
            "Epoch 125: | Train Loss: 0.01541\n",
            "Val Loss: 3.72295\n",
            "Train Acc: 99.424\n",
            "Val Acc: 51.762\n",
            "Epoch 126: | Train Loss: 0.01654\n",
            "Val Loss: 3.60416\n",
            "Train Acc: 99.376\n",
            "Val Acc: 52.203\n",
            "Epoch 127: | Train Loss: 0.04163\n",
            "Val Loss: 3.52118\n",
            "Train Acc: 98.304\n",
            "Val Acc: 49.119\n",
            "Epoch 128: | Train Loss: 0.03228\n",
            "Val Loss: 3.57867\n",
            "Train Acc: 98.880\n",
            "Val Acc: 50.220\n",
            "Epoch 129: | Train Loss: 0.01876\n",
            "Val Loss: 3.49460\n",
            "Train Acc: 99.280\n",
            "Val Acc: 48.678\n",
            "Epoch 130: | Train Loss: 0.01684\n",
            "Val Loss: 3.50860\n",
            "Train Acc: 99.368\n",
            "Val Acc: 49.339\n",
            "Epoch 131: | Train Loss: 0.02068\n",
            "Val Loss: 3.67052\n",
            "Train Acc: 99.128\n",
            "Val Acc: 48.899\n",
            "Epoch 132: | Train Loss: 0.02992\n",
            "Val Loss: 3.70957\n",
            "Train Acc: 99.032\n",
            "Val Acc: 48.678\n",
            "Epoch 133: | Train Loss: 0.02940\n",
            "Val Loss: 3.60060\n",
            "Train Acc: 99.176\n",
            "Val Acc: 49.780\n",
            "Epoch 134: | Train Loss: 0.03143\n",
            "Val Loss: 3.56628\n",
            "Train Acc: 98.608\n",
            "Val Acc: 49.559\n",
            "Epoch 135: | Train Loss: 0.03267\n",
            "Val Loss: 3.62592\n",
            "Train Acc: 99.184\n",
            "Val Acc: 48.458\n",
            "Epoch 136: | Train Loss: 0.03608\n",
            "Val Loss: 3.66814\n",
            "Train Acc: 98.776\n",
            "Val Acc: 51.542\n",
            "Epoch 137: | Train Loss: 0.02765\n",
            "Val Loss: 3.71489\n",
            "Train Acc: 98.848\n",
            "Val Acc: 50.220\n",
            "Epoch 138: | Train Loss: 0.03333\n",
            "Val Loss: 3.56254\n",
            "Train Acc: 98.944\n",
            "Val Acc: 51.982\n",
            "Epoch 139: | Train Loss: 0.03347\n",
            "Val Loss: 3.61921\n",
            "Train Acc: 98.560\n",
            "Val Acc: 50.441\n",
            "Epoch 140: | Train Loss: 0.02254\n",
            "Val Loss: 3.68189\n",
            "Train Acc: 99.232\n",
            "Val Acc: 47.357\n",
            "Epoch 141: | Train Loss: 0.02054\n",
            "Val Loss: 3.75120\n",
            "Train Acc: 99.280\n",
            "Val Acc: 51.542\n",
            "Epoch 142: | Train Loss: 0.03450\n",
            "Val Loss: 3.58596\n",
            "Train Acc: 98.832\n",
            "Val Acc: 49.119\n",
            "Epoch 143: | Train Loss: 0.04596\n",
            "Val Loss: 3.45144\n",
            "Train Acc: 98.744\n",
            "Val Acc: 50.441\n",
            "Epoch 144: | Train Loss: 0.03266\n",
            "Val Loss: 3.50687\n",
            "Train Acc: 99.232\n",
            "Val Acc: 49.780\n",
            "Epoch 145: | Train Loss: 0.04993\n",
            "Val Loss: 3.64551\n",
            "Train Acc: 98.312\n",
            "Val Acc: 50.441\n",
            "Epoch 146: | Train Loss: 0.02255\n",
            "Val Loss: 3.62816\n",
            "Train Acc: 99.040\n",
            "Val Acc: 50.220\n",
            "Epoch 147: | Train Loss: 0.01874\n",
            "Val Loss: 3.48878\n",
            "Train Acc: 99.472\n",
            "Val Acc: 51.542\n",
            "Epoch 148: | Train Loss: 0.02790\n",
            "Val Loss: 3.39541\n",
            "Train Acc: 99.136\n",
            "Val Acc: 52.423\n",
            "Epoch 149: | Train Loss: 0.02269\n",
            "Val Loss: 3.57441\n",
            "Train Acc: 99.184\n",
            "Val Acc: 52.643\n",
            "Epoch 150: | Train Loss: 0.02775\n",
            "Val Loss: 3.77425\n",
            "Train Acc: 99.032\n",
            "Val Acc: 51.101\n",
            "Epoch 151: | Train Loss: 0.03099\n",
            "Val Loss: 3.56639\n",
            "Train Acc: 99.184\n",
            "Val Acc: 50.661\n",
            "Epoch 152: | Train Loss: 0.02538\n",
            "Val Loss: 3.60627\n",
            "Train Acc: 99.088\n",
            "Val Acc: 50.441\n",
            "Epoch 153: | Train Loss: 0.01658\n",
            "Val Loss: 3.70066\n",
            "Train Acc: 99.472\n",
            "Val Acc: 50.220\n",
            "Epoch 154: | Train Loss: 0.03247\n",
            "Val Loss: 3.61840\n",
            "Train Acc: 98.840\n",
            "Val Acc: 51.101\n",
            "Epoch 155: | Train Loss: 0.02881\n",
            "Val Loss: 3.75604\n",
            "Train Acc: 99.040\n",
            "Val Acc: 49.780\n",
            "Epoch 156: | Train Loss: 0.02372\n",
            "Val Loss: 3.60751\n",
            "Train Acc: 99.136\n",
            "Val Acc: 49.780\n",
            "Epoch 157: | Train Loss: 0.01695\n",
            "Val Loss: 3.33679\n",
            "Train Acc: 99.520\n",
            "Val Acc: 50.661\n",
            "Epoch 158: | Train Loss: 0.01203\n",
            "Val Loss: 3.66956\n",
            "Train Acc: 99.424\n",
            "Val Acc: 49.780\n",
            "Epoch 159: | Train Loss: 0.01124\n",
            "Val Loss: 3.63611\n",
            "Train Acc: 99.760\n",
            "Val Acc: 51.542\n",
            "Epoch 160: | Train Loss: 0.01915\n",
            "Val Loss: 3.68500\n",
            "Train Acc: 99.224\n",
            "Val Acc: 49.780\n",
            "Epoch 161: | Train Loss: 0.01497\n",
            "Val Loss: 3.63659\n",
            "Train Acc: 99.232\n",
            "Val Acc: 51.982\n",
            "Epoch 162: | Train Loss: 0.00786\n",
            "Val Loss: 3.61004\n",
            "Train Acc: 99.760\n",
            "Val Acc: 52.423\n",
            "Epoch 163: | Train Loss: 0.01488\n",
            "Val Loss: 3.64892\n",
            "Train Acc: 99.424\n",
            "Val Acc: 53.304\n",
            "Epoch 164: | Train Loss: 0.01670\n",
            "Val Loss: 3.61012\n",
            "Train Acc: 99.520\n",
            "Val Acc: 51.762\n",
            "Epoch 165: | Train Loss: 0.01074\n",
            "Val Loss: 3.82013\n",
            "Train Acc: 99.664\n",
            "Val Acc: 52.203\n",
            "Epoch 166: | Train Loss: 0.02525\n",
            "Val Loss: 3.73946\n",
            "Train Acc: 98.984\n",
            "Val Acc: 52.863\n",
            "Epoch 167: | Train Loss: 0.00908\n",
            "Val Loss: 3.72002\n",
            "Train Acc: 99.568\n",
            "Val Acc: 51.762\n",
            "Epoch 168: | Train Loss: 0.02583\n",
            "Val Loss: 3.90340\n",
            "Train Acc: 99.328\n",
            "Val Acc: 50.661\n",
            "Epoch 169: | Train Loss: 0.01780\n",
            "Val Loss: 3.81677\n",
            "Train Acc: 99.472\n",
            "Val Acc: 53.084\n",
            "Epoch 170: | Train Loss: 0.02031\n",
            "Val Loss: 3.97121\n",
            "Train Acc: 99.328\n",
            "Val Acc: 51.762\n",
            "Epoch 171: | Train Loss: 0.01242\n",
            "Val Loss: 3.97686\n",
            "Train Acc: 99.472\n",
            "Val Acc: 50.441\n",
            "Epoch 172: | Train Loss: 0.01129\n",
            "Val Loss: 3.96554\n",
            "Train Acc: 99.568\n",
            "Val Acc: 52.643\n",
            "Epoch 173: | Train Loss: 0.04162\n",
            "Val Loss: 4.08631\n",
            "Train Acc: 98.584\n",
            "Val Acc: 50.441\n",
            "Epoch 174: | Train Loss: 0.03188\n",
            "Val Loss: 4.00469\n",
            "Train Acc: 98.800\n",
            "Val Acc: 49.119\n",
            "Epoch 175: | Train Loss: 0.01726\n",
            "Val Loss: 3.94386\n",
            "Train Acc: 99.328\n",
            "Val Acc: 50.881\n",
            "Epoch 176: | Train Loss: 0.01941\n",
            "Val Loss: 4.31581\n",
            "Train Acc: 99.464\n",
            "Val Acc: 49.780\n",
            "Epoch 177: | Train Loss: 0.03883\n",
            "Val Loss: 4.29698\n",
            "Train Acc: 98.352\n",
            "Val Acc: 51.322\n",
            "Epoch 178: | Train Loss: 0.05410\n",
            "Val Loss: 4.21465\n",
            "Train Acc: 98.408\n",
            "Val Acc: 49.780\n",
            "Epoch 179: | Train Loss: 0.02279\n",
            "Val Loss: 3.94813\n",
            "Train Acc: 99.136\n",
            "Val Acc: 50.881\n",
            "Epoch 180: | Train Loss: 0.02322\n",
            "Val Loss: 3.79757\n",
            "Train Acc: 99.080\n",
            "Val Acc: 50.441\n",
            "Epoch 181: | Train Loss: 0.01999\n",
            "Val Loss: 3.81032\n",
            "Train Acc: 99.280\n",
            "Val Acc: 50.220\n",
            "Epoch 182: | Train Loss: 0.01051\n",
            "Val Loss: 3.92718\n",
            "Train Acc: 99.712\n",
            "Val Acc: 51.542\n",
            "Epoch 183: | Train Loss: 0.01665\n",
            "Val Loss: 3.90543\n",
            "Train Acc: 99.328\n",
            "Val Acc: 49.339\n",
            "Epoch 184: | Train Loss: 0.01577\n",
            "Val Loss: 4.03369\n",
            "Train Acc: 99.568\n",
            "Val Acc: 50.220\n",
            "Epoch 185: | Train Loss: 0.01604\n",
            "Val Loss: 4.20921\n",
            "Train Acc: 99.464\n",
            "Val Acc: 49.780\n",
            "Epoch 186: | Train Loss: 0.01990\n",
            "Val Loss: 4.28728\n",
            "Train Acc: 99.280\n",
            "Val Acc: 50.441\n",
            "Epoch 187: | Train Loss: 0.01430\n",
            "Val Loss: 4.09705\n",
            "Train Acc: 99.328\n",
            "Val Acc: 50.220\n",
            "Epoch 188: | Train Loss: 0.01315\n",
            "Val Loss: 4.31987\n",
            "Train Acc: 99.376\n",
            "Val Acc: 49.119\n",
            "Epoch 189: | Train Loss: 0.02261\n",
            "Val Loss: 4.27927\n",
            "Train Acc: 99.136\n",
            "Val Acc: 48.238\n",
            "Epoch 190: | Train Loss: 0.01043\n",
            "Val Loss: 4.25035\n",
            "Train Acc: 99.568\n",
            "Val Acc: 49.339\n",
            "Epoch 191: | Train Loss: 0.02326\n",
            "Val Loss: 4.25348\n",
            "Train Acc: 99.136\n",
            "Val Acc: 47.357\n",
            "Epoch 192: | Train Loss: 0.02677\n",
            "Val Loss: 4.27674\n",
            "Train Acc: 99.040\n",
            "Val Acc: 47.577\n",
            "Epoch 193: | Train Loss: 0.02014\n",
            "Val Loss: 4.29046\n",
            "Train Acc: 99.184\n",
            "Val Acc: 48.678\n",
            "Epoch 194: | Train Loss: 0.02374\n",
            "Val Loss: 4.12983\n",
            "Train Acc: 99.024\n",
            "Val Acc: 50.661\n",
            "Epoch 195: | Train Loss: 0.02126\n",
            "Val Loss: 4.08993\n",
            "Train Acc: 99.088\n",
            "Val Acc: 48.018\n",
            "Epoch 196: | Train Loss: 0.00944\n",
            "Val Loss: 4.30897\n",
            "Train Acc: 99.424\n",
            "Val Acc: 48.458\n",
            "Epoch 197: | Train Loss: 0.00987\n",
            "Val Loss: 4.25528\n",
            "Train Acc: 99.568\n",
            "Val Acc: 48.238\n",
            "Epoch 198: | Train Loss: 0.02705\n",
            "Val Loss: 4.49668\n",
            "Train Acc: 99.040\n",
            "Val Acc: 47.797\n",
            "Epoch 199: | Train Loss: 0.01905\n",
            "Val Loss: 4.28195\n",
            "Train Acc: 99.184\n",
            "Val Acc: 46.916\n",
            "Epoch 200: | Train Loss: 0.01401\n",
            "Val Loss: 4.18817\n",
            "Train Acc: 99.520\n",
            "Val Acc: 46.916\n",
            "Epoch 201: | Train Loss: 0.01659\n",
            "Val Loss: 4.46138\n",
            "Train Acc: 99.280\n",
            "Val Acc: 48.238\n",
            "Epoch 202: | Train Loss: 0.01701\n",
            "Val Loss: 4.45302\n",
            "Train Acc: 99.424\n",
            "Val Acc: 48.678\n",
            "Epoch 203: | Train Loss: 0.01408\n",
            "Val Loss: 4.45749\n",
            "Train Acc: 99.376\n",
            "Val Acc: 48.678\n",
            "Epoch 204: | Train Loss: 0.01149\n",
            "Val Loss: 4.49998\n",
            "Train Acc: 99.424\n",
            "Val Acc: 49.559\n",
            "Epoch 205: | Train Loss: 0.01666\n",
            "Val Loss: 4.59778\n",
            "Train Acc: 99.176\n",
            "Val Acc: 49.559\n",
            "Epoch 206: | Train Loss: 0.03270\n",
            "Val Loss: 4.13686\n",
            "Train Acc: 99.080\n",
            "Val Acc: 48.899\n",
            "Epoch 207: | Train Loss: 0.04835\n",
            "Val Loss: 4.08905\n",
            "Train Acc: 98.944\n",
            "Val Acc: 50.441\n",
            "Epoch 208: | Train Loss: 0.01472\n",
            "Val Loss: 4.01282\n",
            "Train Acc: 99.376\n",
            "Val Acc: 50.661\n",
            "Epoch 209: | Train Loss: 0.01756\n",
            "Val Loss: 4.09681\n",
            "Train Acc: 99.424\n",
            "Val Acc: 51.982\n",
            "Epoch 210: | Train Loss: 0.01526\n",
            "Val Loss: 4.04907\n",
            "Train Acc: 99.560\n",
            "Val Acc: 52.203\n",
            "Epoch 211: | Train Loss: 0.00851\n",
            "Val Loss: 4.26111\n",
            "Train Acc: 99.712\n",
            "Val Acc: 51.101\n",
            "Epoch 212: | Train Loss: 0.01392\n",
            "Val Loss: 4.23855\n",
            "Train Acc: 99.376\n",
            "Val Acc: 51.322\n",
            "Epoch 213: | Train Loss: 0.00811\n",
            "Val Loss: 4.20787\n",
            "Train Acc: 99.712\n",
            "Val Acc: 52.423\n",
            "Epoch 214: | Train Loss: 0.02953\n",
            "Val Loss: 4.61816\n",
            "Train Acc: 98.936\n",
            "Val Acc: 48.899\n",
            "Epoch 215: | Train Loss: 0.02543\n",
            "Val Loss: 4.20582\n",
            "Train Acc: 99.136\n",
            "Val Acc: 50.220\n",
            "Epoch 216: | Train Loss: 0.01508\n",
            "Val Loss: 4.52237\n",
            "Train Acc: 99.376\n",
            "Val Acc: 49.780\n",
            "Epoch 217: | Train Loss: 0.01583\n",
            "Val Loss: 4.16809\n",
            "Train Acc: 99.568\n",
            "Val Acc: 49.559\n",
            "Epoch 218: | Train Loss: 0.02020\n",
            "Val Loss: 4.44582\n",
            "Train Acc: 99.040\n",
            "Val Acc: 48.899\n",
            "Epoch 219: | Train Loss: 0.00749\n",
            "Val Loss: 4.36042\n",
            "Train Acc: 99.856\n",
            "Val Acc: 52.203\n",
            "Epoch 220: | Train Loss: 0.01363\n",
            "Val Loss: 4.47545\n",
            "Train Acc: 99.472\n",
            "Val Acc: 50.441\n",
            "Epoch 221: | Train Loss: 0.01467\n",
            "Val Loss: 4.32651\n",
            "Train Acc: 99.472\n",
            "Val Acc: 51.101\n",
            "Epoch 222: | Train Loss: 0.02541\n",
            "Val Loss: 4.32015\n",
            "Train Acc: 99.088\n",
            "Val Acc: 48.458\n",
            "Epoch 223: | Train Loss: 0.01123\n",
            "Val Loss: 4.54313\n",
            "Train Acc: 99.320\n",
            "Val Acc: 48.458\n",
            "Epoch 224: | Train Loss: 0.01434\n",
            "Val Loss: 4.81190\n",
            "Train Acc: 99.224\n",
            "Val Acc: 50.000\n",
            "Epoch 225: | Train Loss: 0.04485\n",
            "Val Loss: 4.54709\n",
            "Train Acc: 98.792\n",
            "Val Acc: 47.357\n",
            "Epoch 226: | Train Loss: 0.02636\n",
            "Val Loss: 4.72254\n",
            "Train Acc: 98.992\n",
            "Val Acc: 47.357\n",
            "Epoch 227: | Train Loss: 0.01658\n",
            "Val Loss: 4.58520\n",
            "Train Acc: 99.328\n",
            "Val Acc: 47.137\n",
            "Epoch 228: | Train Loss: 0.00727\n",
            "Val Loss: 4.56701\n",
            "Train Acc: 99.664\n",
            "Val Acc: 48.238\n",
            "Epoch 229: | Train Loss: 0.00945\n",
            "Val Loss: 4.60154\n",
            "Train Acc: 99.568\n",
            "Val Acc: 48.678\n",
            "Epoch 230: | Train Loss: 0.00913\n",
            "Val Loss: 4.60033\n",
            "Train Acc: 99.280\n",
            "Val Acc: 47.577\n",
            "Epoch 231: | Train Loss: 0.00829\n",
            "Val Loss: 4.64463\n",
            "Train Acc: 99.808\n",
            "Val Acc: 48.899\n",
            "Epoch 232: | Train Loss: 0.01405\n",
            "Val Loss: 4.76056\n",
            "Train Acc: 99.568\n",
            "Val Acc: 50.000\n",
            "Epoch 233: | Train Loss: 0.02233\n",
            "Val Loss: 5.25070\n",
            "Train Acc: 98.896\n",
            "Val Acc: 48.238\n",
            "Epoch 234: | Train Loss: 0.02404\n",
            "Val Loss: 4.60916\n",
            "Train Acc: 99.280\n",
            "Val Acc: 49.339\n",
            "Epoch 235: | Train Loss: 0.01491\n",
            "Val Loss: 4.83114\n",
            "Train Acc: 99.376\n",
            "Val Acc: 49.339\n",
            "Epoch 236: | Train Loss: 0.00955\n",
            "Val Loss: 4.69331\n",
            "Train Acc: 99.520\n",
            "Val Acc: 50.220\n",
            "Epoch 237: | Train Loss: 0.01037\n",
            "Val Loss: 5.08884\n",
            "Train Acc: 99.424\n",
            "Val Acc: 50.661\n",
            "Epoch 238: | Train Loss: 0.01084\n",
            "Val Loss: 4.90599\n",
            "Train Acc: 99.616\n",
            "Val Acc: 49.780\n",
            "Epoch 239: | Train Loss: 0.02057\n",
            "Val Loss: 4.88960\n",
            "Train Acc: 99.232\n",
            "Val Acc: 50.220\n",
            "Epoch 240: | Train Loss: 0.00462\n",
            "Val Loss: 4.91448\n",
            "Train Acc: 99.712\n",
            "Val Acc: 49.339\n",
            "Epoch 241: | Train Loss: 0.00448\n",
            "Val Loss: 4.74597\n",
            "Train Acc: 99.808\n",
            "Val Acc: 48.238\n",
            "Epoch 242: | Train Loss: 0.00860\n",
            "Val Loss: 4.89785\n",
            "Train Acc: 99.520\n",
            "Val Acc: 49.119\n",
            "Epoch 243: | Train Loss: 0.01065\n",
            "Val Loss: 5.23123\n",
            "Train Acc: 99.568\n",
            "Val Acc: 47.797\n",
            "Epoch 244: | Train Loss: 0.01094\n",
            "Val Loss: 4.80797\n",
            "Train Acc: 99.616\n",
            "Val Acc: 49.780\n",
            "Epoch 245: | Train Loss: 0.01726\n",
            "Val Loss: 5.11800\n",
            "Train Acc: 99.416\n",
            "Val Acc: 46.696\n",
            "Epoch 246: | Train Loss: 0.00867\n",
            "Val Loss: 5.39124\n",
            "Train Acc: 99.520\n",
            "Val Acc: 48.458\n",
            "Epoch 247: | Train Loss: 0.06998\n",
            "Val Loss: 4.80731\n",
            "Train Acc: 98.448\n",
            "Val Acc: 47.797\n",
            "Epoch 248: | Train Loss: 0.04297\n",
            "Val Loss: 4.74318\n",
            "Train Acc: 98.408\n",
            "Val Acc: 46.916\n",
            "Epoch 249: | Train Loss: 0.01431\n",
            "Val Loss: 4.89209\n",
            "Train Acc: 99.280\n",
            "Val Acc: 49.119\n",
            "Epoch 250: | Train Loss: 0.01948\n",
            "Val Loss: 4.81851\n",
            "Train Acc: 99.176\n",
            "Val Acc: 46.256\n",
            "Epoch 251: | Train Loss: 0.02671\n",
            "Val Loss: 4.83768\n",
            "Train Acc: 99.032\n",
            "Val Acc: 49.559\n",
            "Epoch 252: | Train Loss: 0.00987\n",
            "Val Loss: 4.62292\n",
            "Train Acc: 99.616\n",
            "Val Acc: 49.780\n",
            "Epoch 253: | Train Loss: 0.02170\n",
            "Val Loss: 4.52889\n",
            "Train Acc: 98.936\n",
            "Val Acc: 50.000\n",
            "Epoch 254: | Train Loss: 0.02046\n",
            "Val Loss: 4.66260\n",
            "Train Acc: 99.136\n",
            "Val Acc: 51.762\n",
            "Epoch 255: | Train Loss: 0.00635\n",
            "Val Loss: 4.53670\n",
            "Train Acc: 99.712\n",
            "Val Acc: 51.762\n",
            "Epoch 256: | Train Loss: 0.02819\n",
            "Val Loss: 4.59826\n",
            "Train Acc: 99.176\n",
            "Val Acc: 50.000\n",
            "Epoch 257: | Train Loss: 0.02004\n",
            "Val Loss: 4.71091\n",
            "Train Acc: 99.376\n",
            "Val Acc: 47.577\n",
            "Epoch 258: | Train Loss: 0.02608\n",
            "Val Loss: 4.85714\n",
            "Train Acc: 99.080\n",
            "Val Acc: 48.678\n",
            "Epoch 259: | Train Loss: 0.02711\n",
            "Val Loss: 4.73619\n",
            "Train Acc: 99.136\n",
            "Val Acc: 49.339\n",
            "Epoch 260: | Train Loss: 0.02257\n",
            "Val Loss: 5.02867\n",
            "Train Acc: 99.376\n",
            "Val Acc: 47.797\n",
            "Epoch 261: | Train Loss: 0.01811\n",
            "Val Loss: 4.66818\n",
            "Train Acc: 99.424\n",
            "Val Acc: 48.458\n",
            "Epoch 262: | Train Loss: 0.01147\n",
            "Val Loss: 4.77668\n",
            "Train Acc: 99.664\n",
            "Val Acc: 49.119\n",
            "Epoch 263: | Train Loss: 0.01410\n",
            "Val Loss: 4.74135\n",
            "Train Acc: 99.328\n",
            "Val Acc: 49.559\n",
            "Epoch 264: | Train Loss: 0.01097\n",
            "Val Loss: 4.81398\n",
            "Train Acc: 99.712\n",
            "Val Acc: 47.357\n",
            "Epoch 265: | Train Loss: 0.00950\n",
            "Val Loss: 4.63878\n",
            "Train Acc: 99.472\n",
            "Val Acc: 48.678\n",
            "Epoch 266: | Train Loss: 0.00712\n",
            "Val Loss: 4.66563\n",
            "Train Acc: 99.472\n",
            "Val Acc: 48.458\n",
            "Epoch 267: | Train Loss: 0.00750\n",
            "Val Loss: 4.64409\n",
            "Train Acc: 99.472\n",
            "Val Acc: 47.577\n",
            "Epoch 268: | Train Loss: 0.00943\n",
            "Val Loss: 4.85762\n",
            "Train Acc: 99.568\n",
            "Val Acc: 47.357\n",
            "Epoch 269: | Train Loss: 0.00772\n",
            "Val Loss: 4.67542\n",
            "Train Acc: 99.616\n",
            "Val Acc: 49.780\n",
            "Epoch 270: | Train Loss: 0.01456\n",
            "Val Loss: 4.75687\n",
            "Train Acc: 99.376\n",
            "Val Acc: 46.696\n",
            "Epoch 271: | Train Loss: 0.01878\n",
            "Val Loss: 4.59374\n",
            "Train Acc: 99.184\n",
            "Val Acc: 48.018\n",
            "Epoch 272: | Train Loss: 0.00739\n",
            "Val Loss: 4.83384\n",
            "Train Acc: 99.616\n",
            "Val Acc: 50.661\n",
            "Epoch 273: | Train Loss: 0.00720\n",
            "Val Loss: 4.78003\n",
            "Train Acc: 99.712\n",
            "Val Acc: 50.661\n",
            "Epoch 274: | Train Loss: 0.01031\n",
            "Val Loss: 4.85467\n",
            "Train Acc: 99.616\n",
            "Val Acc: 49.119\n",
            "Epoch 275: | Train Loss: 0.01875\n",
            "Val Loss: 4.81617\n",
            "Train Acc: 99.424\n",
            "Val Acc: 48.899\n",
            "Epoch 276: | Train Loss: 0.02410\n",
            "Val Loss: 4.65950\n",
            "Train Acc: 99.424\n",
            "Val Acc: 51.101\n",
            "Epoch 277: | Train Loss: 0.01114\n",
            "Val Loss: 4.84131\n",
            "Train Acc: 99.616\n",
            "Val Acc: 51.762\n",
            "Epoch 278: | Train Loss: 0.01285\n",
            "Val Loss: 4.99888\n",
            "Train Acc: 99.416\n",
            "Val Acc: 51.542\n",
            "Epoch 279: | Train Loss: 0.00753\n",
            "Val Loss: 4.82693\n",
            "Train Acc: 99.616\n",
            "Val Acc: 49.119\n",
            "Epoch 280: | Train Loss: 0.00952\n",
            "Val Loss: 4.82895\n",
            "Train Acc: 99.616\n",
            "Val Acc: 48.018\n",
            "Epoch 281: | Train Loss: 0.01275\n",
            "Val Loss: 4.71580\n",
            "Train Acc: 99.424\n",
            "Val Acc: 51.542\n",
            "Epoch 282: | Train Loss: 0.01346\n",
            "Val Loss: 4.88162\n",
            "Train Acc: 99.712\n",
            "Val Acc: 50.220\n",
            "Epoch 283: | Train Loss: 0.00822\n",
            "Val Loss: 4.78383\n",
            "Train Acc: 99.856\n",
            "Val Acc: 52.203\n",
            "Epoch 284: | Train Loss: 0.01390\n",
            "Val Loss: 4.70579\n",
            "Train Acc: 99.424\n",
            "Val Acc: 52.203\n",
            "Epoch 285: | Train Loss: 0.01954\n",
            "Val Loss: 4.65424\n",
            "Train Acc: 99.136\n",
            "Val Acc: 50.441\n",
            "Epoch 286: | Train Loss: 0.01338\n",
            "Val Loss: 4.87543\n",
            "Train Acc: 99.328\n",
            "Val Acc: 50.881\n",
            "Epoch 287: | Train Loss: 0.01244\n",
            "Val Loss: 4.56515\n",
            "Train Acc: 99.520\n",
            "Val Acc: 51.542\n",
            "Epoch 288: | Train Loss: 0.01532\n",
            "Val Loss: 4.74965\n",
            "Train Acc: 99.568\n",
            "Val Acc: 53.304\n",
            "Epoch 289: | Train Loss: 0.01731\n",
            "Val Loss: 4.50108\n",
            "Train Acc: 99.184\n",
            "Val Acc: 51.982\n",
            "Epoch 290: | Train Loss: 0.00869\n",
            "Val Loss: 4.88007\n",
            "Train Acc: 99.664\n",
            "Val Acc: 50.661\n",
            "Epoch 291: | Train Loss: 0.01111\n",
            "Val Loss: 4.65805\n",
            "Train Acc: 99.520\n",
            "Val Acc: 49.780\n",
            "Epoch 292: | Train Loss: 0.01261\n",
            "Val Loss: 4.91919\n",
            "Train Acc: 99.616\n",
            "Val Acc: 51.542\n",
            "Epoch 293: | Train Loss: 0.01065\n",
            "Val Loss: 4.69424\n",
            "Train Acc: 99.664\n",
            "Val Acc: 50.881\n",
            "Epoch 294: | Train Loss: 0.01143\n",
            "Val Loss: 4.86439\n",
            "Train Acc: 99.808\n",
            "Val Acc: 50.881\n",
            "Epoch 295: | Train Loss: 0.01517\n",
            "Val Loss: 4.63480\n",
            "Train Acc: 99.472\n",
            "Val Acc: 49.119\n",
            "Epoch 296: | Train Loss: 0.01096\n",
            "Val Loss: 5.02749\n",
            "Train Acc: 99.472\n",
            "Val Acc: 51.542\n",
            "Epoch 297: | Train Loss: 0.01931\n",
            "Val Loss: 4.76928\n",
            "Train Acc: 99.664\n",
            "Val Acc: 49.339\n",
            "Epoch 298: | Train Loss: 0.02608\n",
            "Val Loss: 4.87905\n",
            "Train Acc: 99.472\n",
            "Val Acc: 47.137\n",
            "Epoch 299: | Train Loss: 0.01619\n",
            "Val Loss: 4.87195\n",
            "Train Acc: 99.472\n",
            "Val Acc: 50.661\n",
            "Epoch 300: | Train Loss: 0.00934\n",
            "Val Loss: 4.65321\n",
            "Train Acc: 99.664\n",
            "Val Acc: 50.000\n",
            "\n",
            "895.139904499054\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXIRnTZTIlvG",
        "outputId": "0e96a40e-585c-4240-f0d5-24e422cea984"
      },
      "source": [
        "print(end - start)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "862.2819263935089\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uT_Fl2GXiPc"
      },
      "source": [
        "# Get Training Weights for Late fusion Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kvu7fyzY8PFD"
      },
      "source": [
        "y_train_pred_list = []\n",
        "albert_train_preds = []\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    for X_batch, _ in train_loader:\n",
        "        X_batch = X_batch.to(device)\n",
        "        y_train_pred = model(X_batch)\n",
        "        # probs = nn.Softmax(dim=1)(y_test_pred)\n",
        "        albert_train_preds.extend(y_train_pred.tolist())\n",
        "        _, y_pred_tags = torch.max(y_train_pred, dim = 1)\n",
        "        y_train_pred_list.append(y_pred_tags.cpu().numpy())\n",
        "y_train_pred_list = [a.squeeze().tolist() for a in y_train_pred_list]"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4F79UGLE8TvF",
        "outputId": "0226100d-6a1a-4ee9-ca6b-6d9a057b3950"
      },
      "source": [
        "print(albert_train_preds)\n",
        "len(albert_train_preds)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-10.492827415466309, 6.430241107940674, -3.3277971744537354], [5.339158058166504, -3.4060215950012207, -5.900485038757324], [17.838287353515625, -25.724138259887695, -10.603468894958496], [12.448497772216797, -10.349291801452637, -12.43375015258789], [-2.106818199157715, 6.903900623321533, -10.829522132873535], [7.565122127532959, -10.969015121459961, -4.610668182373047], [6.8547444343566895, -11.378409385681152, -3.5445556640625], [-5.800631999969482, 6.873424530029297, -6.498617172241211], [-10.647794723510742, 12.434248924255371, -9.806272506713867], [-8.547662734985352, -5.190649032592773, 4.990792274475098], [7.459901809692383, -7.553781509399414, -6.2474775314331055], [-7.5226359367370605, -8.286276817321777, 5.839081764221191], [-7.8271989822387695, 6.098625659942627, -4.342911720275879], [14.02364730834961, -21.20992660522461, -7.8726606369018555], [-13.94931697845459, 9.762503623962402, -6.009303569793701], [7.840201377868652, -8.074419975280762, -6.849146842956543], [-10.337258338928223, 7.226346492767334, -4.431812286376953], [-4.734475612640381, 6.322030544281006, -8.423569679260254], [8.666224479675293, -5.9552178382873535, -9.552448272705078], [10.874079704284668, -15.736557960510254, -6.931699752807617], [-9.558626174926758, 5.430910587310791, -2.956106662750244], [-2.8284881114959717, 4.299113750457764, -4.806760787963867], [17.838287353515625, -25.724138259887695, -10.603468894958496], [-27.274742126464844, 12.977316856384277, -2.6974847316741943], [10.019279479980469, -14.208151817321777, -6.1577887535095215], [-16.073665618896484, 12.265690803527832, -7.836395263671875], [-7.092403888702393, -6.644712448120117, 4.833363056182861], [-5.48675537109375, 7.908560276031494, -7.561803340911865], [-7.283411979675293, 6.974210262298584, -6.10921573638916], [-10.261528968811035, 7.838229179382324, -5.820950508117676], [7.395413875579834, -9.312141418457031, -5.0562896728515625], [-9.424330711364746, -5.726481914520264, 5.449044704437256], [-11.905296325683594, -11.04484748840332, 8.822799682617188], [-14.790603637695312, -7.473880767822266, 8.138456344604492], [14.279317855834961, -14.22532844543457, -11.398200035095215], [18.19631004333496, -24.165206909179688, -11.847738265991211], [-8.621072769165039, 7.803587436676025, -6.437317848205566], [-16.509737014770508, 15.951644897460938, -12.769012451171875], [-5.48675537109375, 7.908560276031494, -7.561803340911865], [5.826041221618652, -8.6952486038208, -3.9700310230255127], [6.536657333374023, -2.906428098678589, -9.133979797363281], [21.270044326782227, -22.446868896484375, -18.32491683959961], [-10.887458801269531, -5.181262493133545, 6.040328025817871], [12.060287475585938, -15.8449068069458, -7.768596172332764], [-4.605480194091797, 6.332579135894775, -6.954439640045166], [11.645926475524902, -11.876580238342285, -10.378730773925781], [-12.989629745483398, 10.266707420349121, -6.623069763183594], [-0.8605672717094421, 5.515394687652588, -9.852791786193848], [8.795114517211914, -11.711180686950684, -5.730846405029297], [-7.594695091247559, 6.082391262054443, -4.361800193786621], [7.9546918869018555, -14.242546081542969, -3.5324203968048096], [-5.396224021911621, 11.868857383728027, -15.988790512084961], [-26.854413986206055, 21.146284103393555, -12.526363372802734], [-10.647794723510742, 12.434248924255371, -9.806272506713867], [-17.604694366455078, 14.48685359954834, -10.546371459960938], [7.954293727874756, -6.217179775238037, -8.169193267822266], [-18.51460075378418, 15.604022026062012, -12.566503524780273], [-2.303260564804077, 4.068064212799072, -4.5194597244262695], [8.649608612060547, -9.120036125183105, -7.5752458572387695], [10.592416763305664, -17.81296157836914, -4.927392482757568], [14.628694534301758, -27.380168914794922, -5.708286285400391], [9.558029174804688, -11.855738639831543, -6.806777477264404], [7.027563571929932, -6.798065662384033, -6.887174606323242], [-7.143360137939453, 6.717846393585205, -5.176322937011719], [5.356437683105469, -5.088895797729492, -5.038539886474609], [-19.026391983032227, 11.348217010498047, -4.1962971687316895], [-12.094659805297852, -11.710270881652832, 9.028345108032227], [4.140283107757568, -6.09446382522583, -2.578439235687256], [18.021251678466797, -16.63170051574707, -16.43130874633789], [13.358892440795898, -17.291025161743164, -8.858125686645508], [-5.144034385681152, 7.580053329467773, -9.564373970031738], [-4.906809329986572, 4.899119853973389, -4.4894609451293945], [0.22276684641838074, 0.10341117531061172, -0.4178540110588074], [8.97312068939209, -7.565772533416748, -8.66447639465332], [11.201221466064453, -11.94632625579834, -8.998289108276367], [-13.53258991241455, 9.692896842956543, -6.514551639556885], [-10.256734848022461, 3.7839748859405518, -0.935243546962738], [13.632579803466797, -20.223133087158203, -8.156600952148438], [11.962982177734375, -3.746262311935425, -18.599205017089844], [-4.706685543060303, 7.494658470153809, -7.569887638092041], [13.604545593261719, -17.16191864013672, -10.72700309753418], [-9.075263977050781, -8.83381462097168, 6.661500930786133], [-5.757220268249512, 6.703151226043701, -6.564630508422852], [14.02364730834961, -21.20992660522461, -7.8726606369018555], [9.051957130432129, -15.844714164733887, -3.9492998123168945], [-8.01869010925293, 8.713883399963379, -7.757722854614258], [7.311738014221191, -8.863567352294922, -5.616972923278809], [9.035608291625977, -11.038796424865723, -6.773324489593506], [6.835726737976074, -5.023699760437012, -7.432529926300049], [5.454394340515137, -4.815492153167725, -5.051860809326172], [-7.2203450202941895, 5.347239971160889, -3.264239549636841], [9.740806579589844, -19.247055053710938, -2.9440839290618896], [7.412613868713379, -6.38263463973999, -7.126633644104004], [-15.189640045166016, 10.138237953186035, -5.218189716339111], [9.450736999511719, -13.5980806350708, -5.894375801086426], [13.632579803466797, -20.223133087158203, -8.156600952148438], [-9.84118366241455, -17.871944427490234, 10.622681617736816], [6.3953776359558105, -6.1729655265808105, -5.816994667053223], [7.764996528625488, -12.831585884094238, -3.719252586364746], [-6.9796929359436035, 4.606950759887695, -3.3782811164855957], [13.646478652954102, -28.543609619140625, -3.402714252471924], [-6.5134429931640625, 6.394641876220703, -5.185219764709473], [8.178077697753906, -10.27885913848877, -5.878335952758789], [8.128214836120605, -12.359643936157227, -4.986379146575928], [-9.33398723602295, -5.606843948364258, 5.444157123565674], [11.988961219787598, -12.883696556091309, -10.643953323364258], [-8.504932403564453, 7.952483654022217, -6.981597900390625], [-37.84723663330078, 19.707984924316406, -6.048786640167236], [8.229011535644531, -8.331793785095215, -7.193197727203369], [7.6998701095581055, -6.505009174346924, -7.103606700897217], [7.134673595428467, -7.71309757232666, -5.9680867195129395], [9.250758171081543, -8.533238410949707, -8.648527145385742], [6.4086103439331055, -9.993733406066895, -3.6734843254089355], [8.750617027282715, -12.49507999420166, -5.624958515167236], [13.604545593261719, -17.16191864013672, -10.72700309753418], [-26.7706241607666, 13.837260246276855, -4.408916473388672], [-6.622231960296631, 4.526622295379639, -2.7056424617767334], [11.703407287597656, -16.274005889892578, -7.025913715362549], [-6.10491418838501, -6.239525318145752, 4.459178924560547], [-10.339799880981445, 10.301271438598633, -9.503365516662598], [17.526689529418945, -31.735998153686523, -6.959362983703613], [-8.184568405151367, -8.519767761230469, 6.185671806335449], [8.384172439575195, -9.523811340332031, -6.429576396942139], [5.826041221618652, -8.6952486038208, -3.9700310230255127], [-6.496282577514648, 9.725188255310059, -10.453752517700195], [-8.459912300109863, -9.659894943237305, 6.967763900756836], [-5.8514909744262695, 7.14164400100708, -7.7592549324035645], [10.0723876953125, -14.789557456970215, -5.945219039916992], [14.076918601989746, -16.367626190185547, -10.975666999816895], [-9.684122085571289, 6.783024311065674, -4.272149085998535], [-7.99495792388916, 6.620176315307617, -4.343988418579102], [12.142823219299316, -18.248945236206055, -6.742952823638916], [-3.792569398880005, 5.436117649078369, -5.961348056793213], [-13.026541709899902, 16.141151428222656, -15.683297157287598], [-6.051728248596191, 4.728518962860107, -2.8524723052978516], [10.335952758789062, -10.867419242858887, -8.359572410583496], [11.722526550292969, -12.670186042785645, -9.933632850646973], [4.795630931854248, -6.708851337432861, -3.157831907272339], [-6.870338439941406, 8.821928024291992, -8.779556274414062], [9.740806579589844, -19.247055053710938, -2.9440839290618896], [9.16384506225586, -12.197443962097168, -6.356995105743408], [-30.264829635620117, 16.030315399169922, -4.652859210968018], [11.464750289916992, -11.575746536254883, -9.75704574584961], [7.496209621429443, -14.92968463897705, -2.929572820663452], [14.057329177856445, -25.540599822998047, -5.897387981414795], [-39.79096984863281, 22.059144973754883, -7.277474403381348], [-4.661600112915039, 6.970088481903076, -6.842704772949219], [-5.760527610778809, -10.947892189025879, 6.379888534545898], [-5.307422637939453, 8.014395713806152, -8.764427185058594], [9.55926513671875, -8.968976974487305, -8.468971252441406], [-4.016763210296631, 3.917935848236084, -3.7793428897857666], [10.45529556274414, -12.869181632995605, -7.774377822875977], [-3.494274377822876, 4.8894267082214355, -5.147516250610352], [9.251121520996094, -13.031824111938477, -6.055791854858398], [5.218318462371826, -3.349174976348877, -6.394394874572754], [-3.6232049465179443, 11.040884971618652, -16.054466247558594], [-4.7158203125, 6.065824031829834, -7.764530181884766], [13.315649032592773, -14.104796409606934, -10.89581298828125], [-12.130512237548828, 7.546111583709717, -3.504016637802124], [16.835607528686523, -29.295948028564453, -7.32181453704834], [-3.0112252235412598, 5.090948104858398, -6.337133407592773], [6.424762725830078, -7.273589134216309, -5.089213848114014], [-7.106760025024414, 6.710391521453857, -5.866595268249512], [15.979040145874023, -34.371604919433594, -4.849285125732422], [9.013355255126953, -1.5585253238677979, -15.772124290466309], [7.496209621429443, -14.92968463897705, -2.929572820663452], [-8.353057861328125, 6.611860752105713, -4.646827697753906], [-17.12482452392578, 6.582282543182373, -0.6803547739982605], [9.130045890808105, -9.898277282714844, -7.962809085845947], [9.77199649810791, -9.436358451843262, -9.417659759521484], [10.778921127319336, -16.340110778808594, -6.010115623474121], [14.378263473510742, -27.062040328979492, -4.701389789581299], [-15.631535530090332, 12.314770698547363, -8.117238998413086], [-7.573925971984863, 15.09584903717041, -19.86185073852539], [-13.172759056091309, 12.808011054992676, -11.501554489135742], [-6.121986389160156, -7.3530683517456055, 4.828707218170166], [-12.309320449829102, 10.538203239440918, -7.419451713562012], [-14.159124374389648, 11.269610404968262, -7.64931583404541], [5.769932746887207, -8.095166206359863, -4.18861198425293], [-5.762598991394043, 6.0683674812316895, -5.809243202209473], [8.286117553710938, -7.5315022468566895, -7.849813938140869], [-10.552349090576172, 7.17145299911499, -4.676444053649902], [-19.165815353393555, -22.122802734375, 16.2482967376709], [-8.564319610595703, 6.9248576164245605, -5.032937049865723], [-8.259200096130371, 8.416196823120117, -8.47054672241211], [10.464518547058105, -14.809738159179688, -6.213345050811768], [-5.247201919555664, 4.1235880851745605, -3.172031879425049], [9.35760498046875, -11.358017921447754, -6.930395126342773], [7.520524024963379, -6.4865193367004395, -7.1169939041137695], [-12.615842819213867, 9.768522262573242, -6.831482887268066], [-8.243976593017578, 6.36051082611084, -4.103107929229736], [-12.560985565185547, -7.500161647796631, 7.494596481323242], [-29.92291259765625, 16.716197967529297, -6.649824142456055], [9.035608291625977, -11.038796424865723, -6.773324489593506], [-17.919082641601562, 9.60156536102295, -4.4745659828186035], [13.553155899047852, -8.901749610900879, -14.662593841552734], [10.33625602722168, -13.766057968139648, -7.017155647277832], [-10.11301040649414, -15.493630409240723, 9.894705772399902], [-10.778450012207031, 9.127413749694824, -5.903804779052734], [-18.832983016967773, 12.392298698425293, -7.433306694030762], [4.4303131103515625, -3.1208882331848145, -5.072040557861328], [-2.6500396728515625, 8.165192604064941, -12.225929260253906], [8.809793472290039, -12.993678092956543, -5.134390830993652], [-8.602420806884766, -14.255818367004395, 9.119112014770508], [13.315649032592773, -14.104796409606934, -10.89581298828125], [13.233055114746094, -5.881181240081787, -18.375526428222656], [-11.074193954467773, 11.396933555603027, -11.943887710571289], [5.70024299621582, -6.161524295806885, -4.894780158996582], [-3.2133257389068604, 6.405241966247559, -7.812558650970459], [4.668062210083008, -2.150050163269043, -6.162070274353027], [6.808491230010986, -10.577404022216797, -4.079163074493408], [4.510572910308838, -4.736263275146484, -4.325773239135742], [8.951467514038086, -10.398550987243652, -6.869524955749512], [-20.45323944091797, 8.422747611999512, -1.3123136758804321], [-28.616561889648438, 13.59127140045166, -2.7192981243133545], [-13.212812423706055, 7.534635543823242, -4.172411918640137], [-7.143360137939453, 6.717846393585205, -5.176322937011719], [10.647565841674805, -16.14261245727539, -6.171962261199951], [6.007291793823242, -7.307216644287109, -4.714445114135742], [-5.856383800506592, 6.7595438957214355, -6.622043609619141], [0.22276684641838074, 0.10341117531061172, -0.4178540110588074], [-17.79195213317871, 9.414685249328613, -3.375209331512451], [-3.7751543521881104, 3.5219335556030273, -3.2226061820983887], [-19.026391983032227, 11.348217010498047, -4.1962971687316895], [-5.844655513763428, 3.9524788856506348, -4.034974098205566], [-37.84723663330078, 19.707984924316406, -6.048786640167236], [-14.563329696655273, 11.392426490783691, -8.075016021728516], [14.057329177856445, -25.540599822998047, -5.897387981414795], [-9.424330711364746, -5.726481914520264, 5.449044704437256], [-3.4454128742218018, 5.757242679595947, -5.962325572967529], [-10.290448188781738, 10.767644882202148, -9.665335655212402], [-10.242557525634766, 13.419488906860352, -13.282798767089844], [14.279317855834961, -14.22532844543457, -11.398200035095215], [12.448497772216797, -10.349291801452637, -12.43375015258789], [9.740806579589844, -19.247055053710938, -2.9440839290618896], [-22.960783004760742, 10.901471138000488, -2.134521245956421], [-29.92291259765625, 16.716197967529297, -6.649824142456055], [-10.290448188781738, 10.767644882202148, -9.665335655212402], [-6.320391654968262, 5.609457969665527, -4.471625328063965], [-8.726936340332031, -7.983395099639893, 6.374201774597168], [-3.2671890258789062, 3.854069232940674, -3.5997817516326904], [-12.280599594116211, 7.787750720977783, -5.432510852813721], [-9.040148735046387, 5.303361415863037, -3.1674489974975586], [-15.041820526123047, -11.836148262023926, 10.080251693725586], [7.364887714385986, -9.720860481262207, -5.313720226287842], [7.496209621429443, -14.92968463897705, -2.929572820663452], [10.019279479980469, -14.208151817321777, -6.1577887535095215], [-5.115837097167969, -6.784493923187256, 4.417018413543701], [-6.9270195960998535, 6.89312219619751, -6.180122375488281], [0.22276684641838074, 0.10341117531061172, -0.4178540110588074], [-10.191398620605469, 6.695157051086426, -4.155752182006836], [7.3816046714782715, -7.043989181518555, -6.798469543457031], [-8.772141456604004, -5.48861837387085, 5.1980390548706055], [10.674448013305664, -13.988927841186523, -7.015342712402344], [-10.290448188781738, 10.767644882202148, -9.665335655212402], [3.1540310382843018, -3.0212316513061523, -3.119725465774536], [9.35760498046875, -11.358017921447754, -6.930395126342773], [-4.999420166015625, 3.6861369609832764, -2.748501777648926], [7.7775115966796875, -12.803902626037598, -3.738840103149414], [-8.790660858154297, 6.046139240264893, -3.915195941925049], [-5.541615009307861, 9.226128578186035, -11.171825408935547], [-11.19202995300293, 8.680680274963379, -5.388477325439453], [9.939355850219727, -16.613513946533203, -4.295341968536377], [7.366508960723877, -4.309683799743652, -8.570446014404297], [-5.099119186401367, 4.984870433807373, -4.642736434936523], [-5.98799467086792, 4.15494966506958, -3.154359817504883], [6.8099517822265625, -6.778563976287842, -6.250368595123291], [10.33625602722168, -13.766057968139648, -7.017155647277832], [13.39968490600586, -19.646347045898438, -7.963436126708984], [6.964578628540039, -9.662760734558105, -4.78239107131958], [-8.889117240905762, 12.787650108337402, -15.307732582092285], [12.510683059692383, -17.55218505859375, -8.106313705444336], [-9.684122085571289, 6.783024311065674, -4.272149085998535], [9.35760498046875, -11.358017921447754, -6.930395126342773], [-11.697338104248047, 7.412383556365967, -4.315227031707764], [0.22276684641838074, 0.10341117531061172, -0.4178540110588074], [5.659021377563477, -5.521759510040283, -5.661589622497559], [8.098910331726074, -10.042872428894043, -5.7061967849731445], [8.222244262695312, -6.848881244659424, -8.241806030273438], [10.162086486816406, -14.754308700561523, -5.951993465423584], [-5.810072898864746, 8.706777572631836, -9.635246276855469], [-25.775903701782227, 12.19196605682373, -2.3707938194274902], [-19.97602653503418, 12.462350845336914, -6.761974334716797], [-10.227804183959961, 9.710480690002441, -7.654151916503906], [7.779860496520996, -9.189706802368164, -5.659964561462402], [15.089961051940918, -21.8094482421875, -8.779350280761719], [-2.57049298286438, 6.174069404602051, -8.692939758300781], [-4.306393623352051, 4.822900772094727, -4.10449743270874], [9.55926513671875, -8.968976974487305, -8.468971252441406], [11.962982177734375, -3.746262311935425, -18.599205017089844], [-4.858401298522949, 6.120352745056152, -7.761970043182373], [-10.869637489318848, 9.68714427947998, -8.036062240600586], [-5.465967178344727, -12.209031105041504, 6.667773246765137], [12.357913970947266, -19.512731552124023, -6.500783920288086], [19.318647384643555, -19.517200469970703, -16.26953125], [-9.699939727783203, 7.954380512237549, -5.511702060699463], [9.724196434020996, -7.6137003898620605, -9.772671699523926], [10.306835174560547, -12.997950553894043, -7.168400287628174], [14.009965896606445, -12.32047176361084, -13.412952423095703], [-15.751145362854004, -8.5690336227417, 9.355066299438477], [-3.0178868770599365, 8.869610786437988, -14.35114860534668], [-3.3870794773101807, 6.574244022369385, -7.75770378112793], [12.060287475585938, -15.8449068069458, -7.768596172332764], [-2.6500396728515625, 8.165192604064941, -12.225929260253906], [-12.326301574707031, 10.570594787597656, -8.227862358093262], [11.550528526306152, -22.33078384399414, -3.9988772869110107], [-5.339793682098389, 4.9750823974609375, -5.296778678894043], [-36.654205322265625, 16.496776580810547, -2.0949347019195557], [-6.881565093994141, 4.490762233734131, -3.0249156951904297], [9.507768630981445, -9.355646133422852, -8.17386531829834], [10.95701789855957, -15.147369384765625, -7.383087158203125], [15.979040145874023, -34.371604919433594, -4.849285125732422], [5.772918701171875, -6.478123664855957, -4.8878493309021], [8.48111629486084, -5.940098762512207, -9.25161361694336], [-9.424330711364746, -5.726481914520264, 5.449044704437256], [-7.728233814239502, 15.093358039855957, -18.882112503051758], [-3.283047914505005, -4.830611705780029, 2.9230542182922363], [-12.158710479736328, 8.762070655822754, -5.515639781951904], [-26.35738754272461, 14.528714179992676, -4.3634185791015625], [-19.165815353393555, -22.122802734375, 16.2482967376709], [-3.2133257389068604, 6.405241966247559, -7.812558650970459], [-25.186979293823242, -3.995305061340332, 9.870248794555664], [13.632579803466797, -20.223133087158203, -8.156600952148438], [-4.7114081382751465, 6.338507175445557, -5.938821792602539], [7.438446998596191, -7.18048620223999, -6.618453502655029], [-5.367438316345215, -14.32066822052002, 7.335988998413086], [-8.504932403564453, 7.952483654022217, -6.981597900390625], [-9.820694923400879, 10.282920837402344, -7.794319152832031], [14.657220840454102, -28.67003631591797, -4.8174543380737305], [6.564144134521484, -10.273599624633789, -3.567183017730713], [6.709505081176758, -9.591019630432129, -4.132943153381348], [13.553155899047852, -8.901749610900879, -14.662593841552734], [-26.25931167602539, 21.167367935180664, -14.962072372436523], [-7.0437912940979, 8.55385684967041, -9.47353744506836], [-20.126163482666016, 11.044363021850586, -4.9137187004089355], [-9.76881217956543, -5.940968990325928, 5.6018571853637695], [-7.143360137939453, 6.717846393585205, -5.176322937011719], [10.33625602722168, -13.766057968139648, -7.017155647277832], [-2.5322978496551514, 5.463643550872803, -8.114592552185059], [8.194221496582031, -12.08778190612793, -4.519360542297363], [-26.541433334350586, 12.364949226379395, -2.3347623348236084], [-15.751145362854004, -8.5690336227417, 9.355066299438477], [-4.069384574890137, 4.816013813018799, -4.5272932052612305], [-11.907999038696289, 7.298376083374023, -3.528620481491089], [-10.337258338928223, 7.226346492767334, -4.431812286376953], [-8.459912300109863, -9.659894943237305, 6.967763900756836], [-11.665376663208008, 14.853099822998047, -15.56821060180664], [-6.826601505279541, 5.35768985748291, -3.6630072593688965], [-7.951520919799805, 6.5158209800720215, -6.015078544616699], [-18.51460075378418, 15.604022026062012, -12.566503524780273], [-6.563270568847656, 4.23034143447876, -2.6847121715545654], [14.657220840454102, -28.67003631591797, -4.8174543380737305], [-13.680051803588867, -11.271105766296387, 9.314187049865723], [-5.810072898864746, 8.706777572631836, -9.635246276855469], [7.364887714385986, -9.720860481262207, -5.313720226287842], [13.604545593261719, -17.16191864013672, -10.72700309753418], [-8.493236541748047, 4.938760280609131, -3.1127734184265137], [-7.092403888702393, -6.644712448120117, 4.833363056182861], [-7.313728332519531, 4.387152194976807, -2.844252824783325], [-4.920523166656494, 3.6481428146362305, -2.83329439163208], [-9.426904678344727, 5.685746669769287, -2.535645008087158], [7.954293727874756, -6.217179775238037, -8.169193267822266], [7.395413875579834, -9.312141418457031, -5.0562896728515625], [-3.373504400253296, 8.74220085144043, -12.522331237792969], [-6.5044732093811035, 5.1623854637146, -4.721511363983154], [-7.2203450202941895, 5.347239971160889, -3.264239549636841], [-2.9665353298187256, 4.43968391418457, -5.329307556152344], [6.709505081176758, -9.591019630432129, -4.132943153381348], [-4.7114081382751465, 6.338507175445557, -5.938821792602539], [-11.152751922607422, 7.773117542266846, -4.293296813964844], [-4.460765361785889, 4.874350070953369, -4.772940158843994], [6.791418552398682, -11.677483558654785, -3.173628330230713], [13.538376808166504, -16.383785247802734, -9.9639310836792], [14.908467292785645, -20.5523681640625, -9.921972274780273], [-9.554960250854492, 9.423227310180664, -8.578622817993164], [-11.889568328857422, 5.775449752807617, -2.1682040691375732], [-13.187914848327637, -3.130825996398926, 5.584185600280762], [15.747912406921387, -28.255409240722656, -6.258203506469727], [-13.712591171264648, -5.960197925567627, 6.965120792388916], [9.684289932250977, -15.090508460998535, -4.925569534301758], [8.001921653747559, -13.058855056762695, -4.17803955078125], [9.403413772583008, -16.944271087646484, -3.693189859390259], [-6.870338439941406, 8.821928024291992, -8.779556274414062], [-14.290937423706055, 8.16196346282959, -3.8845391273498535], [-2.2781078815460205, 3.9564666748046875, -4.254044532775879], [11.877137184143066, -17.957569122314453, -6.681894302368164], [6.907169342041016, -6.516016483306885, -6.2589921951293945], [-20.867761611938477, 9.953587532043457, -3.3356456756591797], [-2.5092737674713135, 7.333230495452881, -10.448657035827637], [-12.400014877319336, -4.858269214630127, 6.127224922180176], [10.443245887756348, -14.383490562438965, -6.4572625160217285], [-9.057987213134766, -6.452313423156738, 5.581906318664551], [-3.2356433868408203, 6.361391067504883, -7.679746627807617], [-6.202801704406738, 6.234927654266357, -5.881304740905762], [-15.751145362854004, -8.5690336227417, 9.355066299438477], [-7.687220573425293, -7.2679877281188965, 5.538692474365234], [-5.191629409790039, 6.1027512550354, -4.770295143127441], [-5.757220268249512, 6.703151226043701, -6.564630508422852], [-6.776309967041016, 6.031853675842285, -5.124009132385254], [9.706975936889648, -11.1325044631958, -7.7085442543029785], [-8.612483024597168, 8.444588661193848, -6.773785591125488], [10.771350860595703, -17.23667335510254, -5.582174301147461], [-7.175439357757568, 9.376989364624023, -9.35865592956543], [13.035839080810547, -22.47117042541504, -6.017362594604492], [15.321916580200195, -19.392391204833984, -10.597338676452637], [8.20064926147461, -11.091933250427246, -5.5890655517578125], [7.762805461883545, -8.962477684020996, -5.97571325302124], [-7.594695091247559, 6.082391262054443, -4.361800193786621], [18.282649993896484, -30.16025161743164, -8.902725219726562], [-3.1836161613464355, 6.468957424163818, -8.135700225830078], [-22.814462661743164, -4.0467400550842285, 8.921432495117188], [-8.394216537475586, 7.911179065704346, -5.711674690246582], [13.843236923217773, -15.74173641204834, -10.754179000854492], [0.22276684641838074, 0.10341117531061172, -0.4178540110588074], [6.564144134521484, -10.273599624633789, -3.567183017730713], [27.636919021606445, -54.73030090332031, -7.634807109832764], [-3.373504400253296, 8.74220085144043, -12.522331237792969], [-7.891449928283691, 6.57757043838501, -5.365339756011963], [-8.611481666564941, 5.904804706573486, -3.5569565296173096], [-15.568107604980469, 10.223296165466309, -5.392012596130371], [-11.98570728302002, 9.637831687927246, -6.413572788238525], [-10.647794723510742, 12.434248924255371, -9.806272506713867], [17.952280044555664, -26.059476852416992, -10.736275672912598], [9.854516983032227, -11.530826568603516, -7.584815979003906], [4.658669948577881, -7.138916015625, -3.1479053497314453], [-7.577391147613525, 7.939591884613037, -6.640144348144531], [-16.430898666381836, 9.228426933288574, -3.4958271980285645], [-11.849143981933594, 7.76315450668335, -4.1272125244140625], [-9.696791648864746, 5.800116062164307, -2.800469398498535], [-13.026541709899902, 16.141151428222656, -15.683297157287598], [-12.588136672973633, 9.575165748596191, -6.454342842102051], [-53.101558685302734, 29.793846130371094, -8.908967018127441], [-3.722830057144165, 4.286098003387451, -4.326161861419678], [10.647565841674805, -16.14261245727539, -6.171962261199951], [8.79952621459961, -12.955757141113281, -6.46574068069458], [-10.647794723510742, 12.434248924255371, -9.806272506713867], [-32.45539093017578, 13.837347030639648, -1.46541166305542], [5.70024299621582, -6.161524295806885, -4.894780158996582], [12.209151268005371, -13.859098434448242, -9.75901985168457], [-12.615842819213867, 9.768522262573242, -6.831482887268066], [-4.988400459289551, 5.364867687225342, -4.920291900634766], [-9.032696723937988, -10.389758110046387, 7.341872215270996], [6.96628475189209, -3.32926869392395, -9.227481842041016], [-11.011493682861328, 6.3412370681762695, -2.873697280883789], [-13.212812423706055, 7.534635543823242, -4.172411918640137], [-8.171263694763184, -10.102745056152344, 6.996148109436035], [10.43596363067627, -12.225510597229004, -8.634552001953125], [12.510683059692383, -17.55218505859375, -8.106313705444336], [-11.329961776733398, -11.362900733947754, 8.488693237304688], [-4.664931297302246, 4.32725715637207, -3.2569923400878906], [-8.621072769165039, 7.803587436676025, -6.437317848205566], [-5.163269996643066, 8.838242530822754, -10.88486385345459], [-14.384961128234863, 8.905146598815918, -3.7722270488739014], [10.814484596252441, -14.473967552185059, -7.082087516784668], [-20.365449905395508, -3.218794345855713, 7.920854568481445], [9.04275131225586, -6.175381183624268, -9.641511917114258], [9.874959945678711, -13.102139472961426, -6.269874095916748], [-12.590143203735352, -3.9080703258514404, 6.001544952392578], [-2.5236613750457764, 4.430443286895752, -4.8431572914123535], [7.764996528625488, -12.831585884094238, -3.719252586364746], [-5.0980072021484375, 6.520993709564209, -6.220221519470215], [12.997407913208008, -12.438645362854004, -11.63497543334961], [-10.647794723510742, 12.434248924255371, -9.806272506713867], [9.333253860473633, -10.204903602600098, -7.646515846252441], [-9.51955509185791, 5.126938343048096, -2.113555908203125], [12.824928283691406, -19.447301864624023, -6.6877241134643555], [-12.806116104125977, -18.91510009765625, 12.435369491577148], [14.212135314941406, -15.070418357849121, -11.626275062561035], [14.400750160217285, -13.587477684020996, -13.119390487670898], [11.703407287597656, -16.274005889892578, -7.025913715362549], [-13.932621002197266, 10.56214427947998, -5.77390718460083], [12.300361633300781, -13.700508117675781, -9.764280319213867], [9.201311111450195, -16.811782836914062, -3.312986135482788], [-10.952750205993652, 7.375445365905762, -4.459314346313477], [8.098910331726074, -10.042872428894043, -5.7061967849731445], [-28.755739212036133, 15.48177433013916, -4.414236068725586], [7.864064693450928, -7.808862209320068, -7.060039520263672], [9.471944808959961, -7.548049449920654, -9.614391326904297], [13.632579803466797, -20.223133087158203, -8.156600952148438], [-5.52677583694458, 5.67743444442749, -4.596512317657471], [-3.6276323795318604, 9.523289680480957, -13.881612777709961], [10.63825798034668, -12.378142356872559, -8.208850860595703], [11.037687301635742, -17.997804641723633, -5.5287346839904785], [-11.625724792480469, 6.94088888168335, -3.288175106048584], [-6.9270195960998535, 6.89312219619751, -6.180122375488281], [13.553155899047852, -8.901749610900879, -14.662593841552734], [7.366508960723877, -4.309683799743652, -8.570446014404297], [9.02287769317627, -11.857726097106934, -6.61026668548584], [-8.072593688964844, -4.463984966278076, 4.490083694458008], [13.564435005187988, -20.789939880371094, -7.329296588897705], [9.55926513671875, -8.968976974487305, -8.468971252441406], [8.496620178222656, -9.784466743469238, -6.517873764038086], [7.126773834228516, -9.401732444763184, -5.154427528381348], [-5.344265460968018, 5.023643970489502, -3.743826389312744], [8.843368530273438, -3.992794990539551, -11.15319538116455], [-3.0030364990234375, 4.883960723876953, -6.479983329772949], [-18.796539306640625, 7.83461856842041, -0.6449383497238159], [-19.44541358947754, 9.377127647399902, -2.625213146209717], [-9.330070495605469, -7.526871204376221, 6.201337814331055], [-14.242755889892578, 9.892614364624023, -5.316074371337891], [-7.577391147613525, 7.939591884613037, -6.640144348144531], [-11.747425079345703, 7.744273662567139, -4.563365459442139], [-8.592670440673828, 6.160412311553955, -4.465765953063965], [13.020544052124023, -22.577529907226562, -5.937955856323242], [-6.870338439941406, 8.821928024291992, -8.779556274414062], [-16.329673767089844, 9.077624320983887, -2.953723669052124], [6.9487762451171875, -3.086669683456421, -9.025230407714844], [11.828384399414062, -19.74256134033203, -5.43366813659668], [-10.884033203125, 9.821869850158691, -7.073429107666016], [15.229829788208008, -23.91033935546875, -8.374670028686523], [-10.979669570922852, 11.11892032623291, -9.87299919128418], [-6.945735931396484, -7.0883355140686035, 5.183561325073242], [-11.533618927001953, -5.3324408531188965, 6.167666912078857], [-10.69714641571045, 8.016753196716309, -6.5341620445251465], [7.311738014221191, -8.863567352294922, -5.616972923278809], [-11.435653686523438, -7.30566930770874, 7.062258720397949], [-10.172792434692383, 9.243882179260254, -6.5365824699401855], [-7.45115852355957, 5.112936496734619, -3.224701404571533], [-10.290448188781738, 10.767644882202148, -9.665335655212402], [-20.07496452331543, 11.933845520019531, -4.073879241943359], [-13.172759056091309, 12.808011054992676, -11.501554489135742], [-13.94931697845459, 9.762503623962402, -6.009303569793701], [-3.2303755283355713, 6.513327598571777, -7.98296594619751], [10.647565841674805, -16.14261245727539, -6.171962261199951], [-8.217263221740723, -15.765883445739746, 9.517398834228516], [-3.0237555503845215, 4.109670162200928, -4.476978302001953], [-10.509571075439453, 7.060370922088623, -3.443561553955078], [10.282209396362305, -16.601774215698242, -5.240932941436768], [8.178077697753906, -10.27885913848877, -5.878335952758789], [5.494208335876465, -6.15114164352417, -4.362939357757568], [17.526689529418945, -31.735998153686523, -6.959362983703613], [-10.686765670776367, -6.400233745574951, 6.241691589355469], [9.552451133728027, -13.105748176574707, -6.025030612945557], [-19.96579933166504, 14.226853370666504, -7.400768280029297], [-7.988516807556152, 15.126683235168457, -18.982086181640625], [-11.04652214050293, 8.017669677734375, -5.759982109069824], [-19.026391983032227, 11.348217010498047, -4.1962971687316895], [7.522019386291504, -8.123238563537598, -6.732319355010986], [-29.07779884338379, 13.010220527648926, -2.814716339111328], [6.973389625549316, -1.8566642999649048, -10.99606704711914], [-9.609931945800781, 5.769722938537598, -2.9502480030059814], [4.339999198913574, -3.437385320663452, -4.769549369812012], [-17.41774559020996, 7.797772407531738, -2.4791533946990967], [-12.989629745483398, 10.266707420349121, -6.623069763183594], [-4.277419567108154, 5.53081750869751, -5.792609214782715], [-11.05699634552002, 5.651363849639893, -2.286989450454712], [10.592416763305664, -17.81296157836914, -4.927392482757568], [-15.751145362854004, -8.5690336227417, 9.355066299438477], [11.811230659484863, -13.079110145568848, -9.972692489624023], [4.668062210083008, -2.150050163269043, -6.162070274353027], [-2.7653372287750244, 6.807243347167969, -10.008376121520996], [-7.487483501434326, 7.1159892082214355, -6.890527725219727], [-4.837325096130371, 6.572618007659912, -9.243644714355469], [-5.76597785949707, 4.1943793296813965, -3.295989513397217], [-8.602420806884766, -14.255818367004395, 9.119112014770508], [6.143988609313965, -9.279328346252441, -3.5737223625183105], [8.55196762084961, -10.364469528198242, -6.346224784851074], [-14.663522720336914, 8.347284317016602, -3.7034354209899902], [-13.026541709899902, 16.141151428222656, -15.683297157287598], [-16.11286163330078, 9.868535041809082, -4.1506452560424805], [5.943950653076172, -8.085816383361816, -4.090007305145264], [20.98638916015625, -39.599151611328125, -7.01345682144165], [-6.512392044067383, 5.455392360687256, -4.699226379394531], [-9.33398723602295, -5.606843948364258, 5.444157123565674], [9.684289932250977, -15.090508460998535, -4.925569534301758], [-20.45323944091797, 8.422747611999512, -1.3123136758804321], [-26.35738754272461, 14.528714179992676, -4.3634185791015625], [-6.145122528076172, -9.794736862182617, 5.953055381774902], [-2.9002346992492676, 7.653080463409424, -11.716377258300781], [-10.290448188781738, 10.767644882202148, -9.665335655212402], [12.647379875183105, -15.305985450744629, -9.559041976928711], [-8.08690357208252, 7.891030311584473, -6.804013729095459], [-11.141548156738281, 7.554872035980225, -4.601336479187012], [8.993757247924805, -12.184961318969727, -5.798817157745361], [6.96628475189209, -3.32926869392395, -9.227481842041016], [-12.35909652709961, 8.708593368530273, -4.861235618591309], [-2.756770610809326, 5.363918304443359, -6.211790084838867], [-4.320773124694824, 3.72348952293396, -3.3374624252319336], [-4.189117431640625, 4.821987628936768, -5.090269565582275], [-24.40938377380371, 15.02043628692627, -7.396740436553955], [7.412613868713379, -6.38263463973999, -7.126633644104004], [9.457594871520996, -12.611895561218262, -6.260798454284668], [-8.529878616333008, -10.251368522644043, 7.150699615478516], [-22.814462661743164, -4.0467400550842285, 8.921432495117188], [-9.82600212097168, 6.839812755584717, -3.8800668716430664], [-7.421207427978516, -9.0897855758667, 6.135613918304443], [7.895440101623535, -12.3458833694458, -4.359139442443848], [17.246902465820312, -32.127437591552734, -6.405094146728516], [-7.440505504608154, 5.4207305908203125, -3.291098117828369], [-7.594695091247559, 6.082391262054443, -4.361800193786621], [-31.564170837402344, 16.066619873046875, -4.217386722564697], [-10.313743591308594, 10.055869102478027, -7.695013046264648], [-21.063135147094727, 10.757161140441895, -2.967198371887207], [10.918723106384277, -3.9924192428588867, -16.279449462890625], [-9.095673561096191, 5.574628829956055, -2.4147145748138428], [5.180056571960449, -5.496469497680664, -4.746403694152832], [-19.238021850585938, 11.714761734008789, -6.916616916656494], [5.454394340515137, -4.815492153167725, -5.051860809326172], [-6.7163496017456055, 5.232845783233643, -4.900230407714844], [0.22276684641838074, 0.10341117531061172, -0.4178540110588074], [12.647379875183105, -15.305985450744629, -9.559041976928711], [11.828384399414062, -19.74256134033203, -5.43366813659668], [9.684289932250977, -15.090508460998535, -4.925569534301758], [19.380550384521484, -26.127178192138672, -12.629068374633789], [-8.217263221740723, -15.765883445739746, 9.517398834228516], [-15.751145362854004, -8.5690336227417, 9.355066299438477], [-7.8271989822387695, 6.098625659942627, -4.342911720275879], [7.764996528625488, -12.831585884094238, -3.719252586364746], [7.027563571929932, -6.798065662384033, -6.887174606323242], [6.8099517822265625, -6.778563976287842, -6.250368595123291], [9.333253860473633, -10.204903602600098, -7.646515846252441], [8.862930297851562, -6.70359468460083, -9.767234802246094], [-20.30230140686035, 10.0260648727417, -3.7694592475891113], [-10.273422241210938, -10.493144035339355, 7.9741058349609375], [-19.2990665435791, 9.333680152893066, -2.601158618927002], [-8.829365730285645, -5.895798206329346, 5.378607273101807], [8.750617027282715, -12.49507999420166, -5.624958515167236], [-8.564319610595703, 6.9248576164245605, -5.032937049865723], [15.836101531982422, -24.802499771118164, -8.39187240600586], [-7.935407638549805, 6.978679656982422, -5.0035505294799805], [12.959781646728516, -11.36289119720459, -11.809081077575684], [-4.211877346038818, 4.977309703826904, -4.783956527709961], [8.55196762084961, -10.364469528198242, -6.346224784851074], [-16.073665618896484, 12.265690803527832, -7.836395263671875], [-14.277657508850098, 9.203424453735352, -5.422886848449707], [13.43130111694336, -21.540252685546875, -6.384504795074463], [-4.901155471801758, 7.091223239898682, -8.985586166381836], [-3.2671890258789062, 3.854069232940674, -3.5997817516326904], [-14.290937423706055, 8.16196346282959, -3.8845391273498535], [-18.007617950439453, 11.743609428405762, -7.734055519104004], [-7.71732234954834, 5.4852423667907715, -3.3794124126434326], [-10.941976547241211, -7.341639995574951, 6.714064598083496], [-5.197445869445801, 6.7357916831970215, -8.116875648498535], [10.294763565063477, -11.66895580291748, -8.0269775390625], [11.297133445739746, -10.667693138122559, -9.970539093017578], [7.412613868713379, -6.38263463973999, -7.126633644104004], [-11.031660079956055, 6.8133320808410645, -3.436915874481201], [-2.35886549949646, 4.017256259918213, -4.297575950622559], [9.471944808959961, -7.548049449920654, -9.614391326904297], [11.545655250549316, -8.794795989990234, -11.889654159545898], [-18.51460075378418, 15.604022026062012, -12.566503524780273], [-6.320391654968262, 5.609457969665527, -4.471625328063965], [-15.222896575927734, 13.36240005493164, -11.690691947937012], [14.620966911315918, -11.566195487976074, -14.709465026855469], [-5.274232864379883, 5.347879409790039, -4.72579288482666], [-12.821471214294434, 7.5692267417907715, -3.6191320419311523], [-5.76597785949707, 4.1943793296813965, -3.295989513397217], [7.296306610107422, -14.5585298538208, -2.2928638458251953], [10.432065963745117, -12.408717155456543, -8.042882919311523], [13.358892440795898, -17.291025161743164, -8.858125686645508], [-5.52677583694458, 5.67743444442749, -4.596512317657471], [-5.264927387237549, 5.572635173797607, -4.928565502166748], [-8.772141456604004, -5.48861837387085, 5.1980390548706055], [-8.973766326904297, 6.4771504402160645, -4.3560380935668945], [9.024347305297852, -7.957961559295654, -8.427305221557617], [-12.823736190795898, -8.350852012634277, 8.085399627685547], [6.808491230010986, -10.577404022216797, -4.079163074493408], [-10.809972763061523, 8.764067649841309, -5.739048480987549], [-21.530670166015625, 12.568848609924316, -6.446889877319336], [-7.528538227081299, -5.332338809967041, 4.728240966796875], [-12.823736190795898, -8.350852012634277, 8.085399627685547], [-10.193629264831543, 10.05153751373291, -7.939033031463623], [-2.9624269008636475, 5.759120464324951, -7.6140522956848145], [-21.68229866027832, 15.866714477539062, -9.021239280700684], [11.073751449584961, -12.095343589782715, -8.5455322265625], [10.592416763305664, -17.81296157836914, -4.927392482757568], [9.035608291625977, -11.038796424865723, -6.773324489593506], [-7.846216201782227, 10.425283432006836, -9.605466842651367], [-6.699471950531006, 7.2031025886535645, -7.212128639221191], [-11.087639808654785, -6.628819942474365, 6.495594024658203], [-1.423811435699463, 5.375197410583496, -8.753922462463379], [12.818896293640137, -11.074740409851074, -11.768596649169922], [7.412613868713379, -6.38263463973999, -7.126633644104004], [-12.130512237548828, 7.546111583709717, -3.504016637802124], [11.318078994750977, -8.966285705566406, -11.399480819702148], [6.3635149002075195, -8.528822898864746, -4.587957382202148], [-4.858401298522949, 6.120352745056152, -7.761970043182373], [-11.625724792480469, 6.94088888168335, -3.288175106048584], [-7.092403888702393, -6.644712448120117, 4.833363056182861], [4.825490951538086, -0.9164479374885559, -8.19427490234375], [8.000248908996582, -7.129655361175537, -7.762881278991699], [-29.680130004882812, 16.250511169433594, -6.6247172355651855], [-6.061100959777832, 5.490784168243408, -3.7338905334472656], [8.015324592590332, -8.138378143310547, -6.8440704345703125], [13.68143081665039, -9.349896430969238, -15.450399398803711], [-4.493061065673828, 5.39553689956665, -5.211410999298096], [-19.4110107421875, 12.368189811706543, -6.993350982666016], [-14.30998706817627, 7.998920917510986, -3.635176658630371], [-8.790660858154297, 6.046139240264893, -3.915195941925049], [-10.680704116821289, -10.906342506408691, 8.241575241088867], [7.387996196746826, -10.056954383850098, -5.353874206542969], [-3.181556463241577, 7.453078746795654, -9.888419151306152], [-12.400014877319336, -4.858269214630127, 6.127224922180176], [9.403413772583008, -16.944271087646484, -3.693189859390259], [-10.185839653015137, 6.4820146560668945, -3.770463228225708], [-6.59006404876709, 5.95145845413208, -4.642788887023926], [7.864064693450928, -7.808862209320068, -7.060039520263672], [-23.3689022064209, 13.943624496459961, -5.696510314941406], [13.564435005187988, -20.789939880371094, -7.329296588897705], [7.440948963165283, -5.549636363983154, -7.921567916870117], [-11.152751922607422, 7.773117542266846, -4.293296813964844], [14.657220840454102, -28.67003631591797, -4.8174543380737305], [-13.932621002197266, 10.56214427947998, -5.77390718460083], [-11.697338104248047, 7.412383556365967, -4.315227031707764], [-11.957499504089355, 8.041516304016113, -5.753830909729004], [-12.361688613891602, 8.019493103027344, -4.144661903381348], [5.659021377563477, -5.521759510040283, -5.661589622497559], [18.141315460205078, -31.218019485473633, -8.297379493713379], [14.378263473510742, -27.062040328979492, -4.701389789581299], [-2.176103115081787, 5.1213603019714355, -8.065449714660645], [-9.375809669494629, -8.93602466583252, 6.924137115478516], [12.757074356079102, -10.649426460266113, -12.54272174835205], [-4.9255805015563965, 4.341986179351807, -4.2839035987854], [10.860738754272461, -20.40045166015625, -3.7735342979431152], [-2.484898090362549, 5.834445476531982, -7.457779884338379], [-2.8284881114959717, 4.299113750457764, -4.806760787963867], [9.552451133728027, -13.105748176574707, -6.025030612945557], [-20.12642478942871, 12.010908126831055, -5.180844783782959], [-3.373504400253296, 8.74220085144043, -12.522331237792969], [-24.40938377380371, 15.02043628692627, -7.396740436553955], [-7.542028427124023, 7.845306396484375, -6.356692790985107], [9.024347305297852, -7.957961559295654, -8.427305221557617], [8.697599411010742, -8.918854713439941, -7.673382759094238], [-10.604166984558105, 4.466442584991455, -1.1350033283233643], [0.22276684641838074, 0.10341117531061172, -0.4178540110588074], [7.53324031829834, -7.420950412750244, -6.670927047729492], [4.171440601348877, -1.8809900283813477, -5.684330940246582], [-4.920523166656494, 3.6481428146362305, -2.83329439163208], [-24.075698852539062, 14.19619083404541, -5.144304275512695], [-8.781538009643555, 7.405655384063721, -5.109467506408691], [-6.512392044067383, 5.455392360687256, -4.699226379394531], [-19.026391983032227, 11.348217010498047, -4.1962971687316895], [17.911542892456055, -18.78268814086914, -15.23791217803955], [9.343389511108398, -13.796745300292969, -5.625461578369141], [-7.998856544494629, 8.344819068908691, -6.439383029937744], [11.136575698852539, -10.589862823486328, -10.830810546875], [9.013355255126953, -1.5585253238677979, -15.772124290466309], [-36.654205322265625, 16.496776580810547, -2.0949347019195557], [-15.568107604980469, 10.223296165466309, -5.392012596130371], [12.490029335021973, -15.48830795288086, -8.817659378051758], [-0.4707459807395935, 4.229969501495361, -8.440925598144531], [6.907169342041016, -6.516016483306885, -6.2589921951293945], [-14.242755889892578, 9.892614364624023, -5.316074371337891], [-9.810052871704102, 8.206070899963379, -5.848387718200684], [6.884319305419922, -13.028105735778809, -2.602914333343506], [9.130045890808105, -9.898277282714844, -7.962809085845947], [-7.228796005249023, 7.6951375007629395, -5.984646797180176], [-9.674443244934082, 5.669002532958984, -3.3834948539733887], [6.29313325881958, -5.560166358947754, -6.236698627471924], [-5.810072898864746, 8.706777572631836, -9.635246276855469], [13.315649032592773, -14.104796409606934, -10.89581298828125], [-5.180670738220215, 6.52745246887207, -8.404475212097168], [7.366508960723877, -4.309683799743652, -8.570446014404297], [-3.419745445251465, 4.197172164916992, -4.134328365325928], [8.913345336914062, -11.967484474182129, -5.964664936065674], [-16.42848777770996, 11.695425987243652, -7.160297870635986], [4.7972636222839355, -5.60092306137085, -3.983715057373047], [8.222244262695312, -6.848881244659424, -8.241806030273438], [-9.424330711364746, -5.726481914520264, 5.449044704437256], [15.169191360473633, -18.947750091552734, -11.048746109008789], [9.403413772583008, -16.944271087646484, -3.693189859390259], [-11.699951171875, 11.332581520080566, -9.234959602355957], [-19.933368682861328, 14.099431991577148, -8.813840866088867], [-7.092403888702393, -6.644712448120117, 4.833363056182861], [7.207337379455566, -2.7371327877044678, -10.97809886932373], [-8.112235069274902, 7.097407341003418, -4.906929969787598], [-26.83246612548828, 14.91518497467041, -5.145045280456543], [-7.728233814239502, 15.093358039855957, -18.882112503051758], [11.155434608459473, -18.94989013671875, -5.560288429260254], [-12.615842819213867, 9.768522262573242, -6.831482887268066], [-39.79096984863281, 22.059144973754883, -7.277474403381348], [12.201915740966797, -16.81549072265625, -7.950252532958984], [11.352771759033203, -13.262528419494629, -8.291987419128418], [-9.095673561096191, 5.574628829956055, -2.4147145748138428], [14.279020309448242, -16.454761505126953, -10.667078018188477], [-2.462367057800293, 4.9150238037109375, -6.0705389976501465], [19.392467498779297, -34.86536407470703, -7.7275776863098145], [-8.884737014770508, 6.224996566772461, -3.761603355407715], [-4.613589286804199, 9.39669418334961, -11.661660194396973], [14.382746696472168, -23.637516021728516, -7.080314636230469], [13.358892440795898, -17.291025161743164, -8.858125686645508], [-7.936378479003906, 6.123579502105713, -3.85888934135437], [9.403413772583008, -16.944271087646484, -3.693189859390259], [-5.762598991394043, 6.0683674812316895, -5.809243202209473], [6.007291793823242, -7.307216644287109, -4.714445114135742], [-7.465376377105713, 6.4769206047058105, -5.129316806793213], [-29.1523494720459, 19.520170211791992, -10.949952125549316], [6.564352035522461, -7.027089595794678, -5.4074249267578125], [-0.8605672717094421, 5.515394687652588, -9.852791786193848], [-8.876420974731445, 8.451470375061035, -6.946828842163086], [-2.2781078815460205, 3.9564666748046875, -4.254044532775879], [-7.009609222412109, 8.25522518157959, -8.023900032043457], [-12.576417922973633, 10.677210807800293, -7.388948917388916], [27.636919021606445, -54.73030090332031, -7.634807109832764], [7.412613868713379, -6.38263463973999, -7.126633644104004], [6.564352035522461, -7.027089595794678, -5.4074249267578125], [15.747912406921387, -28.255409240722656, -6.258203506469727], [-14.1431303024292, 8.159032821655273, -4.160513401031494], [6.96628475189209, -3.32926869392395, -9.227481842041016], [18.51108741760254, -28.5725154876709, -10.39033031463623], [-6.699471950531006, 7.2031025886535645, -7.212128639221191], [-7.793857097625732, 7.530531406402588, -6.072155952453613], [-16.509737014770508, 15.951644897460938, -12.769012451171875], [-10.209125518798828, -5.42315149307251, 5.567877769470215], [19.556447982788086, -21.294342041015625, -15.061574935913086], [9.507768630981445, -9.355646133422852, -8.17386531829834], [6.889252185821533, -3.329808235168457, -8.595972061157227], [-8.459912300109863, -9.659894943237305, 6.967763900756836], [-6.116085529327393, 4.998836994171143, -3.5646517276763916], [9.578780174255371, -17.67113494873047, -3.9656777381896973], [8.194221496582031, -12.08778190612793, -4.519360542297363], [9.552451133728027, -13.105748176574707, -6.025030612945557], [-40.30009078979492, 16.620433807373047, -1.0158941745758057], [-7.081482887268066, 8.5834379196167, -7.840932846069336], [9.130045890808105, -9.898277282714844, -7.962809085845947], [-16.059459686279297, 9.28173542022705, -3.4178972244262695], [-12.309320449829102, 10.538203239440918, -7.419451713562012], [-11.298538208007812, 8.82294750213623, -6.146461486816406], [10.366434097290039, -16.15155792236328, -5.44295597076416], [-14.1431303024292, 8.159032821655273, -4.160513401031494], [-15.751145362854004, -8.5690336227417, 9.355066299438477], [8.001921653747559, -13.058855056762695, -4.17803955078125], [9.507768630981445, -9.355646133422852, -8.17386531829834], [-45.423370361328125, 26.014238357543945, -10.442476272583008], [12.824928283691406, -19.447301864624023, -6.6877241134643555], [-8.171263694763184, -10.102745056152344, 6.996148109436035], [11.27564811706543, -16.383319854736328, -6.579980850219727], [-4.810981750488281, -6.98474645614624, 4.355222225189209], [13.155441284179688, -16.898109436035156, -8.701558113098145], [6.865355491638184, -5.385744571685791, -7.06129264831543], [7.387996196746826, -10.056954383850098, -5.353874206542969], [-0.15528751909732819, 3.21099853515625, -6.782529830932617], [-40.30009078979492, 16.620433807373047, -1.0158941745758057], [-7.05748176574707, -13.786398887634277, 7.717203617095947], [17.961416244506836, -28.005029678344727, -9.623071670532227], [-8.829927444458008, 6.762425899505615, -5.380227088928223], [-4.5761518478393555, 5.223642349243164, -4.102651596069336], [16.199270248413086, -19.48625946044922, -11.707465171813965], [11.297969818115234, -12.905900001525879, -8.645700454711914], [8.931991577148438, -9.844730377197266, -7.442870616912842], [18.141315460205078, -31.218019485473633, -8.297379493713379], [-28.327938079833984, 10.736077308654785, -0.8914132118225098], [-3.373504400253296, 8.74220085144043, -12.522331237792969], [10.591897964477539, -12.049052238464355, -8.351846694946289], [-3.6232049465179443, 11.040884971618652, -16.054466247558594], [10.688766479492188, -13.352842330932617, -7.78139591217041], [-3.483671188354492, 4.027109622955322, -4.007823944091797], [15.975332260131836, -23.25510597229004, -9.656908988952637], [-8.753682136535645, 9.261652946472168, -8.838659286499023], [-33.27729797363281, 18.036026000976562, -7.993965148925781], [-6.6265974044799805, 5.633667945861816, -3.7892355918884277], [-2.835531234741211, 5.078425884246826, -5.667599678039551], [-12.255428314208984, -7.400235652923584, 7.483814716339111], [10.758951187133789, -18.168167114257812, -5.168050289154053], [-8.105362892150879, 6.664349555969238, -4.816871166229248], [8.744858741760254, -15.932971000671387, -3.721620798110962], [-6.665478229522705, 5.86922025680542, -4.103260040283203], [-12.733295440673828, -5.685854434967041, 6.46628475189209], [6.424762725830078, -7.273589134216309, -5.089213848114014], [7.728481292724609, -7.858255386352539, -6.834259986877441], [-7.817025184631348, 5.121356964111328, -3.141516923904419], [-7.081482887268066, 8.5834379196167, -7.840932846069336], [-2.6598479747772217, 4.8540496826171875, -6.156943321228027], [3.8073277473449707, -0.8071917295455933, -6.902437686920166], [-3.3165605068206787, 4.1221699714660645, -4.253275394439697], [-5.163269996643066, 8.838242530822754, -10.88486385345459], [-29.680130004882812, 16.250511169433594, -6.6247172355651855], [-23.588685989379883, 14.434614181518555, -6.018947601318359], [-8.753682136535645, 9.261652946472168, -8.838659286499023], [-20.10309410095215, 10.583704948425293, -2.82285213470459], [8.496620178222656, -9.784466743469238, -6.517873764038086], [-8.003580093383789, 2.761381149291992, -0.6215971112251282], [0.22276684641838074, 0.10341117531061172, -0.4178540110588074], [-4.623034477233887, 8.907349586486816, -10.793784141540527], [-5.284435272216797, 6.634659290313721, -6.797201156616211], [9.450736999511719, -13.5980806350708, -5.894375801086426], [-8.243976593017578, 6.36051082611084, -4.103107929229736], [-5.52677583694458, 5.67743444442749, -4.596512317657471], [-4.306393623352051, 4.822900772094727, -4.10449743270874], [13.553155899047852, -8.901749610900879, -14.662593841552734], [5.827681541442871, -4.999284744262695, -6.097939968109131], [-14.983366966247559, 10.143556594848633, -5.817974090576172], [-19.2990665435791, 9.333680152893066, -2.601158618927002], [-17.79195213317871, 9.414685249328613, -3.375209331512451], [-5.844655513763428, 3.9524788856506348, -4.034974098205566], [8.007932662963867, -5.856138706207275, -8.343062400817871], [8.502449035644531, -9.6544771194458, -6.778806686401367], [12.357913970947266, -19.512731552124023, -6.500783920288086], [-4.2934770584106445, 5.329757213592529, -4.860855579376221], [-15.564414978027344, 8.137990951538086, -3.0871617794036865], [-9.424330711364746, -5.726481914520264, 5.449044704437256], [-10.290448188781738, 10.767644882202148, -9.665335655212402], [-6.58245849609375, 6.435299396514893, -5.529486179351807], [17.069169998168945, -22.99913215637207, -10.693055152893066], [-6.283868789672852, 3.641838550567627, -2.8548965454101562], [18.676185607910156, -38.861724853515625, -4.202635765075684], [-13.932621002197266, 10.56214427947998, -5.77390718460083], [-15.041820526123047, -11.836148262023926, 10.080251693725586], [-12.201953887939453, 8.77600383758545, -5.1745500564575195], [-3.283047914505005, -4.830611705780029, 2.9230542182922363], [12.07658576965332, -17.713224411010742, -7.519526481628418], [6.791418552398682, -11.677483558654785, -3.173628330230713], [15.169191360473633, -18.947750091552734, -11.048746109008789], [-10.941976547241211, -7.341639995574951, 6.714064598083496], [16.83244514465332, -30.398502349853516, -6.7961883544921875], [-53.101558685302734, 29.793846130371094, -8.908967018127441], [-8.243976593017578, 6.36051082611084, -4.103107929229736], [6.494298934936523, -5.093862056732178, -6.753664016723633], [-24.56758689880371, 17.477888107299805, -11.577400207519531], [-6.342885971069336, 6.162067890167236, -6.44816780090332], [-11.416658401489258, -9.276297569274902, 7.880576133728027], [-5.088716506958008, 4.369619846343994, -3.4218716621398926], [13.43130111694336, -21.540252685546875, -6.384504795074463], [10.063286781311035, -7.752983570098877, -10.26196002960205], [11.201221466064453, -11.94632625579834, -8.998289108276367], [-5.367597579956055, 6.4992241859436035, -6.717539310455322], [11.464750289916992, -11.575746536254883, -9.75704574584961], [6.709505081176758, -9.591019630432129, -4.132943153381348], [8.110705375671387, -6.57235860824585, -8.556428909301758], [-12.821471214294434, 7.5692267417907715, -3.6191320419311523], [-11.141548156738281, 7.554872035980225, -4.601336479187012], [8.503676414489746, -12.944801330566406, -4.754755020141602], [-13.026541709899902, 16.141151428222656, -15.683297157287598], [-5.307251930236816, 5.918064594268799, -5.363537788391113], [-9.252718925476074, 7.078148365020752, -5.240120887756348], [-8.547150611877441, 11.086396217346191, -10.411958694458008], [-9.609931945800781, 5.769722938537598, -2.9502480030059814], [-8.105362892150879, 6.664349555969238, -4.816871166229248], [-10.985706329345703, 5.4156575202941895, -2.4654974937438965], [0.22276684641838074, 0.10341117531061172, -0.4178540110588074], [17.952280044555664, -26.059476852416992, -10.736275672912598], [-8.772141456604004, -5.48861837387085, 5.1980390548706055], [-7.728233814239502, 15.093358039855957, -18.882112503051758], [8.922565460205078, -12.8650484085083, -5.4270219802856445], [13.275178909301758, -22.55467414855957, -5.8063764572143555], [-8.347772598266602, -7.893719673156738, 5.979922294616699], [19.318647384643555, -19.517200469970703, -16.26953125], [-23.218381881713867, 12.940552711486816, -4.350881576538086], [-7.383498668670654, 8.8286714553833, -8.34068775177002], [-11.570262908935547, 8.190951347351074, -4.321943283081055], [-12.400014877319336, -4.858269214630127, 6.127224922180176], [8.171032905578613, -5.752447605133057, -8.641716003417969], [-5.49771785736084, 6.672813892364502, -6.688780307769775], [-7.283411979675293, 6.974210262298584, -6.10921573638916], [-8.876420974731445, 8.451470375061035, -6.946828842163086], [-8.072593688964844, -4.463984966278076, 4.490083694458008], [7.678919792175293, -9.845968246459961, -6.062156677246094], [-5.757220268249512, 6.703151226043701, -6.564630508422852], [-7.146871089935303, 5.975586891174316, -5.13693904876709], [12.829208374023438, -15.627589225769043, -9.138487815856934], [-17.456586837768555, 11.179892539978027, -6.534125804901123], [-7.846216201782227, 10.425283432006836, -9.605466842651367], [-10.686765670776367, -6.400233745574951, 6.241691589355469], [9.819831848144531, -15.632006645202637, -5.084641456604004], [-5.628459930419922, 8.811103820800781, -9.485428810119629], [-4.725827693939209, 3.5699210166931152, -2.7356810569763184], [-10.209434509277344, 8.371160507202148, -5.892823696136475], [4.551292419433594, -3.3009369373321533, -5.005941867828369], [8.775425910949707, -16.942134857177734, -3.330202341079712], [20.98638916015625, -39.599151611328125, -7.01345682144165], [-4.211877346038818, 4.977309703826904, -4.783956527709961], [13.564435005187988, -20.789939880371094, -7.329296588897705], [-6.5044732093811035, 5.1623854637146, -4.721511363983154], [17.069169998168945, -22.99913215637207, -10.693055152893066], [-10.869637489318848, 9.68714427947998, -8.036062240600586], [-13.773265838623047, 5.5431013107299805, -0.7837145328521729], [-9.84118366241455, -17.871944427490234, 10.622681617736816], [-10.884033203125, 9.821869850158691, -7.073429107666016], [-3.8911163806915283, 4.943990707397461, -4.987673759460449], [-5.284435272216797, 6.634659290313721, -6.797201156616211], [7.412613868713379, -6.38263463973999, -7.126633644104004], [-11.493094444274902, 9.14470100402832, -7.7760491371154785], [-4.320773124694824, 3.72348952293396, -3.3374624252319336], [8.16683292388916, -5.609935283660889, -8.772762298583984], [-13.712591171264648, -5.960197925567627, 6.965120792388916], [-14.276376724243164, 10.493353843688965, -6.467752456665039], [5.218318462371826, -3.349174976348877, -6.394394874572754], [11.828384399414062, -19.74256134033203, -5.43366813659668], [-3.2133257389068604, 6.405241966247559, -7.812558650970459], [-7.288652420043945, 7.879174709320068, -8.282702445983887], [-7.459534168243408, 10.543694496154785, -10.08046817779541], [-8.822628021240234, 9.412476539611816, -9.363343238830566], [8.544132232666016, -14.52919864654541, -3.8561339378356934], [-11.087639808654785, -6.628819942474365, 6.495594024658203], [0.22276684641838074, 0.10341117531061172, -0.4178540110588074], [8.241020202636719, -3.727515697479248, -10.792553901672363], [10.366434097290039, -16.15155792236328, -5.44295597076416], [-6.051728248596191, 4.728518962860107, -2.8524723052978516], [-5.0980072021484375, 6.520993709564209, -6.220221519470215], [-9.424330711364746, -5.726481914520264, 5.449044704437256], [-10.032841682434082, 10.207243919372559, -8.093523025512695], [13.646478652954102, -28.543609619140625, -3.402714252471924], [-39.79096984863281, 22.059144973754883, -7.277474403381348], [-11.689748764038086, 9.912739753723145, -7.687429428100586], [-9.40842056274414, 6.752116680145264, -4.109596252441406], [14.620966911315918, -11.566195487976074, -14.709465026855469], [-10.079084396362305, -10.403279304504395, 7.574409484863281], [-11.689748764038086, 9.912739753723145, -7.687429428100586], [-8.158622741699219, 7.934462547302246, -6.436416149139404], [-6.9796929359436035, 4.606950759887695, -3.3782811164855957], [-18.007617950439453, 11.743609428405762, -7.734055519104004], [-9.478103637695312, 7.473667621612549, -5.595801830291748], [-10.273422241210938, -10.493144035339355, 7.9741058349609375], [-6.665478229522705, 5.86922025680542, -4.103260040283203], [13.632579803466797, -20.223133087158203, -8.156600952148438], [-11.19202995300293, 8.680680274963379, -5.388477325439453], [9.740806579589844, -19.247055053710938, -2.9440839290618896], [-10.778450012207031, 9.127413749694824, -5.903804779052734], [11.020820617675781, -14.825328826904297, -6.82685661315918], [10.09360408782959, -4.674990177154541, -14.825336456298828], [-11.141548156738281, 7.554872035980225, -4.601336479187012], [15.186223030090332, -17.935955047607422, -10.905014991760254], [-19.2990665435791, 9.333680152893066, -2.601158618927002], [-12.576417922973633, 10.677210807800293, -7.388948917388916], [4.171440601348877, -1.8809900283813477, -5.684330940246582], [9.291881561279297, -14.663579940795898, -4.547352313995361], [8.222244262695312, -6.848881244659424, -8.241806030273438], [8.271251678466797, -9.330910682678223, -6.711079120635986], [-14.70942211151123, -8.44132137298584, 8.410669326782227], [10.88534164428711, -17.02437973022461, -5.502456188201904], [-11.473048210144043, -9.194245338439941, 7.8932342529296875], [-15.751145362854004, -8.5690336227417, 9.355066299438477], [-10.856404304504395, 5.914386749267578, -2.552563190460205], [10.287894248962402, -12.85303020477295, -7.342006206512451], [13.194997787475586, -20.050674438476562, -7.352902889251709], [14.652389526367188, -12.258933067321777, -14.061123847961426], [-5.307422637939453, 8.014395713806152, -8.764427185058594], [-7.935698509216309, -9.14145565032959, 6.446652412414551], [-7.648664951324463, -7.371931552886963, 5.6172027587890625], [-9.684122085571289, 6.783024311065674, -4.272149085998535], [-4.858401298522949, 6.120352745056152, -7.761970043182373], [16.442424774169922, -18.69131088256836, -12.731391906738281], [7.509078025817871, -4.777816295623779, -8.212198257446289], [10.443245887756348, -14.383490562438965, -6.4572625160217285], [9.435863494873047, -4.607083797454834, -12.139050483703613], [-14.384961128234863, 8.905146598815918, -3.7722270488739014], [-13.712591171264648, -5.960197925567627, 6.965120792388916], [9.02783203125, -11.176905632019043, -7.051296234130859], [-5.48675537109375, 7.908560276031494, -7.561803340911865], [7.895440101623535, -12.3458833694458, -4.359139442443848], [-4.493061065673828, 5.39553689956665, -5.211410999298096], [-1.6070106029510498, 4.189625263214111, -5.574999809265137], [8.143359184265137, -4.370612621307373, -9.92990493774414], [-9.246733665466309, 7.3986735343933105, -6.082607746124268], [-13.384278297424316, 6.86798620223999, -2.4812657833099365], [-7.687220573425293, -7.2679877281188965, 5.538692474365234], [-3.5025687217712402, 5.100644111633301, -5.590760231018066], [-38.44618606567383, -8.276463508605957, 17.1540584564209], [12.510683059692383, -17.55218505859375, -8.106313705444336], [-4.069384574890137, 4.816013813018799, -4.5272932052612305], [-20.12642478942871, 12.010908126831055, -5.180844783782959], [-18.832983016967773, 12.392298698425293, -7.433306694030762], [11.442588806152344, -10.592442512512207, -10.427997589111328], [-7.681231498718262, 4.908383846282959, -3.2384462356567383], [-10.509571075439453, 7.060370922088623, -3.443561553955078], [-29.07779884338379, 13.010220527648926, -2.814716339111328], [7.728481292724609, -7.858255386352539, -6.834259986877441], [11.318078994750977, -8.966285705566406, -11.399480819702148], [-9.040148735046387, 5.303361415863037, -3.1674489974975586], [23.149587631225586, -30.174301147460938, -15.549097061157227], [12.975536346435547, -9.135769844055176, -13.903026580810547], [-8.363926887512207, -6.416116237640381, 5.332829475402832], [19.392467498779297, -34.86536407470703, -7.7275776863098145], [-5.292626857757568, 6.979321002960205, -8.381546020507812], [-21.68229866027832, 15.866714477539062, -9.021239280700684], [-4.016763210296631, 3.917935848236084, -3.7793428897857666], [10.674448013305664, -13.988927841186523, -7.015342712402344], [-13.680051803588867, -11.271105766296387, 9.314187049865723], [8.750617027282715, -12.49507999420166, -5.624958515167236], [11.352771759033203, -13.262528419494629, -8.291987419128418], [-11.05699634552002, 5.651363849639893, -2.286989450454712], [17.017126083374023, -17.710323333740234, -15.15506362915039], [-9.375809669494629, -8.93602466583252, 6.924137115478516], [-21.68229866027832, 15.866714477539062, -9.021239280700684], [11.703407287597656, -16.274005889892578, -7.025913715362549], [-4.016763210296631, 3.917935848236084, -3.7793428897857666], [6.791418552398682, -11.677483558654785, -3.173628330230713], [-14.802305221557617, 8.096672058105469, -2.814469337463379], [12.969608306884766, -19.90664291381836, -6.932753562927246], [5.385076522827148, -2.2225918769836426, -7.587765216827393], [9.430841445922852, -10.439338684082031, -7.10772180557251], [-10.856404304504395, 5.914386749267578, -2.552563190460205], [13.68143081665039, -9.349896430969238, -15.450399398803711], [-14.684957504272461, 12.99361515045166, -11.230224609375], [-11.387872695922852, 5.957265377044678, -2.3587186336517334], [-8.564319610595703, 6.9248576164245605, -5.032937049865723], [12.38165283203125, -13.536505699157715, -10.142057418823242], [-3.483671188354492, 4.027109622955322, -4.007823944091797], [10.43596363067627, -12.225510597229004, -8.634552001953125], [-11.04652214050293, 8.017669677734375, -5.759982109069824], [-9.843096733093262, -10.325392723083496, 7.544674396514893], [-3.2357335090637207, 7.156976222991943, -10.282371520996094], [-12.590143203735352, -3.9080703258514404, 6.001544952392578], [-9.320619583129883, 7.459369659423828, -6.464052200317383], [-5.865166664123535, -8.228116989135742, 5.3361005783081055], [-18.235389709472656, 15.69333553314209, -10.717330932617188], [13.739002227783203, -20.37224578857422, -8.144184112548828], [7.7775115966796875, -12.803902626037598, -3.738840103149414], [13.553155899047852, -8.901749610900879, -14.662593841552734], [-36.654205322265625, 16.496776580810547, -2.0949347019195557], [8.774736404418945, -11.869736671447754, -5.948441505432129], [-7.228796005249023, 7.6951375007629395, -5.984646797180176], [4.973596572875977, -3.7430553436279297, -5.688329696655273], [-7.744747638702393, 4.909225940704346, -2.528547763824463], [-6.145122528076172, -9.794736862182617, 5.953055381774902], [9.654419898986816, -9.403717041015625, -8.57494068145752], [-6.9270195960998535, 6.89312219619751, -6.180122375488281], [-4.133981227874756, 6.674174785614014, -6.9158525466918945], [-10.979669570922852, 11.11892032623291, -9.87299919128418], [4.4690470695495605, -4.4513630867004395, -4.7488179206848145], [7.4925432205200195, -7.947486400604248, -5.833086967468262], [-26.742109298706055, 15.1139554977417, -6.795065879821777], [16.675506591796875, -17.750442504882812, -14.151086807250977], [-14.563329696655273, 11.392426490783691, -8.075016021728516], [8.54144287109375, -15.254521369934082, -3.630765914916992], [-7.303631782531738, -10.309927940368652, 6.608153820037842], [-10.079084396362305, -10.403279304504395, 7.574409484863281], [-30.264829635620117, 16.030315399169922, -4.652859210968018], [6.486898899078369, -9.484633445739746, -4.40077018737793], [-10.985706329345703, 5.4156575202941895, -2.4654974937438965], [-6.258078575134277, 7.237476825714111, -6.097898483276367], [-10.778450012207031, 9.127413749694824, -5.903804779052734], [4.825490951538086, -0.9164479374885559, -8.19427490234375], [-9.684122085571289, 6.783024311065674, -4.272149085998535], [19.556447982788086, -21.294342041015625, -15.061574935913086], [11.352771759033203, -13.262528419494629, -8.291987419128418], [-10.503238677978516, 8.856213569641113, -6.582061290740967], [-1.284037709236145, 5.262775897979736, -8.247698783874512], [-1.4105372428894043, 3.4411113262176514, -4.829916000366211], [17.42658233642578, -29.491352081298828, -7.934643268585205], [-7.092403888702393, -6.644712448120117, 4.833363056182861], [-10.242557525634766, 13.419488906860352, -13.282798767089844], [-16.852872848510742, 10.908287048339844, -4.78411340713501], [-6.328278541564941, 5.77228307723999, -4.588986873626709], [8.098910331726074, -10.042872428894043, -5.7061967849731445], [-10.341577529907227, -6.406616687774658, 6.104247093200684], [-24.61438751220703, 18.303470611572266, -10.706388473510742], [16.661596298217773, -15.4862060546875, -16.17884635925293], [10.95701789855957, -15.147369384765625, -7.383087158203125], [-12.638143539428711, 6.187277317047119, -2.2358438968658447], [-12.130512237548828, 7.546111583709717, -3.504016637802124], [-36.654205322265625, 16.496776580810547, -2.0949347019195557], [19.825490951538086, -23.72612762451172, -15.243282318115234], [12.142823219299316, -18.248945236206055, -6.742952823638916], [-7.566719055175781, 6.743184566497803, -6.492243766784668], [-31.564170837402344, 16.066619873046875, -4.217386722564697], [6.074582099914551, -10.589287757873535, -3.025987386703491], [12.413690567016602, -7.4759087562561035, -14.052116394042969], [-5.831843852996826, 6.673238277435303, -6.429149627685547], [-9.699939727783203, 7.954380512237549, -5.511702060699463], [-6.619622230529785, 4.797318458557129, -3.229048728942871], [10.778921127319336, -16.340110778808594, -6.010115623474121], [-8.531839370727539, -13.714486122131348, 8.264421463012695], [-20.07496452331543, 11.933845520019531, -4.073879241943359], [11.318078994750977, -8.966285705566406, -11.399480819702148], [-5.48675537109375, 7.908560276031494, -7.561803340911865], [10.785383224487305, -18.548694610595703, -5.089953422546387], [-7.129870414733887, 5.2151570320129395, -3.3282341957092285], [13.358892440795898, -17.291025161743164, -8.858125686645508], [12.307700157165527, -16.938209533691406, -7.275630474090576], [7.764996528625488, -12.831585884094238, -3.719252586364746], [10.443245887756348, -14.383490562438965, -6.4572625160217285], [-14.838781356811523, 8.5407075881958, -3.8353028297424316], [-11.625724792480469, 6.94088888168335, -3.288175106048584], [-8.993075370788574, 7.7987380027771, -5.427196979522705], [-4.016763210296631, 3.917935848236084, -3.7793428897857666], [14.620966911315918, -11.566195487976074, -14.709465026855469], [-10.509571075439453, 7.060370922088623, -3.443561553955078], [-6.803225040435791, 7.265015602111816, -6.59169340133667], [10.98049545288086, -9.455120086669922, -10.544576644897461], [-18.51460075378418, 15.604022026062012, -12.566503524780273], [11.550528526306152, -22.33078384399414, -3.9988772869110107], [-4.462897300720215, 4.769344329833984, -4.018381118774414], [10.335952758789062, -10.867419242858887, -8.359572410583496], [-12.130512237548828, 7.546111583709717, -3.504016637802124], [-5.088716506958008, 4.369619846343994, -3.4218716621398926], [-2.0114426612854004, 5.101272106170654, -8.448081016540527], [-12.615842819213867, 9.768522262573242, -6.831482887268066], [-0.8915429711341858, 4.541992664337158, -7.72123384475708], [12.829208374023438, -15.627589225769043, -9.138487815856934], [13.464397430419922, -19.932823181152344, -8.046276092529297], [9.819831848144531, -15.632006645202637, -5.084641456604004], [-13.426349639892578, -6.871109485626221, 7.54543399810791], [-3.494274377822876, 4.8894267082214355, -5.147516250610352], [-10.337258338928223, 7.226346492767334, -4.431812286376953], [21.270044326782227, -22.446868896484375, -18.32491683959961], [9.756420135498047, -17.56523895263672, -4.406274795532227], [-11.465059280395508, 8.034244537353516, -5.395780086517334], [-6.116085529327393, 4.998836994171143, -3.5646517276763916], [-9.458377838134766, 6.673965930938721, -4.46345853805542], [-5.0980072021484375, 6.520993709564209, -6.220221519470215], [-5.144034385681152, 7.580053329467773, -9.564373970031738], [-7.601970195770264, 5.031371116638184, -3.261989116668701], [12.364490509033203, -15.39237117767334, -9.240829467773438], [11.217155456542969, -13.312935829162598, -8.264169692993164], [-13.94931697845459, 9.762503623962402, -6.009303569793701], [-22.92376136779785, 12.65185546875, -5.393691539764404], [-3.2133257389068604, 6.405241966247559, -7.812558650970459], [6.032380104064941, -4.116967678070068, -6.971258640289307], [-13.85314655303955, 7.6827874183654785, -2.681816577911377], [14.01398754119873, -20.881879806518555, -8.265955924987793], [-7.009609222412109, 8.25522518157959, -8.023900032043457], [12.060287475585938, -15.8449068069458, -7.768596172332764], [-14.80284309387207, 10.398669242858887, -5.221007347106934], [-7.542028427124023, 7.845306396484375, -6.356692790985107], [14.532262802124023, -18.506893157958984, -9.906270980834961], [-10.079084396362305, -10.403279304504395, 7.574409484863281], [7.438446998596191, -7.18048620223999, -6.618453502655029], [-12.361688613891602, 8.019493103027344, -4.144661903381348], [-12.576417922973633, 10.677210807800293, -7.388948917388916], [10.912918090820312, -18.80520248413086, -5.520962238311768], [-4.999420166015625, 3.6861369609832764, -2.748501777648926], [-8.612483024597168, 8.444588661193848, -6.773785591125488], [10.860738754272461, -20.40045166015625, -3.7735342979431152], [9.291881561279297, -14.663579940795898, -4.547352313995361], [-5.52726936340332, 4.714402198791504, -4.428869247436523], [13.14248275756836, -7.793320178985596, -14.704935073852539], [4.360757827758789, -3.7432608604431152, -5.205264091491699], [-13.212812423706055, 7.534635543823242, -4.172411918640137], [-8.570018768310547, 7.004744052886963, -4.936870574951172], [-10.884033203125, 9.821869850158691, -7.073429107666016], [-38.44618606567383, -8.276463508605957, 17.1540584564209], [-11.333234786987305, 10.346920013427734, -8.344152450561523], [-4.4201483726501465, 3.8016135692596436, -3.1220362186431885], [-3.6232049465179443, 11.040884971618652, -16.054466247558594], [19.017532348632812, -14.477068901062012, -20.05084800720215], [-9.095673561096191, 5.574628829956055, -2.4147145748138428], [5.803066253662109, -3.718872547149658, -7.024952411651611], [-5.197445869445801, 6.7357916831970215, -8.116875648498535], [-5.192178726196289, 4.991812229156494, -4.476449966430664], [15.747912406921387, -28.255409240722656, -6.258203506469727], [-7.313728332519531, 4.387152194976807, -2.844252824783325], [-4.837325096130371, 6.572618007659912, -9.243644714355469], [-25.25655174255371, 13.626238822937012, -4.974329471588135], [7.496209621429443, -14.92968463897705, -2.929572820663452], [-12.864911079406738, 10.193706512451172, -8.407234191894531], [9.756420135498047, -17.56523895263672, -4.406274795532227], [7.438446998596191, -7.18048620223999, -6.618453502655029], [-12.261157989501953, 10.468713760375977, -7.9317450523376465], [12.33880615234375, -11.184233665466309, -11.260007858276367], [14.378263473510742, -27.062040328979492, -4.701389789581299], [7.731569766998291, -2.9657304286956787, -10.594829559326172], [-9.554960250854492, 9.423227310180664, -8.578622817993164], [-4.2775163650512695, 4.8727498054504395, -3.9155960083007812], [-15.041820526123047, -11.836148262023926, 10.080251693725586], [7.438446998596191, -7.18048620223999, -6.618453502655029], [-2.7608802318573, 4.4029998779296875, -4.577863693237305], [-6.450241565704346, 5.58679723739624, -4.585660934448242], [-7.106760025024414, 6.710391521453857, -5.866595268249512], [28.848201751708984, -44.460182189941406, -15.146627426147461], [16.199270248413086, -19.48625946044922, -11.707465171813965], [13.315649032592773, -14.104796409606934, -10.89581298828125], [-10.509571075439453, 7.060370922088623, -3.443561553955078], [9.874959945678711, -13.102139472961426, -6.269874095916748], [-5.844655513763428, 3.9524788856506348, -4.034974098205566], [-20.515182495117188, 13.576449394226074, -7.418042182922363], [7.296306610107422, -14.5585298538208, -2.2928638458251953], [-10.918292045593262, 6.855649471282959, -3.4400038719177246], [14.076918601989746, -16.367626190185547, -10.975666999816895], [-8.158622741699219, 7.934462547302246, -6.436416149139404], [-18.51460075378418, 15.604022026062012, -12.566503524780273], [10.074247360229492, -11.466397285461426, -8.14668083190918], [-9.84118366241455, -17.871944427490234, 10.622681617736816], [-11.533618927001953, -5.3324408531188965, 6.167666912078857], [-5.810072898864746, 8.706777572631836, -9.635246276855469], [-15.751145362854004, -8.5690336227417, 9.355066299438477], [-5.865166664123535, -8.228116989135742, 5.3361005783081055], [-19.026391983032227, 11.348217010498047, -4.1962971687316895], [13.553155899047852, -8.901749610900879, -14.662593841552734], [6.579203128814697, -3.1185107231140137, -8.110913276672363], [-7.542028427124023, 7.845306396484375, -6.356692790985107], [-11.327714920043945, 6.738553047180176, -4.218196868896484], [-22.92376136779785, 12.65185546875, -5.393691539764404], [-7.440505504608154, 5.4207305908203125, -3.291098117828369], [9.054336547851562, -17.90301513671875, -2.906597375869751], [-15.602956771850586, 11.283162117004395, -6.908313274383545], [13.713109970092773, -16.466552734375, -9.993587493896484], [18.61359214782715, -28.89122200012207, -9.679366111755371], [-10.56559944152832, -7.410687446594238, 6.614612579345703], [-15.895736694335938, 12.218134880065918, -8.092429161071777], [-2.106818199157715, 6.903900623321533, -10.829522132873535], [-30.103572845458984, 18.678382873535156, -7.667101860046387], [-9.458377838134766, 6.673965930938721, -4.46345853805542], [-8.529878616333008, -10.251368522644043, 7.150699615478516], [12.33880615234375, -11.184233665466309, -11.260007858276367], [11.020820617675781, -14.825328826904297, -6.82685661315918], [7.289367198944092, -9.83029556274414, -4.936114311218262], [-16.21630859375, 9.421360969543457, -3.5970773696899414], [-10.56559944152832, -7.410687446594238, 6.614612579345703], [-18.95228385925293, 12.360389709472656, -6.556608200073242], [-8.840730667114258, 6.257080078125, -3.52118182182312], [-5.090214252471924, -6.040642261505127, 3.9336471557617188], [-5.111029148101807, -16.757312774658203, 7.8402204513549805], [7.895053863525391, -9.740012168884277, -5.557229518890381], [7.395413875579834, -9.312141418457031, -5.0562896728515625], [8.615340232849121, -3.5372862815856934, -12.592720031738281], [8.832389831542969, -16.51479721069336, -3.073967456817627], [-15.564414978027344, 8.137990951538086, -3.0871617794036865], [13.538376808166504, -16.383785247802734, -9.9639310836792], [6.842535972595215, -8.371338844299316, -5.385270118713379], [13.713109970092773, -16.466552734375, -9.993587493896484], [-7.0437912940979, 8.55385684967041, -9.47353744506836], [-7.594695091247559, 6.082391262054443, -4.361800193786621], [18.848512649536133, -15.012104988098145, -18.194503784179688], [-17.919082641601562, 9.60156536102295, -4.4745659828186035], [-39.79096984863281, 22.059144973754883, -7.277474403381348], [6.032380104064941, -4.116967678070068, -6.971258640289307], [-5.960402488708496, 7.073380947113037, -8.493145942687988], [-22.921586990356445, 9.828827857971191, -1.7293862104415894], [6.842535972595215, -8.371338844299316, -5.385270118713379], [9.23562240600586, -13.10699462890625, -5.727849006652832], [-12.193915367126465, -4.686333179473877, 6.179584503173828], [10.435327529907227, -15.818097114562988, -5.693871021270752], [-9.674443244934082, 5.669002532958984, -3.3834948539733887], [-13.085129737854004, 9.347038269042969, -5.680936336517334], [-15.041820526123047, -11.836148262023926, 10.080251693725586], [-9.736579895019531, 6.312227725982666, -3.8764474391937256], [-3.359834909439087, 4.991603851318359, -5.3204240798950195], [8.550851821899414, -13.8461332321167, -4.424982070922852], [-26.7706241607666, 13.837260246276855, -4.408916473388672], [-13.026541709899902, 16.141151428222656, -15.683297157287598], [15.229829788208008, -23.91033935546875, -8.374670028686523], [-4.7588396072387695, -6.940605163574219, 4.196356773376465], [-30.264829635620117, 16.030315399169922, -4.652859210968018], [-15.927810668945312, 11.690655708312988, -8.208549499511719], [12.38165283203125, -13.536505699157715, -10.142057418823242], [-5.800631999969482, 6.873424530029297, -6.498617172241211], [12.304152488708496, -20.76797866821289, -5.481656074523926], [6.656723976135254, -12.31191349029541, -3.1386170387268066], [8.97312068939209, -7.565772533416748, -8.66447639465332], [7.773064613342285, -9.015216827392578, -6.337558269500732], [10.902244567871094, -14.547176361083984, -6.936845302581787], [-2.5322978496551514, 5.463643550872803, -8.114592552185059], [-9.810052871704102, 8.206070899963379, -5.848387718200684], [-26.541433334350586, 12.364949226379395, -2.3347623348236084], [16.714406967163086, -15.318740844726562, -14.767766952514648], [-8.847286224365234, -9.261578559875488, 6.768899917602539], [-6.699471950531006, 7.2031025886535645, -7.212128639221191], [-4.725827693939209, 3.5699210166931152, -2.7356810569763184], [-7.846216201782227, 10.425283432006836, -9.605466842651367], [6.579203128814697, -3.1185107231140137, -8.110913276672363], [10.998543739318848, -15.199847221374512, -6.6404008865356445], [-26.83246612548828, 14.91518497467041, -5.145045280456543], [-9.246733665466309, 7.3986735343933105, -6.082607746124268], [-5.0980072021484375, 6.520993709564209, -6.220221519470215], [7.351899147033691, -7.015301704406738, -7.063825607299805], [9.380025863647461, -10.937326431274414, -7.144468307495117], [9.578780174255371, -17.67113494873047, -3.9656777381896973], [-26.742109298706055, 15.1139554977417, -6.795065879821777], [12.241645812988281, -14.220052719116211, -8.780298233032227], [-10.339799880981445, 10.301271438598633, -9.503365516662598], [-8.661748886108398, 9.858892440795898, -9.570442199707031], [9.343389511108398, -13.796745300292969, -5.625461578369141], [-23.385896682739258, 13.083683013916016, -5.946964263916016], [9.140521049499512, -16.226680755615234, -3.6491589546203613], [7.801953315734863, -9.416182518005371, -5.571476936340332], [9.948369979858398, -12.115273475646973, -7.808775424957275], [-5.760527610778809, -10.947892189025879, 6.379888534545898], [9.359424591064453, -16.997669219970703, -4.396566867828369], [11.962982177734375, -3.746262311935425, -18.599205017089844], [0.22276684641838074, 0.10341117531061172, -0.4178540110588074], [-15.564414978027344, 8.137990951538086, -3.0871617794036865], [12.954328536987305, -15.914812088012695, -9.802508354187012], [-5.98799467086792, 4.15494966506958, -3.154359817504883], [-7.081482887268066, 8.5834379196167, -7.840932846069336], [-11.031660079956055, 6.8133320808410645, -3.436915874481201], [-4.829131126403809, 4.9920735359191895, -4.926603317260742], [8.709281921386719, -16.642900466918945, -2.851555824279785], [-4.462897300720215, 4.769344329833984, -4.018381118774414], [0.22276684641838074, 0.10341117531061172, -0.4178540110588074], [-21.65923309326172, 14.839943885803223, -8.044072151184082], [-1.9155669212341309, 3.5978074073791504, -4.197784423828125], [11.437151908874512, -13.510998725891113, -9.311509132385254], [-19.026391983032227, 11.348217010498047, -4.1962971687316895], [8.961705207824707, -11.306528091430664, -6.330747604370117], [8.015324592590332, -8.138378143310547, -6.8440704345703125], [-8.424372673034668, -5.186946392059326, 4.940959453582764], [8.286117553710938, -7.5315022468566895, -7.849813938140869], [-5.365305423736572, 11.07822036743164, -15.572992324829102], [-14.70942211151123, -8.44132137298584, 8.410669326782227], [10.403413772583008, -7.196382999420166, -11.397744178771973], [-2.6598479747772217, 4.8540496826171875, -6.156943321228027], [-8.242268562316895, -9.84390926361084, 6.850317001342773], [-11.329961776733398, -11.362900733947754, 8.488693237304688], [-4.635326385498047, 4.537899494171143, -3.349992513656616], [7.678919792175293, -9.845968246459961, -6.062156677246094], [-10.03541088104248, 10.49335765838623, -8.895874977111816], [-53.101558685302734, 29.793846130371094, -8.908967018127441], [15.747912406921387, -28.255409240722656, -6.258203506469727], [-7.092403888702393, -6.644712448120117, 4.833363056182861], [-3.1385953426361084, 5.250074863433838, -5.762273788452148], [7.815494537353516, -6.060764789581299, -8.111154556274414], [-10.62254810333252, 6.190123081207275, -2.956050157546997], [-6.850580215454102, 7.160037994384766, -5.602806091308594], [5.799735069274902, -7.66129732131958, -4.329920291900635], [6.8547444343566895, -11.378409385681152, -3.5445556640625], [-5.163269996643066, 8.838242530822754, -10.88486385345459], [-6.477660179138184, 4.7548508644104, -2.7760519981384277], [-16.21630859375, 9.421360969543457, -3.5970773696899414], [9.529589653015137, -14.334973335266113, -5.383985996246338], [8.649608612060547, -9.120036125183105, -7.5752458572387695], [-7.528538227081299, -5.332338809967041, 4.728240966796875], [6.791418552398682, -11.677483558654785, -3.173628330230713], [8.204483985900879, -12.62914752960205, -4.8717756271362305], [14.22274398803711, -20.553796768188477, -8.598474502563477], [-5.307422637939453, 8.014395713806152, -8.764427185058594], [-5.3670125007629395, -7.275975704193115, 4.729623794555664], [12.171722412109375, -8.958099365234375, -12.307306289672852], [-11.298538208007812, 8.82294750213623, -6.146461486816406], [-9.623190879821777, 7.779556751251221, -6.745719909667969], [-6.9796929359436035, 4.606950759887695, -3.3782811164855957], [9.024347305297852, -7.957961559295654, -8.427305221557617], [-7.577391147613525, 7.939591884613037, -6.640144348144531], [10.335952758789062, -10.867419242858887, -8.359572410583496], [-6.512392044067383, 5.455392360687256, -4.699226379394531], [12.824928283691406, -19.447301864624023, -6.6877241134643555], [8.128214836120605, -12.359643936157227, -4.986379146575928], [7.296306610107422, -14.5585298538208, -2.2928638458251953], [-10.172792434692383, 9.243882179260254, -6.5365824699401855], [-11.01388168334961, 6.86995267868042, -4.0501790046691895], [-5.844655513763428, 3.9524788856506348, -4.034974098205566], [-11.141548156738281, 7.554872035980225, -4.601336479187012], [6.079524517059326, -4.724264621734619, -5.9648942947387695], [-8.570018768310547, 7.004744052886963, -4.936870574951172], [10.177857398986816, -11.52778148651123, -7.951636791229248], [-4.829131126403809, 4.9920735359191895, -4.926603317260742], [-7.460574150085449, 5.869074821472168, -4.446407794952393], [-11.141548156738281, 7.554872035980225, -4.601336479187012], [-5.810072898864746, 8.706777572631836, -9.635246276855469], [-2.5236613750457764, 4.430443286895752, -4.8431572914123535], [8.384172439575195, -9.523811340332031, -6.429576396942139], [-16.647981643676758, -7.848698139190674, 8.80171012878418], [-12.361688613891602, 8.019493103027344, -4.144661903381348], [-3.483671188354492, 4.027109622955322, -4.007823944091797], [-7.846216201782227, 10.425283432006836, -9.605466842651367], [-9.52785873413086, 6.625223159790039, -3.617783546447754], [-7.2875189781188965, -11.013578414916992, 6.760579586029053], [-24.075698852539062, 14.19619083404541, -5.144304275512695], [-4.706685543060303, 7.494658470153809, -7.569887638092041], [-20.867761611938477, 9.953587532043457, -3.3356456756591797], [-4.906809329986572, 4.899119853973389, -4.4894609451293945], [8.55196762084961, -10.364469528198242, -6.346224784851074], [-10.979669570922852, 11.11892032623291, -9.87299919128418], [-17.456586837768555, 11.179892539978027, -6.534125804901123], [16.442424774169922, -18.69131088256836, -12.731391906738281], [-15.564414978027344, 8.137990951538086, -3.0871617794036865], [6.842535972595215, -8.371338844299316, -5.385270118713379], [-53.101558685302734, 29.793846130371094, -8.908967018127441], [10.33625602722168, -13.766057968139648, -7.017155647277832], [8.428498268127441, -11.10602855682373, -6.038485527038574], [-12.615842819213867, 9.768522262573242, -6.831482887268066], [13.604545593261719, -17.16191864013672, -10.72700309753418], [-3.1472551822662354, 4.519177436828613, -4.22398567199707], [-5.976195335388184, 5.527545928955078, -4.00871467590332], [10.130491256713867, -15.8594331741333, -5.301461219787598], [-5.3670125007629395, -7.275975704193115, 4.729623794555664], [-0.8915429711341858, 4.541992664337158, -7.72123384475708], [-18.832983016967773, 12.392298698425293, -7.433306694030762], [4.4690470695495605, -4.4513630867004395, -4.7488179206848145], [4.510572910308838, -4.736263275146484, -4.325773239135742], [9.89626693725586, -16.27234649658203, -4.611997127532959], [-9.989461898803711, -5.622344493865967, 5.575967788696289], [-4.493061065673828, 5.39553689956665, -5.211410999298096], [-10.869637489318848, 9.68714427947998, -8.036062240600586], [-2.246987819671631, 4.592334270477295, -5.584125518798828], [11.352771759033203, -13.262528419494629, -8.291987419128418], [11.371187210083008, -9.164634704589844, -11.128191947937012], [6.905963897705078, -7.4238200187683105, -5.984988212585449], [9.507768630981445, -9.355646133422852, -8.17386531829834], [8.241020202636719, -3.727515697479248, -10.792553901672363], [-12.400014877319336, -4.858269214630127, 6.127224922180176], [-6.810924530029297, -7.989344120025635, 5.586540699005127], [-7.288652420043945, 7.879174709320068, -8.282702445983887], [8.645513534545898, -5.543895721435547, -9.75044059753418], [-7.228796005249023, 7.6951375007629395, -5.984646797180176], [12.033031463623047, -11.804532051086426, -10.420427322387695], [-15.041820526123047, -11.836148262023926, 10.080251693725586], [-25.201417922973633, 15.191885948181152, -7.031039237976074], [-8.361467361450195, -15.830757141113281, 9.356886863708496], [-8.283451080322266, 9.8551607131958, -8.761467933654785], [-7.891449928283691, 6.57757043838501, -5.365339756011963], [-6.826601505279541, 5.35768985748291, -3.6630072593688965], [13.275178909301758, -22.55467414855957, -5.8063764572143555], [-5.791563987731934, -25.77492904663086, 11.381112098693848], [7.565122127532959, -10.969015121459961, -4.610668182373047], [-5.8514909744262695, 7.14164400100708, -7.7592549324035645], [-5.810072898864746, 8.706777572631836, -9.635246276855469], [10.335952758789062, -10.867419242858887, -8.359572410583496], [10.432065963745117, -12.408717155456543, -8.042882919311523], [4.825490951538086, -0.9164479374885559, -8.19427490234375], [-4.7114081382751465, 6.338507175445557, -5.938821792602539], [-5.163269996643066, 8.838242530822754, -10.88486385345459], [-5.691033363342285, 3.8425328731536865, -2.5991787910461426], [-4.763455867767334, 8.143095016479492, -9.333776473999023], [5.2897186279296875, -5.121896266937256, -5.277800559997559], [15.169191360473633, -18.947750091552734, -11.048746109008789], [17.838287353515625, -25.724138259887695, -10.603468894958496], [-9.51955509185791, 5.126938343048096, -2.113555908203125], [-5.469324111938477, 3.92610239982605, -2.6986875534057617], [8.649608612060547, -9.120036125183105, -7.5752458572387695], [-17.79195213317871, 9.414685249328613, -3.375209331512451], [-5.4876627922058105, -7.912959575653076, 4.954165935516357], [12.718326568603516, -17.25703239440918, -7.902665615081787], [7.438446998596191, -7.18048620223999, -6.618453502655029], [-3.6834192276000977, 7.872661113739014, -10.540558815002441], [10.43596363067627, -12.225510597229004, -8.634552001953125], [12.38165283203125, -13.536505699157715, -10.142057418823242], [7.728481292724609, -7.858255386352539, -6.834259986877441], [-18.832983016967773, 12.392298698425293, -7.433306694030762], [-6.36533260345459, 4.111560344696045, -2.598491907119751], [-30.264829635620117, 16.030315399169922, -4.652859210968018], [-6.870338439941406, 8.821928024291992, -8.779556274414062], [7.4925432205200195, -7.947486400604248, -5.833086967468262], [-14.983366966247559, 10.143556594848633, -5.817974090576172], [23.149587631225586, -30.174301147460938, -15.549097061157227], [15.139650344848633, -30.007091522216797, -4.078278541564941], [-16.11286163330078, 9.868535041809082, -4.1506452560424805], [-5.782598495483398, 6.725225448608398, -7.070751667022705], [-12.576417922973633, 10.677210807800293, -7.388948917388916], [-7.8271989822387695, 6.098625659942627, -4.342911720275879], [-6.699471950531006, 7.2031025886535645, -7.212128639221191], [-36.654205322265625, 16.496776580810547, -2.0949347019195557], [17.246902465820312, -32.127437591552734, -6.405094146728516], [-13.345202445983887, 8.131815910339355, -3.5731301307678223], [-6.606266021728516, -11.92342472076416, 6.869169235229492], [17.355518341064453, -29.300092697143555, -8.019299507141113], [-12.070478439331055, 7.464205265045166, -4.269432067871094], [-4.2934770584106445, 5.329757213592529, -4.860855579376221], [12.033031463623047, -11.804532051086426, -10.420427322387695], [-13.531767845153809, -4.712166786193848, 6.496042728424072], [10.019279479980469, -14.208151817321777, -6.1577887535095215], [9.38589859008789, -10.916218757629395, -7.1307573318481445], [8.874737739562988, -12.339282989501953, -6.063090801239014], [-10.658424377441406, 6.4504570960998535, -3.430525779724121], [-8.942752838134766, 5.043038845062256, -2.498107433319092], [6.356890678405762, 0.7552168369293213, -15.085981369018555], [-5.800631999969482, 6.873424530029297, -6.498617172241211], [-4.493061065673828, 5.39553689956665, -5.211410999298096], [-10.133880615234375, 5.855138778686523, -4.104073524475098], [8.750617027282715, -12.49507999420166, -5.624958515167236], [-5.163269996643066, 8.838242530822754, -10.88486385345459], [8.286117553710938, -7.5315022468566895, -7.849813938140869], [-7.558218955993652, 4.342304706573486, -2.478832960128784], [-26.7706241607666, 13.837260246276855, -4.408916473388672], [-7.542028427124023, 7.845306396484375, -6.356692790985107], [13.315649032592773, -14.104796409606934, -10.89581298828125], [-5.515659332275391, 4.723277568817139, -4.763174533843994], [8.015324592590332, -8.138378143310547, -6.8440704345703125], [-9.399070739746094, 7.785565376281738, -5.283393859863281], [12.377584457397461, -11.892661094665527, -11.70791244506836], [16.199270248413086, -19.48625946044922, -11.707465171813965], [14.378263473510742, -27.062040328979492, -4.701389789581299], [-7.997166633605957, 7.508892059326172, -6.922243595123291], [-9.313373565673828, -4.146530628204346, 4.973560810089111], [4.4690470695495605, -4.4513630867004395, -4.7488179206848145], [5.402606010437012, -1.434280276298523, -8.610797882080078], [13.713109970092773, -16.466552734375, -9.993587493896484], [9.035608291625977, -11.038796424865723, -6.773324489593506], [13.358892440795898, -17.291025161743164, -8.858125686645508], [-6.020092010498047, 4.741431713104248, -3.8536336421966553], [-3.373504400253296, 8.74220085144043, -12.522331237792969], [-3.373504400253296, 8.74220085144043, -12.522331237792969], [4.546313762664795, -3.300872802734375, -5.304401874542236], [8.862930297851562, -6.70359468460083, -9.767234802246094], [9.251121520996094, -13.031824111938477, -6.055791854858398], [-9.313373565673828, -4.146530628204346, 4.973560810089111], [-34.0687255859375, 22.628658294677734, -11.0105562210083], [16.127750396728516, -19.137893676757812, -11.853368759155273], [13.604545593261719, -17.16191864013672, -10.72700309753418], [-6.320391654968262, 5.609457969665527, -4.471625328063965], [-14.384961128234863, 8.905146598815918, -3.7722270488739014], [6.229706764221191, -7.214712142944336, -5.660389423370361], [-8.459912300109863, -9.659894943237305, 6.967763900756836], [8.993757247924805, -12.184961318969727, -5.798817157745361], [-29.92291259765625, 16.716197967529297, -6.649824142456055], [-5.762598991394043, 6.0683674812316895, -5.809243202209473], [-26.541433334350586, 12.364949226379395, -2.3347623348236084], [-7.577391147613525, 7.939591884613037, -6.640144348144531], [-6.36533260345459, 4.111560344696045, -2.598491907119751], [-14.982462882995605, -2.8696560859680176, 5.797813415527344], [-19.165815353393555, -22.122802734375, 16.2482967376709], [13.14248275756836, -7.793320178985596, -14.704935073852539], [-2.5236613750457764, 4.430443286895752, -4.8431572914123535], [-7.528120994567871, 5.536596775054932, -4.381814002990723], [-7.577811241149902, -7.116546630859375, 5.454145431518555], [-6.477660179138184, 4.7548508644104, -2.7760519981384277], [-9.918623924255371, 10.659358024597168, -8.72492790222168], [-9.696791648864746, 5.800116062164307, -2.800469398498535], [-10.502659797668457, 9.758513450622559, -7.719516754150391], [-8.547150611877441, 11.086396217346191, -10.411958694458008], [-12.130512237548828, 7.546111583709717, -3.504016637802124], [-28.327938079833984, 10.736077308654785, -0.8914132118225098], [-4.016763210296631, 3.917935848236084, -3.7793428897857666], [-6.145122528076172, -9.794736862182617, 5.953055381774902], [-15.602956771850586, 11.283162117004395, -6.908313274383545], [-20.07496452331543, 11.933845520019531, -4.073879241943359], [-15.19666862487793, 8.62540340423584, -3.685688018798828], [-10.533060073852539, -6.51392126083374, 6.052618026733398], [-7.092403888702393, -6.644712448120117, 4.833363056182861], [14.378263473510742, -27.062040328979492, -4.701389789581299], [-7.577391147613525, 7.939591884613037, -6.640144348144531], [-9.252718925476074, 7.078148365020752, -5.240120887756348], [8.936744689941406, -10.847115516662598, -6.416030406951904], [8.384172439575195, -9.523811340332031, -6.429576396942139], [-11.435653686523438, -7.30566930770874, 7.062258720397949], [8.626823425292969, -8.353948593139648, -8.140481948852539], [-2.303260564804077, 4.068064212799072, -4.5194597244262695], [-9.810052871704102, 8.206070899963379, -5.848387718200684], [-7.2875189781188965, -11.013578414916992, 6.760579586029053], [8.154458045959473, -14.701150894165039, -3.3011693954467773], [14.127998352050781, -16.541259765625, -10.173673629760742], [-4.5761518478393555, 5.223642349243164, -4.102651596069336], [9.02783203125, -11.176905632019043, -7.051296234130859], [-10.191398620605469, 6.695157051086426, -4.155752182006836], [10.366434097290039, -16.15155792236328, -5.44295597076416], [-6.145122528076172, -9.794736862182617, 5.953055381774902], [9.16384506225586, -12.197443962097168, -6.356995105743408], [-8.578424453735352, -8.431130409240723, 6.391252517700195], [-24.40938377380371, 15.02043628692627, -7.396740436553955], [19.559898376464844, -16.62977409362793, -19.81793785095215], [8.951467514038086, -10.398550987243652, -6.869524955749512], [16.58146095275879, -12.811068534851074, -17.006017684936523], [-6.665478229522705, 5.86922025680542, -4.103260040283203], [-5.753758430480957, -4.618135452270508, 3.7282724380493164], [-9.865575790405273, 9.22107219696045, -6.840677738189697], [-8.592670440673828, 6.160412311553955, -4.465765953063965], [-17.41774559020996, 7.797772407531738, -2.4791533946990967], [-7.665459156036377, 7.514611721038818, -6.926400184631348], [8.143359184265137, -4.370612621307373, -9.92990493774414], [6.403564453125, -2.5274624824523926, -8.777027130126953], [-3.6232049465179443, 11.040884971618652, -16.054466247558594], [-7.528120994567871, 5.536596775054932, -4.381814002990723], [-2.098132371902466, 6.453048229217529, -9.477689743041992], [-7.283411979675293, 6.974210262298584, -6.10921573638916], [18.50676155090332, -18.977310180664062, -15.572896957397461], [14.422298431396484, -18.51639175415039, -9.78369140625], [-3.3165605068206787, 4.1221699714660645, -4.253275394439697], [-5.768110752105713, 7.585954189300537, -8.536884307861328], [-5.163269996643066, 8.838242530822754, -10.88486385345459], [-9.684122085571289, 6.783024311065674, -4.272149085998535], [19.556447982788086, -21.294342041015625, -15.061574935913086], [13.155441284179688, -16.898109436035156, -8.701558113098145], [-4.287667274475098, 4.416986465454102, -4.100783348083496], [-2.7853035926818848, 2.931781053543091, -2.7839131355285645], [11.437151908874512, -13.510998725891113, -9.311509132385254], [13.604545593261719, -17.16191864013672, -10.72700309753418], [-7.601970195770264, 5.031371116638184, -3.261989116668701], [7.158371925354004, -7.673681259155273, -6.296218395233154], [5.066285133361816, -2.1131510734558105, -6.930331230163574], [10.95701789855957, -15.147369384765625, -7.383087158203125], [-5.831843852996826, 6.673238277435303, -6.429149627685547], [-1.9925963878631592, 8.824660301208496, -15.166069030761719], [-5.48675537109375, 7.908560276031494, -7.561803340911865], [7.290307521820068, -8.318623542785645, -6.250197410583496], [-25.186979293823242, -3.995305061340332, 9.870248794555664], [-9.92030143737793, 12.014735221862793, -11.544824600219727], [-3.373504400253296, 8.74220085144043, -12.522331237792969], [-2.748033285140991, 5.095404148101807, -6.0410284996032715], [-10.133880615234375, 5.855138778686523, -4.104073524475098], [-3.792569398880005, 5.436117649078369, -5.961348056793213], [-10.459712982177734, -2.664994716644287, 4.073740005493164], [10.544304847717285, -16.001239776611328, -6.159979820251465], [19.354001998901367, -27.283323287963867, -12.285316467285156], [-20.515182495117188, 13.576449394226074, -7.418042182922363], [12.364490509033203, -15.39237117767334, -9.240829467773438], [15.321916580200195, -19.392391204833984, -10.597338676452637], [-2.5236613750457764, 4.430443286895752, -4.8431572914123535], [15.169191360473633, -18.947750091552734, -11.048746109008789], [15.169191360473633, -18.947750091552734, -11.048746109008789], [-12.638143539428711, 6.187277317047119, -2.2358438968658447], [-4.664931297302246, 4.32725715637207, -3.2569923400878906], [-10.895302772521973, 10.997590065002441, -8.390117645263672], [6.536657333374023, -2.906428098678589, -9.133979797363281], [-10.509571075439453, 7.060370922088623, -3.443561553955078], [-19.24086570739746, 14.6642427444458, -8.868162155151367], [-11.907999038696289, 7.298376083374023, -3.528620481491089], [-1.5043342113494873, 7.5687360763549805, -13.466636657714844], [16.96076774597168, -30.308338165283203, -6.598147392272949], [-5.297569274902344, 8.357926368713379, -8.887674331665039], [7.027563571929932, -6.798065662384033, -6.887174606323242], [-3.2261345386505127, 6.880387783050537, -9.572395324707031], [0.22276684641838074, 0.10341117531061172, -0.4178540110588074], [-8.615124702453613, -9.224961280822754, 6.710240840911865], [7.329789161682129, -7.509541034698486, -6.84872579574585], [-3.56361985206604, 6.631577014923096, -8.127876281738281], [-30.292709350585938, 16.664627075195312, -5.327522277832031], [19.31500816345215, -23.031063079833984, -13.764406204223633], [-17.79195213317871, 9.414685249328613, -3.375209331512451], [-13.977429389953613, 9.12494945526123, -5.313417434692383], [4.668062210083008, -2.150050163269043, -6.162070274353027], [-5.48675537109375, 7.908560276031494, -7.561803340911865], [-4.728065490722656, 4.54547119140625, -3.55045223236084], [6.007291793823242, -7.307216644287109, -4.714445114135742], [19.017532348632812, -14.477068901062012, -20.05084800720215], [-6.202154159545898, 4.9285712242126465, -4.92678165435791], [-16.99637794494629, 9.079619407653809, -3.4862570762634277], [7.7045111656188965, -9.262755393981934, -5.898519515991211], [9.316526412963867, -7.359384059906006, -9.248368263244629], [10.946626663208008, -12.219654083251953, -8.797357559204102], [-20.126163482666016, 11.044363021850586, -4.9137187004089355], [8.271251678466797, -9.330910682678223, -6.711079120635986], [-7.0437912940979, 8.55385684967041, -9.47353744506836], [-7.542028427124023, 7.845306396484375, -6.356692790985107], [-13.977429389953613, 9.12494945526123, -5.313417434692383], [-6.328278541564941, 5.77228307723999, -4.588986873626709], [9.126965522766113, -8.297588348388672, -8.595760345458984], [-3.6572682857513428, 5.417736530303955, -5.43476676940918], [-5.226950645446777, 6.785211086273193, -7.622964859008789], [-5.367597579956055, 6.4992241859436035, -6.717539310455322], [-12.562325477600098, 9.523885726928711, -5.7186079025268555], [-7.436032295227051, 6.573485851287842, -5.687448501586914], [16.132970809936523, -21.39232063293457, -10.590263366699219], [-12.821471214294434, 7.5692267417907715, -3.6191320419311523], [8.171032905578613, -5.752447605133057, -8.641716003417969], [-6.496282577514648, 9.725188255310059, -10.453752517700195], [10.592416763305664, -17.81296157836914, -4.927392482757568], [7.366508960723877, -4.309683799743652, -8.570446014404297], [-9.863554000854492, -13.158952713012695, 8.671483993530273], [-28.601980209350586, 17.693836212158203, -9.149725914001465], [-10.680704116821289, -10.906342506408691, 8.241575241088867], [7.256178379058838, -4.7702717781066895, -7.960312843322754], [-12.789422988891602, 7.958041667938232, -4.40989351272583], [12.300361633300781, -13.700508117675781, -9.764280319213867], [-11.04652214050293, 8.017669677734375, -5.759982109069824], [-8.37014389038086, 5.995917797088623, -3.8973026275634766], [-7.313728332519531, 4.387152194976807, -2.844252824783325], [-12.823736190795898, -8.350852012634277, 8.085399627685547], [7.522019386291504, -8.123238563537598, -6.732319355010986], [-13.712591171264648, -5.960197925567627, 6.965120792388916], [-6.320391654968262, 5.609457969665527, -4.471625328063965], [-8.125781059265137, 6.099034786224365, -4.7743330001831055], [11.988961219787598, -12.883696556091309, -10.643953323364258], [-12.023103713989258, 8.262585639953613, -5.127627849578857], [12.069737434387207, -17.6575927734375, -7.449443817138672], [8.12393569946289, -6.766667366027832, -8.132621765136719], [6.007291793823242, -7.307216644287109, -4.714445114135742], [-3.7751543521881104, 3.5219335556030273, -3.2226061820983887], [-4.891310214996338, 8.20538330078125, -9.93659496307373], [10.98049545288086, -9.455120086669922, -10.544576644897461], [9.169445991516113, -10.118660926818848, -7.061675071716309], [14.446883201599121, -10.31430721282959, -15.640371322631836], [-7.681231498718262, 4.908383846282959, -3.2384462356567383], [-9.883678436279297, 10.518206596374512, -9.100770950317383], [-7.601970195770264, 5.031371116638184, -3.261989116668701], [-11.01388168334961, 6.86995267868042, -4.0501790046691895], [-12.309320449829102, 10.538203239440918, -7.419451713562012], [11.297969818115234, -12.905900001525879, -8.645700454711914], [12.07658576965332, -17.713224411010742, -7.519526481628418], [10.366434097290039, -16.15155792236328, -5.44295597076416], [11.115423202514648, -13.585122108459473, -8.470065116882324], [-13.345202445983887, 8.131815910339355, -3.5731301307678223], [-9.916467666625977, 9.012998580932617, -8.018795013427734], [-8.504932403564453, 7.952483654022217, -6.981597900390625], [13.632579803466797, -20.223133087158203, -8.156600952148438], [-8.612483024597168, 8.444588661193848, -6.773785591125488], [8.922565460205078, -12.8650484085083, -5.4270219802856445], [-24.589656829833984, -1.8157365322113037, 8.416927337646484], [-7.081482887268066, 8.5834379196167, -7.840932846069336], [-5.98799467086792, 4.15494966506958, -3.154359817504883], [-3.0465333461761475, 4.9140448570251465, -4.97648811340332], [12.448497772216797, -10.349291801452637, -12.43375015258789], [-6.279758453369141, 7.192185878753662, -6.188615798950195], [-3.6834192276000977, 7.872661113739014, -10.540558815002441], [7.3816046714782715, -7.043989181518555, -6.798469543457031], [9.430841445922852, -10.439338684082031, -7.10772180557251], [-3.0237555503845215, 4.109670162200928, -4.476978302001953], [7.764996528625488, -12.831585884094238, -3.719252586364746], [12.485349655151367, -12.620991706848145, -9.953964233398438], [19.556447982788086, -21.294342041015625, -15.061574935913086], [-53.101558685302734, 29.793846130371094, -8.908967018127441], [-29.680130004882812, 16.250511169433594, -6.6247172355651855], [-4.763455867767334, 8.143095016479492, -9.333776473999023], [8.286117553710938, -7.5315022468566895, -7.849813938140869], [13.544902801513672, -8.769732475280762, -14.357161521911621], [-10.492827415466309, 6.430241107940674, -3.3277971744537354], [-7.951520919799805, 6.5158209800720215, -6.015078544616699], [-3.4160680770874023, 4.599181175231934, -5.659188270568848], [10.388540267944336, -10.411970138549805, -9.212270736694336], [13.771743774414062, -18.745040893554688, -8.57133960723877], [-15.633231163024902, 11.50104808807373, -5.865250587463379], [-25.25655174255371, 13.626238822937012, -4.974329471588135], [-30.103572845458984, 18.678382873535156, -7.667101860046387], [6.064739227294922, -8.953587532043457, -4.0551347732543945], [-53.101558685302734, 29.793846130371094, -8.908967018127441], [-2.6500396728515625, 8.165192604064941, -12.225929260253906], [-7.2203450202941895, 5.347239971160889, -3.264239549636841], [-10.503238677978516, 8.856213569641113, -6.582061290740967], [13.337125778198242, -15.871891975402832, -9.566869735717773], [-9.684122085571289, 6.783024311065674, -4.272149085998535], [11.284571647644043, -3.573652744293213, -17.561695098876953], [-19.2990665435791, 9.333680152893066, -2.601158618927002], [-4.258496284484863, 6.101088523864746, -5.838005065917969], [-7.725930213928223, 9.13269329071045, -8.277596473693848], [17.838287353515625, -25.724138259887695, -10.603468894958496], [-7.846216201782227, 10.425283432006836, -9.605466842651367], [9.403413772583008, -16.944271087646484, -3.693189859390259], [-7.542028427124023, 7.845306396484375, -6.356692790985107], [12.241645812988281, -14.220052719116211, -8.780298233032227], [-26.7706241607666, 13.837260246276855, -4.408916473388672], [-31.564170837402344, 16.066619873046875, -4.217386722564697], [-8.259200096130371, 8.416196823120117, -8.47054672241211], [-10.778450012207031, 9.127413749694824, -5.903804779052734], [-8.343888282775879, 7.229675769805908, -5.507087230682373], [-6.619622230529785, 4.797318458557129, -3.229048728942871], [6.825117111206055, -7.9007720947265625, -5.286893844604492], [13.564435005187988, -20.789939880371094, -7.329296588897705], [-15.927810668945312, 11.690655708312988, -8.208549499511719], [-6.803225040435791, 7.265015602111816, -6.59169340133667], [-13.773265838623047, 5.5431013107299805, -0.7837145328521729], [-7.4753499031066895, 5.903447151184082, -4.821342468261719], [9.740806579589844, -19.247055053710938, -2.9440839290618896], [-10.979669570922852, 11.11892032623291, -9.87299919128418], [8.544792175292969, -12.802687644958496, -4.906195640563965], [15.813344955444336, -29.967208862304688, -5.060548782348633], [-11.31802749633789, 11.077364921569824, -8.228752136230469], [7.598388671875, -12.388162612915039, -4.194779396057129], [-2.9111149311065674, 4.6234283447265625, -4.972341060638428], [8.843368530273438, -3.992794990539551, -11.15319538116455], [7.943579196929932, -14.16477108001709, -3.673577070236206], [12.241645812988281, -14.220052719116211, -8.780298233032227], [-11.276780128479004, 10.397143363952637, -7.252773284912109], [-5.670983791351318, 7.108270168304443, -7.995873928070068], [-7.536364555358887, 9.413270950317383, -9.079973220825195], [-7.891449928283691, 6.57757043838501, -5.365339756011963], [12.694087982177734, -11.624953269958496, -11.065286636352539], [-11.493094444274902, 9.14470100402832, -7.7760491371154785], [-4.189117431640625, 4.821987628936768, -5.090269565582275], [-6.9867706298828125, 6.156257152557373, -4.604543685913086], [-18.096397399902344, -3.3916234970092773, 7.264754295349121], [-32.93566131591797, 20.785709381103516, -10.646306991577148], [-11.141548156738281, 7.554872035980225, -4.601336479187012], [7.622134208679199, -6.184556484222412, -7.863677024841309], [12.357913970947266, -19.512731552124023, -6.500783920288086], [-8.772141456604004, -5.48861837387085, 5.1980390548706055], [-14.982462882995605, -2.8696560859680176, 5.797813415527344], [-6.145122528076172, -9.794736862182617, 5.953055381774902], [-28.755739212036133, 15.48177433013916, -4.414236068725586], [-9.839462280273438, 11.094893455505371, -12.546197891235352], [-7.469516754150391, 5.218381404876709, -3.4391403198242188], [-9.399070739746094, 7.785565376281738, -5.283393859863281], [12.713788032531738, -10.898207664489746, -11.793069839477539], [-10.103480339050293, 6.6109395027160645, -3.3457159996032715], [8.222244262695312, -6.848881244659424, -8.241806030273438], [-19.24086570739746, 14.6642427444458, -8.868162155151367], [8.404720306396484, -1.311859369277954, -14.944083213806152], [-8.003580093383789, 2.761381149291992, -0.6215971112251282], [9.435863494873047, -4.607083797454834, -12.139050483703613], [-7.935698509216309, -9.14145565032959, 6.446652412414551], [4.836874961853027, -6.413689136505127, -3.577767848968506], [12.291085243225098, -16.741477966308594, -7.821070671081543], [13.405211448669434, -24.492979049682617, -5.157712459564209], [8.351305961608887, -8.001984596252441, -7.791170597076416], [3.6835808753967285, -3.3467113971710205, -3.8575198650360107], [-9.994498252868652, -6.570065498352051, 5.9799909591674805], [-22.92376136779785, 12.65185546875, -5.393691539764404], [19.392467498779297, -34.86536407470703, -7.7275776863098145], [11.79371452331543, -15.88898754119873, -7.5961384773254395], [-7.573925971984863, 15.09584903717041, -19.86185073852539], [-9.84118366241455, -17.871944427490234, 10.622681617736816], [9.756420135498047, -17.56523895263672, -4.406274795532227], [-5.3023362159729, 7.0708136558532715, -7.401070594787598], [13.604545593261719, -17.16191864013672, -10.72700309753418], [-5.6322021484375, 6.084521770477295, -6.100385665893555], [9.201311111450195, -16.811782836914062, -3.312986135482788], [11.17386531829834, -18.85076141357422, -5.102235794067383], [-6.563270568847656, 4.23034143447876, -2.6847121715545654], [-6.320391654968262, 5.609457969665527, -4.471625328063965], [-9.74024486541748, -8.123004913330078, 6.753817081451416], [8.171032905578613, -5.752447605133057, -8.641716003417969], [-10.979669570922852, 11.11892032623291, -9.87299919128418], [4.795630931854248, -6.708851337432861, -3.157831907272339], [-10.145772933959961, -10.194476127624512, 7.841636657714844], [0.22276684641838074, 0.10341117531061172, -0.4178540110588074], [5.218318462371826, -3.349174976348877, -6.394394874572754], [10.674448013305664, -13.988927841186523, -7.015342712402344], [0.22276684641838074, 0.10341117531061172, -0.4178540110588074], [-7.648664951324463, -7.371931552886963, 5.6172027587890625], [10.156787872314453, -13.808491706848145, -7.207639694213867], [16.189069747924805, -25.89875030517578, -8.007396697998047], [10.874079704284668, -15.736557960510254, -6.931699752807617], [-19.026391983032227, 11.348217010498047, -4.1962971687316895], [-19.026391983032227, 11.348217010498047, -4.1962971687316895], [9.450736999511719, -13.5980806350708, -5.894375801086426], [12.448497772216797, -10.349291801452637, -12.43375015258789], [-8.87899398803711, 5.1763105392456055, -2.330371379852295], [5.218318462371826, -3.349174976348877, -6.394394874572754], [10.083630561828613, -12.296378135681152, -7.7502899169921875], [-7.536049842834473, -5.548581600189209, 4.707921028137207], [-13.08620834350586, 6.09976053237915, -1.849428415298462], [9.16384506225586, -12.197443962097168, -6.356995105743408], [-2.7853035926818848, 2.931781053543091, -2.7839131355285645], [7.680671691894531, -14.11382007598877, -2.6766066551208496], [-29.92291259765625, 16.716197967529297, -6.649824142456055], [-5.307251930236816, 5.918064594268799, -5.363537788391113], [4.825490951538086, -0.9164479374885559, -8.19427490234375], [13.177427291870117, -15.395485877990723, -9.954916954040527], [-7.440505504608154, 5.4207305908203125, -3.291098117828369], [-10.647794723510742, 12.434248924255371, -9.806272506713867], [4.093119144439697, -5.410187244415283, -3.242455244064331], [-11.747425079345703, 7.744273662567139, -4.563365459442139], [-5.768110752105713, 7.585954189300537, -8.536884307861328], [-40.30009078979492, 16.620433807373047, -1.0158941745758057], [-53.101558685302734, 29.793846130371094, -8.908967018127441], [-12.023103713989258, 8.262585639953613, -5.127627849578857], [13.43130111694336, -21.540252685546875, -6.384504795074463], [5.827681541442871, -4.999284744262695, -6.097939968109131], [11.201221466064453, -11.94632625579834, -8.998289108276367], [-7.665459156036377, 7.514611721038818, -6.926400184631348], [-16.99637794494629, 9.079619407653809, -3.4862570762634277], [5.218318462371826, -3.349174976348877, -6.394394874572754], [-11.04652214050293, 8.017669677734375, -5.759982109069824], [5.826041221618652, -8.6952486038208, -3.9700310230255127], [-10.269756317138672, 5.779947757720947, -2.5459976196289062], [-4.706685543060303, 7.494658470153809, -7.569887638092041], [3.3204405307769775, -2.2850341796875, -4.182156562805176], [12.542033195495605, -21.562389373779297, -5.374665260314941], [-9.866436958312988, -6.333093166351318, 5.846960067749023], [-12.821471214294434, 7.5692267417907715, -3.6191320419311523], [-6.861332416534424, 9.903265953063965, -11.270730018615723], [-19.026391983032227, 11.348217010498047, -4.1962971687316895], [10.542045593261719, -13.288008689880371, -7.428267955780029], [13.14248275756836, -7.793320178985596, -14.704935073852539], [14.378263473510742, -27.062040328979492, -4.701389789581299], [-5.197445869445801, 6.7357916831970215, -8.116875648498535], [9.403413772583008, -16.944271087646484, -3.693189859390259], [-15.564414978027344, 8.137990951538086, -3.0871617794036865], [13.932872772216797, -20.435623168945312, -8.031671524047852], [-10.03541088104248, 10.49335765838623, -8.895874977111816], [13.337125778198242, -15.871891975402832, -9.566869735717773], [8.286117553710938, -7.5315022468566895, -7.849813938140869], [6.964578628540039, -9.662760734558105, -4.78239107131958], [9.558029174804688, -11.855738639831543, -6.806777477264404], [-12.882525444030762, 11.175145149230957, -8.735174179077148], [12.733203887939453, -24.435487747192383, -3.8925938606262207], [-10.320711135864258, -10.395262718200684, 7.794048309326172], [-7.081482887268066, 8.5834379196167, -7.840932846069336], [15.139650344848633, -30.007091522216797, -4.078278541564941], [10.345406532287598, -13.495970726013184, -7.237298488616943], [-0.49687057733535767, 3.8918299674987793, -7.366640567779541], [7.466942310333252, -8.842663764953613, -5.907932281494141], [9.64472770690918, -13.564162254333496, -6.172247886657715], [7.278857231140137, -10.288651466369629, -4.530825138092041], [-5.396224021911621, 11.868857383728027, -15.988790512084961], [-6.247659683227539, 8.73685359954834, -9.09024429321289], [-5.307422637939453, 8.014395713806152, -8.764427185058594], [-5.927770614624023, 9.076813697814941, -10.127432823181152], [-9.574502944946289, -4.917022705078125, 5.223669052124023], [9.35760498046875, -11.358017921447754, -6.930395126342773], [-4.837325096130371, 6.572618007659912, -9.243644714355469], [-6.121986389160156, -7.3530683517456055, 4.828707218170166], [14.01398754119873, -20.881879806518555, -8.265955924987793], [12.490029335021973, -15.48830795288086, -8.817659378051758], [-11.625724792480469, 6.94088888168335, -3.288175106048584], [-28.616561889648438, 13.59127140045166, -2.7192981243133545], [6.96628475189209, -3.32926869392395, -9.227481842041016], [-17.12482452392578, 6.582282543182373, -0.6803547739982605], [15.836101531982422, -24.802499771118164, -8.39187240600586], [10.083630561828613, -12.296378135681152, -7.7502899169921875], [-14.844128608703613, 7.666197776794434, -3.0756101608276367], [-32.93566131591797, 20.785709381103516, -10.646306991577148], [-18.007617950439453, 11.743609428405762, -7.734055519104004], [9.403413772583008, -16.944271087646484, -3.693189859390259], [-5.791563987731934, -25.77492904663086, 11.381112098693848], [-4.613589286804199, 9.39669418334961, -11.661660194396973], [-13.712591171264648, -5.960197925567627, 6.965120792388916], [-25.775903701782227, 12.19196605682373, -2.3707938194274902], [-0.14894337952136993, 5.535799026489258, -11.374126434326172], [7.868686199188232, -9.041096687316895, -6.267644882202148], [-1.7285070419311523, 4.295499801635742, -5.958200454711914], [-10.133880615234375, 5.855138778686523, -4.104073524475098], [-13.712591171264648, -5.960197925567627, 6.965120792388916], [-10.647794723510742, 12.434248924255371, -9.806272506713867], [-12.400014877319336, -4.858269214630127, 6.127224922180176], [-9.684122085571289, 6.783024311065674, -4.272149085998535], [-23.588685989379883, 14.434614181518555, -6.018947601318359], [5.5329694747924805, -7.693434238433838, -3.495272159576416], [9.854516983032227, -11.530826568603516, -7.584815979003906], [-15.817020416259766, 8.319411277770996, -3.490692138671875], [-29.92291259765625, 16.716197967529297, -6.649824142456055], [-14.983366966247559, 10.143556594848633, -5.817974090576172], [13.358892440795898, -17.291025161743164, -8.858125686645508], [-7.951520919799805, 6.5158209800720215, -6.015078544616699], [-7.731653213500977, 5.782630920410156, -4.415754318237305], [12.824928283691406, -19.447301864624023, -6.6877241134643555], [11.403934478759766, -14.626139640808105, -7.980630874633789], [-3.6232049465179443, 11.040884971618652, -16.054466247558594], [-11.98570728302002, 9.637831687927246, -6.413572788238525], [-1.423811435699463, 5.375197410583496, -8.753922462463379], [0.22276684641838074, 0.10341117531061172, -0.4178540110588074], [-7.846216201782227, 10.425283432006836, -9.605466842651367], [12.033031463623047, -11.804532051086426, -10.420427322387695], [-7.283411979675293, 6.974210262298584, -6.10921573638916], [8.579602241516113, -10.687929153442383, -6.1665754318237305], [11.811230659484863, -13.079110145568848, -9.972692489624023], [-10.11301040649414, -15.493630409240723, 9.894705772399902], [-4.069384574890137, 4.816013813018799, -4.5272932052612305], [13.646478652954102, -28.543609619140625, -3.402714252471924], [5.328586578369141, -3.2947590351104736, -6.003232479095459], [-5.377325057983398, 4.143699645996094, -2.619281768798828], [-8.504932403564453, 7.952483654022217, -6.981597900390625]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QndaghCxXpxZ"
      },
      "source": [
        "# Get predictions for calculating accuracy, precision, recall"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeXqP6ryL2E0"
      },
      "source": [
        "y_pred_list = []\n",
        "albert_preds = []\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    for X_batch, _ in test_loader:\n",
        "        X_batch = X_batch.to(device)\n",
        "        y_test_pred = model(X_batch)\n",
        "        albert_preds.append(y_test_pred)\n",
        "        # print(y_test_pred)\n",
        "        _, y_pred_tags = torch.max(y_test_pred, dim = 1)\n",
        "        y_pred_list.append(y_pred_tags.cpu().numpy())\n",
        "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5gjzD0ypGbY",
        "outputId": "714d5a88-8c45-4b89-cbb4-298ce1f762ec"
      },
      "source": [
        "print(y_pred_list)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 2, 0, 1, 0, 1, 0, 1, 1, 1, 1, 2, 1, 0, 1, 1, 1, 2, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 2, 1, 0, 0, 0, 2, 1, 0, 1, 0, 2, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 2, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 2, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 2, 2, 1, 0, 0, 1, 1, 0, 1, 0, 2, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 2, 1, 1, 2, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 2, 0, 0, 1, 0, 1, 0, 2, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 0, 0, 1, 1, 2, 0, 0, 0, 1, 1, 0, 2, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 2, 2, 2, 0, 1, 2, 2, 1, 1, 1, 1, 0, 2, 0, 2, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 2, 0, 1, 1, 0, 2, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 2, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 2, 0, 0, 1, 0, 2, 0, 1, 0, 0, 1, 1, 0, 1, 2, 1, 0, 2, 0, 0, 1, 0, 2, 0, 1, 1, 0, 0, 2, 1, 0, 0, 1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 2, 1, 1, 1, 1, 2, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 2, 1, 1, 0, 1, 0, 1, 2, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 2, 0, 0, 1, 2, 0, 0, 0, 2, 1, 0, 2, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 2, 2, 0, 1, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 2, 1, 0, 0, 1, 0, 0, 1, 2, 0, 0, 1, 0, 2, 0, 0, 0, 2, 0, 0, 1, 1, 1, 2, 1, 0, 1, 1, 0, 0, 0, 1, 1, 2, 0, 1, 0, 1, 0, 0, 0, 1, 0, 2, 1, 1, 1, 0, 0, 2, 1, 0, 2, 0, 1, 0, 0, 0, 0, 1, 2, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 2, 2, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 2, 2, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 2, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 2, 0, 1, 0, 1, 1, 0, 2, 1, 0, 1, 0, 0, 0, 1, 2, 0, 1, 0, 0, 0, 0, 1, 2, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 0, 0, 0, 0, 1, 1, 1, 2, 1, 1, 1, 0, 1, 0, 0, 0, 2, 0, 2, 1, 2, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 2, 2, 1, 0, 0, 0, 1, 1, 1, 0, 2, 0, 1, 0, 0, 0, 0, 0, 1, 0, 2, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 2, 1, 1, 0, 1, 0, 0, 1, 1, 2, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 2, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 2, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 2, 1, 1, 0, 2, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 2, 1, 0, 1, 2, 1, 1, 2, 0, 1, 0, 2, 0, 1, 2, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 2, 1, 0, 1, 0, 0, 0, 2, 0, 0, 0, 2, 1, 0, 2, 0, 0, 0, 0, 0, 1, 1, 1, 1, 2, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 2, 0, 1, 0, 0, 0, 2, 0, 1, 0, 1, 0, 0, 0, 1, 1, 2, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 2, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 2, 0, 2, 1, 1, 1, 2, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 2, 1, 1, 0, 2, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 2, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 2, 2, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 2, 0, 0, 0, 0, 1, 0, 1, 1, 1, 2, 0, 0, 0, 1, 1, 1, 0, 2, 0, 0, 0, 1, 1, 0, 1, 1, 1, 2, 0, 1, 0, 1, 2, 0, 1, 1, 2, 1, 0, 0, 1, 0, 1, 1, 1, 0, 2, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 2, 0, 0, 0, 1, 2, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 2, 0, 1, 1, 1, 2, 0, 2, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 2, 0, 2, 0, 1, 2, 0, 1, 1, 1, 0, 1, 2, 1, 1, 1, 0, 2, 1, 0, 2, 2, 2, 1, 1, 1, 0, 0, 0, 0, 2, 1, 2, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 2, 1, 1, 0, 0, 2, 1, 0, 0, 2, 1, 1, 0, 1, 2, 1, 1, 1, 2, 2, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 2, 0, 0, 2, 0, 1, 1, 2, 0, 1, 0, 1, 0, 0, 0, 2, 0, 1, 0, 0, 1, 2, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 1, 0, 1, 1, 1, 1, 0, 2, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 2, 1, 2, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 2, 1, 0, 2, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 2, 0, 0, 1, 0, 0, 2, 2, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 2, 0, 0, 2, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 2, 1, 0, 1, 0, 0, 2, 1, 1, 2, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 2, 1, 0, 1, 2, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 2, 0, 1, 1, 0, 1, 0, 1, 0, 1, 2, 2, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 2, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 2, 0, 1, 0, 1, 0, 2, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 2, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 2, 1, 2, 0, 0, 0, 1, 2, 0, 0, 1, 1, 2, 1, 0, 0, 1, 0, 0, 0, 2, 0, 0, 2, 1, 1, 1, 0, 2, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 2, 2, 2, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 2, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 2, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 2, 0, 1, 1, 0, 2, 1, 0, 1, 0, 1, 1, 2, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 2, 0, 0, 0, 1, 1, 0, 2, 0, 0, 2, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 2, 1, 1, 1, 1, 0, 0, 0, 1, 1, 2, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 2, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 2, 1, 1, 1, 0, 1, 1, 1, 1, 1, 2, 0, 1, 1, 1, 0, 2, 1, 2, 0, 2, 1, 2, 0, 0, 0, 0, 1, 0, 0, 1, 2, 0, 0, 2, 1, 0, 1, 1, 2, 0, 0, 2, 1, 0, 1, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3s7TQ7RL4Zd",
        "outputId": "4f0d2e0d-124e-4775-8fe0-acf109c6a1b7"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_pred_list))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.53      0.53       918\n",
            "           1       0.48      0.49      0.49       855\n",
            "           2       0.18      0.15      0.16       227\n",
            "\n",
            "    accuracy                           0.47      2000\n",
            "   macro avg       0.39      0.39      0.39      2000\n",
            "weighted avg       0.47      0.47      0.47      2000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guBXwFjOL7Jt",
        "outputId": "70abe71b-4ddd-48cf-d17c-5cc31d386b65"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "print(confusion_matrix(y_test, y_pred_list))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[487 354  77]\n",
            " [347 422  86]\n",
            " [ 93  99  35]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DwNtSgsMSss",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55c8311b-4027-4dea-8add-45b1960fb2d9"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "print(confusion_matrix(y_test, y_pred_list))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[487 354  77]\n",
            " [347 422  86]\n",
            " [ 93  99  35]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJR8flR9q5fH"
      },
      "source": [
        "y_pred_list = []\n",
        "albert_test_preds = []\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    for X_batch, _ in test_loader:\n",
        "        X_batch = X_batch.to(device)\n",
        "        y_test_pred = model(X_batch)\n",
        "        # probs = nn.Softmax(dim=1)(y_test_pred)\n",
        "        # preds = torch.max(probs, 1)[1]\n",
        "        # albert_preds.append([float(probs[0][0]), float(probs[0][1]), float(probs[0][2])])\n",
        "        albert_test_preds.extend(y_test_pred.tolist())\n",
        "        _, y_pred_tags = torch.max(y_test_pred, dim = 1)\n",
        "        y_pred_list.append(y_pred_tags.cpu().numpy())\n",
        "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlzSazmgY2Ly"
      },
      "source": [
        "# Save weights which can be later used for Late Fusion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qh0ceYpRkpqk"
      },
      "source": [
        "import csv\n",
        "with open('albert_train', 'w') as f:\n",
        "    # using csv.writer method from CSV package\n",
        "    write = csv.writer(f)   \n",
        "    write.writerows(albert_train_preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63dnGFxRBlkM"
      },
      "source": [
        "import csv\n",
        "with open('albert_test', 'w') as f:\n",
        "    # using csv.writer method from CSV package\n",
        "    write = csv.writer(f)   \n",
        "    write.writerows(albert_test_preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMwVpD9yFZoG"
      },
      "source": [
        "# Late Fusion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FXtMJKOBz8e"
      },
      "source": [
        "bert_train_preds = pd.read_csv('bert_train', header=None)\n",
        "bert_test_preds = pd.read_csv('bert_test', header=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5Hc_7NhB0RM"
      },
      "source": [
        "bert_train_preds = bert_train_preds.values.tolist()\n",
        "bert_test_preds = bert_test_preds.values.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHnzGrPECfbq",
        "outputId": "800e3494-dea3-435d-eadf-b5e5e251f203"
      },
      "source": [
        "print(len(bert_train_preds))\n",
        "print(len(bert_test_preds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2000\n",
            "2000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZV7ktVtDtM7",
        "outputId": "02698e9a-9368-40bb-cd4d-f984d9d0268c"
      },
      "source": [
        "X_train = pd.concat([pd.DataFrame(bert_train_preds), pd.DataFrame(albert_train_preds)], axis=1)\n",
        "print(X_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              0          1          2          0          1          2\n",
            "0     10.974892 -15.270205  -9.919143 -28.730419  16.147238  -6.497130\n",
            "1     -2.136844   5.622533 -10.146481  -6.819132  -7.989262   6.804869\n",
            "2      2.823482  -5.436560  -3.657327  11.972151 -10.419395 -10.709352\n",
            "3      0.711462   1.380729  -8.498755 -14.136111   8.243175  -3.647041\n",
            "4    -16.189619  11.740435  -7.508574  -4.305228   4.872440  -4.817991\n",
            "...         ...        ...        ...        ...        ...        ...\n",
            "1995   4.828914  -3.032495  -8.888766 -15.400626  10.767344  -6.236086\n",
            "1996  11.592005 -20.626102  -7.332647  -4.216844   7.032504  -8.534880\n",
            "1997   4.994088  -3.008132  -8.720770   6.168057  -5.456748  -6.043819\n",
            "1998  -7.031741   6.071712  -5.643101  -7.631064  -8.519232   7.317303\n",
            "1999  -2.481954   5.758660  -9.271006 -11.970511   8.698915  -6.267465\n",
            "\n",
            "[2000 rows x 6 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGTRHX2-EUP0",
        "outputId": "8d9c9c1e-4b03-44b8-def1-ebb98db1ecca"
      },
      "source": [
        "y_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, ..., 0, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GU3vDWy5Eb1v",
        "outputId": "3937f104-df80-4ffa-87fa-f98f4e60011c"
      },
      "source": [
        "X_test = pd.concat([pd.DataFrame(bert_test_preds), pd.DataFrame(albert_test_preds)], axis=1)\n",
        "print(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              0          1          2          0          1          2\n",
            "0     -0.242388   3.252065  -9.946405  -0.040293   4.227477 -10.129842\n",
            "1      1.852692   0.524064  -9.218081   4.259192  -2.240057  -6.048580\n",
            "2      7.448842 -14.324432  -4.955216  -6.544798   5.980649  -6.065374\n",
            "3     -3.606236   4.643353  -6.371252  -3.765430   1.118028  -1.601155\n",
            "4     11.284456 -20.005501  -7.712418  13.809802 -20.022303  -6.271025\n",
            "...         ...        ...        ...        ...        ...        ...\n",
            "1995   6.131945 -14.653542  -2.575500  -3.173794   1.757222  -1.277446\n",
            "1996   5.547508  -3.910492  -8.520976  -1.759112   3.166871  -5.398952\n",
            "1997   4.254806  -9.940295  -2.156491  -2.709748   3.482681  -4.322409\n",
            "1998   3.643074   0.885228 -13.602243   4.426612   0.717485 -10.951860\n",
            "1999   3.382428  -2.586327  -5.810749  -0.137294   3.076669  -7.855352\n",
            "\n",
            "[2000 rows x 6 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMYCF7-kEkcr",
        "outputId": "bb02d83a-d1c1-44bc-c256-cadf819ef742"
      },
      "source": [
        "y_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddYY5platNTe"
      },
      "source": [
        "# X_train, y_train = featurize(pd.concat([val_bert_emb, dev_bert_emb]).sort_index().reset_index())\n",
        "logit = LogisticRegression(C=1e-2, random_state=17, solver='lbfgs', \n",
        "                           multi_class='multinomial', max_iter=100,\n",
        "                          n_jobs=4)\n",
        "logit.fit(X_train, y_train)\n",
        "# X_test, y_test = featurize(test_bert_emb)\n",
        "logit_test_pred = logit.predict_proba(X_test)\n",
        "log_loss(y_test, logit_test_pred)\n",
        "A = logit_test_pred[:, 0]\n",
        "B = logit_test_pred[:, 1]\n",
        "N = logit_test_pred[:, 2]\n",
        "preds = []\n",
        "for i in range(2000):\n",
        "    if A[i] > B[i] and A[i] > N[i]:\n",
        "        preds.append(0)\n",
        "    elif B[i] > A[i] and B[i] > N[i]:\n",
        "        preds.append(1)\n",
        "    else:\n",
        "        preds.append(2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oAUfge7FGeW",
        "outputId": "476fe1af-37a1-4f56-e3a3-1729dedcec83"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "print(confusion_matrix(y_test, preds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[161 757   0]\n",
            " [143 712   0]\n",
            " [ 10 217   0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwMhSNh8FdN6",
        "outputId": "db14833f-d71d-4de1-8f15-f7111aed1080"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(preds,y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.18      0.51      0.26       314\n",
            "           1       0.83      0.42      0.56      1686\n",
            "           2       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.44      2000\n",
            "   macro avg       0.34      0.31      0.27      2000\n",
            "weighted avg       0.73      0.44      0.51      2000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EbfqB1rsv3F",
        "outputId": "82605cb4-23e8-48b4-f34c-056f514335b6"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eylfd6XGFo_y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "941f4679-11cf-4b31-e701-7fd64c644ffc"
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 15232439183533537431, name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 15703311680\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 3159682282082030462\n",
              " physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "va3X3oKJsyvd",
        "outputId": "1c2d59eb-bdc7-4db9-80a2-fe9a62e25049"
      },
      "source": [
        "device_lib.list_local_devices()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 8384576144443995486, name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 15703311680\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 1749055655976364235\n",
              " physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "SDho8YHpsapK",
        "outputId": "20b208af-59a2-46c6-fa27-1c0ff60e44f3"
      },
      "source": [
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmMkr_tLtBn2",
        "outputId": "ced632a9-c1b4-44ef-c4d6-02a5f9090274"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-0e435c7a-545e-84f2-3563-fa616fa547f4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCnVxJGcteG-",
        "outputId": "9b855b0b-1015-46e8-c3ea-fd623971d2f7"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat May  1 02:16:24 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0    34W / 250W |    349MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-X92BuItI-D"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}